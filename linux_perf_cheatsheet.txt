
===========================

* network performance test between client and server
Ref: https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-bandwidth-testing

you can do linux -> Linux or Linux <-> Windows.


From Linux to Windows:
Receiver <Windows>: ntttcp -r -m <2 x nr cores>,*,<Windows server IP> -ns

Sender <Linux> : ntttcp -s -m <2 x nr cores>,*,<Windows server IP> -N -t 300
==========================================================
* dstat good tool to see CPU, disk, network, paging and system info


$ dstat -a
--total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai stl| read  writ| recv  send|  in   out | int   csw 
7 18  73   9   0   0| 936k 3520k|  51M   31M|   0     0 |  43k  191k
7 11  88   1   0   0| 896k   10M|  53M   32M|   0     0 |  22k   90k
7 12  87   2   0   0|1064k    0 |  51M   31M|   0     0 |  22k   94k
7  8  92   0   0   0|   0     0 |  57M   29M|   0     0 |  18k   75k
7  7  93   0   0   0|4096B  408k|  57M   29M|   0     0 |  17k   81k
7  7  93   0   0   0|   0   128k|  55M   30M|   0     0 |  17k  111k
7  7  93   0   0   0| 848k 9624k|  57M   36M|   0     0 |  18k  143k
7  7  93   0   0   0| 808k  376k|  57M   37M|   0     0 |  18k  159k
7  8  92   0   0   0| 348k  344k|  55M   34M|   0     0 |  18k  192k
7  8  92   0   0   0| 252k  368k|  56M   33M|   0     0 |  17k  190k
7  9  91   0   0   0| 252k  336k|  54M   33M|   0     0 |  17k  204k
7  9  91   0   0   0| 260k   11M|  56M   35M|   0     0 |  18k  229k
7  8  92   0   0   0| 268k  400k|  57M   33M|   0     0 |  18k  219k


How to see per socket connection stats/details
Other tools exist: Ref: https://www.binarytides.com/linux-commands-monitor-network/  https://technologynow.home.blog/2019/05/10/18-commands-to-monitor-network-bandwidth-on-linux-server/

$ sudo apt-get install pktstat

outside emacs:-
-n don't resolve ip to name:
-t    "Top" mode.  Sorts the display by bit count (or packet count if -p was given) instead of by the name.
-B    Display data rates in bytes per second (Bps) instead of in bits per second (bps).
This uses bpf
$sudo pktstat -i eth0 -nt -B

You can filter as well: use tcpdump filter ( eg., "src port 80", "dst port 80", "port 80")
 sudo pktstat -i eth0 -nt -B "port 445"
 
interface: eth0
Bps

   Bps    % desc
 855.4  10% udp6 fe80::2411:a663:9040:5ef9,53606 <-> ff02::c,3702
 692.9   8% udp 10.34.178.129:53605 <-> 239.255.255.250:3702
 437.3   5% tcp 10.34.178.31:61576 <-> 10.34.178.64:22
 239.6   2% arp
 142.2   1% udp 10.36.160.117:51340 <-> 239.255.255.250:1900
 130.0   1% udp 10.34.176.141:58049 <-> 239.255.255.250:1900
  93.8   1% ip6 fe80::6e31:eff:fe30:4271 <-> ff02::12 proto 112

========================================================
* top
------

Ref: man top
                         system load avg over the last 1, 5 and 15 minutes
      current time       load average = running + waiting threads
        |    time since last boot                    |
        |         |                                  |
        v         v                                  v

top - 08:54:25 up 37 days,  8:58, 11 users,  load average: 1.77, 0.57, 0.19

Tasks: 321 total,   1 running, 204 sleeping,   0 stopped,   0 zombie
        ^ 
       total tasks or threads         time waiting for I/O completion (disk)
                                 time in kernel| idle handler
                                     |         |       time spent servicing hardware interrupts
                                     |         |        |
                                     v         v        v
                                     
%Cpu(s):  4.9 us,  1.5 sy,  0.0 ni, 93.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st <-+
                                                                                  |
          ^           ^       ^niced user processes              ^        time stolen from this vm by the hypervisor
          |           |                                          |
          |       time kernel processes                   time spent servicing software interrupts
         time running un-niced user processes                         cache: read from the disk
                                                                       v
                                                                       
KiB Mem : 24210912 total,  7884172 free,  2635336 used, 13691404 buff/cache

^          ^                                                      ^ 
|         total = free + used +  buff/cache                 buffers:yet to be written to disk
Physical memory in KiB(kibibyte) = 1024 bytes
KiB Swap:        0 total,        0 free,        0 used. 21357152 avail Mem 

Task's priority. From -20 to 19, with -20 being most important
                |  Niceness: -20 (most favorable) to 19 (least favorable ).
                |   |     Everything in-use and/or reserved 
                |   |     |       RES: occupying physical memory
                |   |     |        |                  %physical memory
                v   v     v        v                   v

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                
31194 krishna   20   0  357412  45168  12188 S 104.3  0.2   2:57.76 handler_perf_te <-- CPU 104% out 1600% (16 cores)      
31192 krishna   20   0   42924   4180   3396 R   0.7  0.0   0:00.76 top                                                    
31130 krishna   20   0  330372  38348  19236 S   0.3  0.2   0:01.67 emacs                                                  
    1 root      20   0   78156   6544   3916 S   0.0  0.0   0:59.73 systemd                                                
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.55 kthreadd                                               
    4 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/0:0H                                           
    5 root      20   0       0      0      0 I   0.0  0.0   0:01.63 kworker/u128:0                                         
    7 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 mm_percpu_wq                                           
    8 root      20   0       0      0      0 S   0.0  0.0   1:04.08 ksoftirqd/0                                            
    9 root      20   0       0      0      0 I   0.0  0.0  15:59.09 rcu_sched                                              
   10 root      20   0       0      0      0 I   0.0  0.0   0:00.00 rcu_bh                                                 
   11 root      rt   0       0      0      0 S   0.0  0.0   0:01.01 migration/0                                            
   12 root      rt   0       0      0      0 S   0.0  0.0   0:09.33 watchdog/0                                             
   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0                                                
   14 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1                                                
   15 root      rt   0       0      0      0 S   0.0  0.0   0:08.38 watchdog/1                                             
   16 root      rt   0       0      0      0 S   0.0  0.0   0:00.80 migration/1                                            
   17 root      20   0       0      0      0 S   0.0  0.0   0:30.31 ksoftirqd/1                                            
   19 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/1:0H                                           
   20 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/2                                                
   21 root      rt   0       0      0      0 S   0.0  0.0   0:09.78 watchdog/2                                             
   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.83 migration/2                                            


           The status of the task which can be one of:
               D = uninterruptible sleep
               R = running
               S = sleeping
               T = stopped by job control signal
               t = stopped by debugger during trace
               Z = zombie


- load average is very roughly (number of process that need to run / number of CPU cores)
  and measures how overloaded a server is.
- A simple rule of thumb: If the 15 min load average exceeds
   0.7 (after dividing by the number of CPU cores), then the server may be overloaded.

Some keys
---------
H - displays threads (GOOD)

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                    SWAP
  20351 krishna   20     9686912 450672  62500 S 20.1  1.9 780:05.43 mysqld
  20350 krishna   20     9686912 450672  62500 R 18.8  1.9 772:32.13 mysqld
  20343 krishna   20     9686912 450672  62500 S 18.4  1.9 779:22.46 mysqld
  20346 krishna   20     9686912 450672  62500 S 18.1  1.9 780:28.93 mysqld
  20349 krishna   20     9686912 450672  62500 S 18.1  1.9 783:59.11 mysqld
  20342 krishna   20     9686912 450672  62500 S 17.1  1.9 771:57.36 mysqld
  20344 krishna   20     9686912 450672  62500 S 17.1  1.9 777:53.31 mysqld
  20347 krishna   20     9686912 450672  62500 S 17.1  1.9 777:07.96 mysqld
  20345 krishna   20     9686912 450672  62500 S 16.1  1.9 770:59.48 mysqld
  20348 krishna   20     9686912 450672  62500 S 16.1  1.9 778:22.14 mysqld

  
0 - does not display) '0's in the output
    (this reduces screen clutter)

1 - shows multiple CPUs (toggle)
Eg.,
%Cpu0  :  0.3 us,  1.7 sy,  0.0 ni, 98.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  5.2 us,  2.8 sy,  0.0 ni, 92.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu2  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu3  :  0.3 us,  0.3 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st

2 - shows NUMA Node
%Cpu(s):  1.5 us,  2.1 sy,  0.0 ni, 96.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Node0 :  1.1 us,  1.3 sy,  0.0 ni, 97.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Node1 :  2.0 us,  2.8 sy,  0.0 ni, 95.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st


3 - displays a specific NUMA node
 eg., press 1(show cpus), 3(display specific NUMA node) & 1 (show NUMA node 1)
 %Node1 :  2.0 us,  3.4 sy,  0.0 ni, 94.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu8  :  3.7 us,  3.7 sy,  0.0 ni, 92.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu9  :  1.6 us,  4.7 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu10 :  1.5 us,  1.5 sy,  0.0 ni, 96.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu11 :  0.7 us,  3.0 sy,  0.0 ni, 96.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu12 :  1.5 us,  4.5 sy,  0.0 ni, 94.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu13 :  3.1 us,  3.8 sy,  0.0 ni, 93.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu14 :  1.6 us,  2.3 sy,  0.0 ni, 96.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu15 :  2.2 us,  3.7 sy,  0.0 ni, 94.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 

f  :Fields-Management These  keys display a separate screen where you can change which fields are displayed


SORTING 
--------
                command   sorted-field
                M         %MEM        
                N         PID         
                P         %CPU        
                T         TIME+       


==================================================================
* /proc/meminfo

Ref: https://www.kernel.org/doc/Documentation/filesystems/proc.txt

$ cat /proc/meminfo
MemTotal:       24210912 kB <-- physical ram size
MemFree:         7465412 kB 
MemAvailable:   20939500 kB <-- memory is available for starting new applications
Buffers:          560476 kB <-- temporary storage for raw disk blocks
Cached:         12487660 kB <-- in-memory cache for files read from the disk (the page cache)
SwapCached:            0 kB
Active:          6260388 kB <-- Kernel memory that has been used more recently
Inactive:        9389976 kB <-- Kernel memory which has been less recently used (It is more eligible to be reclaimed for other purposes)
Active(anon):    1369780 kB <-- user space processes recently used memory
Inactive(anon):  1233564 kB <-- user space processes less recently used memory
Active(file):    4890608 kB <-- Kernel cache for files that was read from disk (recently used)
Inactive(file):  8156412 kB <-- Kernel cache for files that was read from disk (less recently used)
                               Note: Cached = Active(file) + Inactive(file)
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:                36 kB
Writeback:             0 kB
AnonPages:       2600360 kB
Mapped:            78340 kB
Shmem:              1056 kB
Slab:             819012 kB
SReclaimable:     644364 kB
SUnreclaim:       174648 kB
KernelStack:        7248 kB
PageTables:        16568 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    12105456 kB
Committed_AS:    3328516 kB
VmallocTotal:   34359738367 kB
VmallocUsed:           0 kB
VmallocChunk:          0 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
CmaTotal:              0 kB
CmaFree:               0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
DirectMap4k:     1134528 kB
DirectMap2M:    23506944 kB
DirectMap1G:     1048576 kB

===================================
* vmstat


krishna@krishna:~$ vmstat 2 10 
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache    si   so    bi    bo   in   cs us sy id wa st
 1  0      0 7454868 562308 13136452  0    1    12    23    0    1  0  0 98  1  0
 0  0      0 7454744 562308 13136452  0    0     0     0   12  100  0  0 100  0  0
 0  0      0 7454868 562316 13136444  0    0     0     6    8   90  0  0 100  0  0
 0  0      0 7454868 562316 13136444  0    0     0     0    6   74  0  0 100  0  0
 0  0      0 7454996 562316 13136452  0    0     0     0   16  110  0  0 100  0  0
 0  0      0 7455120 562316 13136452  0    0     0     0    6   63  0  0 100  0  0
 0  0      0 7455120 562316 13136452  0    0     0     0    6   84  0  0 100  0  0
 0  0      0 7455244 562316 13136452  0    0     0     0   11   83  0  0 100  0  0
 0  0      0 7455368 562316 13136452  0    0     0     0   33  189  0  0 100  0  0
 0  0      0 7455368 562316 13136452  0    0     0     0   14   80  0  0 100  0  0
 ^
 r: The number of runnable processes (running or waiting for run time).
 b: The number of processes in uninterruptible sleep.

krishna@krishna:~$ 
=======================================
* iotop

gives info by process

$sudo iotop

Total DISK READ :       0.00 B/s | Total DISK WRITE :       2.49 M/s
Actual DISK READ:       0.00 B/s | Actual DISK WRITE:      49.77 K/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO>    COMMAND
  496 be/3 root        0.00 B/s   26.80 K/s  0.00 %  5.79 % [jbd2/dm-0-8]
32086 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.34 % [kworker/u130:3]
38666 be/4 krishna     0.00 B/s    2.46 M/s  0.00 %  0.06 % cc1plus -quiet -I /home/krishna/~orcasql-mysql/source_downloads/g
    1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init maybe-ubiquity
    2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]
    4 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H]
    5 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/u128:0]
    7 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [mm_percpu_wq]
    8 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]
    9 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]
   10 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_bh]
   11 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]
   12 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/0]
   13 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/0]
   14 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/1]
   15 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/1]
   16 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/1]
   17 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/1]
   19 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/1:0H]
   20 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/2]
   21 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/2]
   22 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/2]
   23 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/2]
   25 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/2:0H]
   26 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/3]
   27 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/3]
   28 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/3]
   29 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/3]
   31 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/3:0H]

=================================
* iostat

gives info by devices
==========================

* branch
- conditional branches mispredicted( Bcm) will be high for this:
 
enum E { A, B, C };
enum E e;
int i;
...
switch (e)
{
  case A: i += 1; break;
  case B: i += 2; break;
  case C: i += 3; break;
}

can be replaced with code like this:

enum E { A, B, C };
enum E e;
int table[] = { 1, 2, 3 };
int i;
...
i += table[e]
Ref: https://valgrind.org/docs/manual/cg-manual.html

==========================
* cachegrind * callgrind
Callgrind is a profiling tool that records the call history among functions in a program's run as a call-graph.
Shows the following:-
  - number of instructions executed, their relationship to source lines, the caller/callee relationship between functions, and the numbers of such calls
  - cache simulation and/or branch prediction (similar to Cachegrind) can produce further information about the runtime behavior of an application

Ref: https://valgrind.org/docs/manual/cl-manual.html
     https://accu.org/journals/overload/20/111/floyd_1886/ good

Installation:-
sudo apt-get install  valgrind
sudo apt-get install  kcachegrind


Ref: https://www.valgrind.org/docs/manual/cg-manual.html
I cache reads
 - Ir - which equals the number of instructions executed
 - I1mr - I1 cache read misses (I1mr)
 - ILmr - LL cache instruction read misses
D cache reads
 - Dr -  which equals the number of memory reads
 - D1mr - D1 cache read misses
 - DLmr -  LL cache data read misses
D cache writes
 - Dw - which equals the number of memory writes
 - D1mw - D1 cache write misses
 - DLmw - LL cache data write misses
Bc  - Conditional branches executed
Bcm - conditional branches mispredicted
Bi  - Indirect branches executed:-
     - Rather than specifying the address of the next instruction to execute, as in a direct branch,
       the argument specifies where the address is located.
     - An example is 'jump indirect on the r1 register', which means that the next instruction to be
       executed is at the address in register r1. The address to be jumped to is not known until the
       instruction is executed. Indirect branches can also depend on the value of a memory location.
     Eg.,
       - subroutine call instructions can be indirect, with the address of the subroutine to be
          called specified in memory.
       - Function Pointers are typically implemented with indirect subroutine calls.
Bim - indirect branches mispredicted


$ g++ -g3  simple.cc -o /tmp/simple -lpthread -rdynamic;
$ valgrind --tool=callgrind --branch-sim=yes --cacheuse=yes --collect-systime=msec --callgrind-out-file=clg.out /tmp/simple
 Callgrind, a call-graph generating cache profiler
 Copyright (C) 2002-2017, and GNU GPL'd, by Josef Weidendorfer et al.
 Using Valgrind-3.16.1 and LibVEX; rerun with -h for copyright info
 Command: /tmp/simple  <--  the command line invocation of the program under examination.
 
warning: L3 cache found, using its data for the LL simulation.
For interactive control, run 'callgrind_control -h'. <--- this might be useful to reset counters etc.,
io_threads are running ...
cpu_threads are running ...

                                           2063 I1 cache read misses
 v-- which events are recorded                 v           
 Events    : Ir         Dr         Dw        I1mr D1mr  D1mw ILmr DLmr DLmw Bc        Bcm     Bi      Bim AcCost1 SpLoss1 AcCost2 SpLoss2  sysCount sysTime
 Collected : 3701868262 1331974479 369526140 2063 14574 2925 1909 7994 2044 653672173 2724902 4959114 730 5404230 681470  1349229 247606   727      762732
              ^                                     
             3701868262 Instruction reads (ie., instructions executed)

 I   refs:      3,701,868,262 <- I - instructions cache reads (ie., instructions executed)
 I1  misses:            2,063 <- I1 cache instruction misses
 LLi misses:            1,909 <- LL cache instruction misses (Last Level instruction - LLi)
 I1  miss rate:          0.00% <- I1 cache miss %
 LLi miss rate:          0.00% <- Last Level insruction cache miss %
 
 D   refs:      1,701,500,619  (1,331,974,479 rd + 369,526,140 wr) <-- Data cache memory (ie., memory reads + writes)
 D1  misses:           17,499  (       14,574 rd +       2,925 wr) <-- D1 cache misses (reads + writes)
 LLd misses:           10,038  (        7,994 rd +       2,044 wr) <-- Last level data misses 
 D1  miss rate:           0.0% (          0.0%   +         0.0%  ) <-- D1 cache misses (NOT: write miss means read from storage, update and write to storage)
 LLd miss rate:           0.0% (          0.0%   +         0.0%  ) <-- Last level data miss rate.
 
 LL refs:              19,562  (       16,637 rd +       2,925 wr)
 LL misses:            11,947  (        9,903 rd +       2,044 wr)
 LL miss rate:            0.0% (          0.0%   +         0.0%  )
 
 Branches:        658,631,287  (  653,672,173 cond +   4,959,114 ind)
 Mispredicts:       2,725,632  (    2,724,902 cond +         730 ind)
 Mispred rate:            0.4% (          0.4%     +         0.0%   )
krishna@krishna:~/linux_perf_cheatsheet$ 

viewing output with gui: Use vnc to view kcachegrind output:- GOOD
-----------------------------------------------------------
  sudo apt-get install kcachegrind
  vncpasswd, vncserver
  In vncviewer login to the system and run this
   $kcachegrind chg.out 

 Navigation:-
    On right side click "Types" tab -> select say "Mispredicted cond branch"
    On left side you see see all Bcm ordered in descinding order.
    Click highest self  -> isPrime(int) 99.40.
    Click Source Tab -> is will show these lines
      14% for (int i = 2; i <= limit; ++i) {
      86%  if (x % i == 0) {
   Click on "Call Graph" see see graph of caller/callee relation

viewing output with text editor
----------------------------------
krishna@krishna:~/linux_perf_cheatsheet$ callgrind_annotate clg.out > junk.txt 2>&1 ; cat junk.txt | grep -v /usr/local/bin/callgrind_annotate
Profile data file 'clg.out' (creator: callgrind-3.16.1)

I1 cache: 32768 B, 64 B, 8-way associative <-- 32K I1 cache 
D1 cache: 32768 B, 64 B, 8-way associative <-- 32K D1 cache
LL cache: 20971520 B, 64 B, 20-way associative <-- 20M Last level cache
Timerange: Basic block 0 - 1012368268
Trigger: Program termination
Profiled target:  /tmp/simple (PID 25316, part 1)
Events recorded:  Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw Bc Bcm Bi Bim AcCost1 SpLoss1 AcCost2 SpLoss2 sysCount sysTime
Events shown:     Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw Bc Bcm Bi Bim AcCost1 SpLoss1 AcCost2 SpLoss2 sysCount sysTime
Event sort order: Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw Bc Bcm Bi Bim AcCost1 SpLoss1 AcCost2 SpLoss2 sysCount sysTime
Thresholds:       99 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Include dirs:     
User annotated:   
Auto-annotation:  on

This line shows PROGRAM TOTALS                                           D1 cache read misses
                Data cache reads.    Data cache writes     I1 cache read misses    |
|                      |                      |                    |               |          D1 cache write misses                                       Conditional branches executed           
v                      v                      v                    v               v               |          Last cache read misses          write misses    |                 conditional branches mispredicted     indirect branches mispredicted                      number of system calls done      
-------------------------------------------------------------------------------                    v              v                             v             v                   v               Branch count           v                                                         v         elapsed time spent in system calls
Ir                     Dr                     Dw                   I1mr           D1mr            D1mw           ILmr           DLmr           DLmw           Bc                   Bcm                Bi                 Bim          AcCost1    SpLoss1    AcCost2    SpLoss2    sysCount     sysTime          
--------------------------------------------------------------------------------
3,701,868,280 (100.0%) 1,331,974,479 (100.0%) 369,526,140 (100.0%) 2,063 (100.0%) 14,574 (100.0%) 2,925 (100.0%) 1,909 (100.0%) 7,994 (100.0%) 2,044 (100.0%) 653,672,173 (100.0%) 2,724,902 (100.0%) 4,959,114 (100.0%) 730 (100.0%) 0          0          0          0          741 (100.0%) 778,891 (100.0%)  PROGRAM TOTALS
^                       
+-- so many instructions cache reads (ie., instructions executed) 



Best way to act based on the output: Ref: https://valgrind.org/docs/manual/cg-manual.html
 - Look at large Ir in line-by-line source code annotations
 - After that, we have found that LL misses are typically a much bigger source of slow-downs than L1 misses.
   So it's worth looking for any snippets of code with high DLmr or DLmw counts
 - Looking at the Bcm and Bim misses can also be helpful.
    In particular, Bim misses are often caused by switch statements, and in some cases these
    switch statements can be replaced with table-driven code.
    
 
THIS SHOWS code level details:-- The way to read is walk along a column. to see the code for a cell go the right most column

Eg.,  for (int i = 2; i <= limit; ++i) {
      1,592,156,757 (43.01%)- Ir -  Instructions are executed by the line
      319,421,877 (48.87%)  - Bc - branch conditional
      393,503 (14.44%)      - Bcm - branch condition misses

Eg., for line if (x % i == 0) {
     1,914,170,514 (51.71%) - Ir - Instructions are executed by the line
     319,028,419 (48.81%)   - Bc - - branch conditional
     2,314,953 (84.96%)     - Bcm - branch condition misses
     
--------------------------------------------------------------------------------
-- Auto-annotated source: simple.cc
--------------------------------------------------------------------------------
Ir                     Dr                   Dw                   I1mr       D1mr       D1mw       ILmr       DLmr       DLmw       Bc                   Bcm                Bi           Bim        AcCost1        SpLoss1      AcCost2      SpLoss2      sysCount     sysTime          

            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           
   19,810,528 ( 0.54%)           0            9,905,264 ( 2.68%) 1 ( 0.05%) 0          0          1 ( 0.05%) 0          0                    0                  0            0          0              0           36 ( 0.00%)   0           36 ( 0.00%)   .                .           bool isPrime(int x) {
   24,763,160 ( 0.67%)   4,952,632 ( 0.37%)   9,905,264 ( 2.68%) 0          0          5 ( 0.17%) 0          0          3 ( 0.15%)           0                  0            0          0              0          140 ( 0.00%)   0           84 ( 0.00%)   .                .             int limit = std::sqrt(x);
   84,194,744 ( 2.27%)  29,715,792 ( 2.23%)  19,810,528 ( 5.36%) 2 ( 0.10%) 1 ( 0.01%) 0          1 ( 0.05%) 0          0            4,952,632 ( 0.76%)         3 ( 0.00%) 4,952,632 (99.87%) 1 ( 0.14%)     0            0            0            0           33 ( 4.45%)  31,201 ( 4.01%)  => /usr/include/c++/7/cmath:__gnu_cxx::__enable_if<std::__is_integer<int>::__value, double>::__type std::sqrt<int>(int) (4,952,632x)
1,592,156,757 (43.01%) 638,843,754 (47.96%) 319,421,879 (86.44%) 0          0          0          0          0          0          319,421,877 (48.87%)   393,503 (14.44%)   0          0              0            0            0            0          457 (61.67%) 384,278 (49.34%)    for (int i = 2; i <= limit; ++i) {
1,914,170,514 (51.71%) 638,056,838 (47.90%)           0          0          0          0          0          0          0          319,028,419 (48.81%) 2,314,953 (84.96%)   .          .              .            .            .            .            .                .               if (x % i == 0) {
    9,118,344 ( 0.25%)           .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .                 return false;
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .               }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             }
      393,458 ( 0.01%)           .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             return true;
    9,905,260 ( 0.27%)   9,905,260 ( 0.74%)           0          0          0          0          0          0          0                    0                  0            0          0              0            0            0            0            5 ( 0.67%) 173,223 (22.24%)  }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           
           24 ( 0.00%)           0                   12 ( 0.00%) 1 ( 0.05%) 0          3 ( 0.10%) 1 ( 0.05%) 0          3 ( 0.15%)           0                  0            0          0              0           84 ( 0.00%)   0           84 ( 0.00%)   .                .           void f1(int c) {
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             C1 c1;
            6 ( 0.00%)           0                    6 ( 0.00%) 1 ( 0.05%) 0          0          1 ( 0.05%) 0          0                    0                  0            0          0              0           10 ( 0.00%)   0           10 ( 0.00%)   .                .             c1.m1 = 1;
            6 ( 0.00%)           0                    6 ( 0.00%) .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             c1.m2 = 2;
            6 ( 0.00%)           0                    6 ( 0.00%) .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             c1.m3 = 3;
           18 ( 0.00%)           6 ( 0.00%)           6 ( 0.00%) 0          0          0          0          0          0                    6 ( 0.00%)         4 ( 0.00%)   .          .              .            .            .            .            .                .             for (int i = 0; i > 0; i++) {
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .               i = i + 1;
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             // printf(".");
            6 ( 0.00%)           0                    6 ( 0.00%) .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             int primeCount = 0;
   19,810,538 ( 0.54%)   4,952,636 ( 0.37%)   4,952,636 ( 1.34%) 0          0          0          0          0          0            4,952,636 ( 0.76%)         4 ( 0.00%)   0          0              0            0            0            0            4 ( 0.54%)   3,760 ( 0.48%)    for (int i = 0; i < 1000000; ++i) {
   24,763,156 ( 0.67%)   4,952,632 ( 0.37%)   4,952,632 ( 1.34%) 0          0          0          0          0          0            4,952,630 ( 0.76%)        24 ( 0.00%)   0          0              0            0            0            0            4 ( 0.54%)   4,347 ( 0.56%)      if (isPrime(i)) {
3,654,512,765 (98.72%) 1,321,474,276 (99.21%) 359,042,935 (97.16%) 3 ( 0.15%) 1 ( 0.01%) 5 ( 0.17%) 2 ( 0.10%) 0          3 ( 0.15%) 643,402,928 (98.43%) 2,708,459 (99.40%) 4,952,632 (99.87%) 1 ( 0.14%)     0            0            0            0          495 (66.80%) 588,702 (75.58%)  => simple.cc:isPrime(int) (4,952,632x)
      393,458 ( 0.01%)           0              393,458 ( 0.11%) 0          0          1 ( 0.03%) 0          0          0                    0                  0            0          0              0           56 ( 0.00%)   .            .            .                .                 ++primeCount;
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .               }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             }
           12 ( 0.00%)           8 ( 0.00%)           .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           



valgrind --tool=cachegrind --log-file=cg.out --branch-sim=yes ./badprime

# run cache and branch-predictor profiler
# 
#$ valgrind --tool=cachegrind --branch-sim=yes --cache-sim=yes --cachegrind-out-file=chg.out /tmp/simple


# run call graph simulator and branch-predictor emulator
# 
$ valgrind --tool=callgrind --branch-sim=yes --cacheuse=yes --callgrind-out-file=clg.out /tmp/simple

callgrind_annotate clg.out > junk.txt 2>&1 ; cat junk.txt | grep -v /usr/local/bin/callgrind_annotate


============================
https://github.com/iovisor/bcc/blob/master/tools/trace_example.txt userspace
https://github.com/iovisor/bcc
https://github.com/iovisor/bcc/blob/master/tools/wakeuptime_example.txt
./wakeuptime -u          # don't include kernel threads (user only)
==========================================================================
* mutrace Measuring mutex lock contention

#see also  sudo stap ~/linux_perf_cheatsheet/scripts/mutexes.stp
Ref: http://0pointer.de/blog/projects/mutrace.html

sudo apt-get install mutrace

Note:
 - This tool report lock contention (valgrind drd does not report contention)
 - link with -rdynamic for better traces
   gcc -O -g3  simple.cc -o /tmp/simple -lpthread -rdynamic;
 - program has to exit to capture traces <--
 - use higher --hash-size=1000000 (if you see messages like mutrace: WARNING: 1739093 internal hash collisions detected. Results might not be as reliable as they could be.mutrace:          Try to increase --hash-size=, which is currently at 3371.)
  - program should not crash
  - This might be better: mutrace  --hash-size=1000000 --max=10000 --debug-info
   - Use this to see the debug function names and line numbers: GOOD GOOD <--
      LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libbfd-2.30-system.so mutrace  --hash-size=1000000 --max=100--debug-info
      
~/linux_perf_cheatsheet$ mutrace  --hash-size=1000000 /tmp/simple 
mutrace: 0.2 sucessfully initialized for process simple (pid 53366).
io_threads are running ...
cpu_threads are running ...

  C-c C-cTerminating due to signal:2

mutrace: Showing statistics for process simple (pid 53366).
mutrace: 3 mutexes used.

Mutex #1 (0x0x560d19982080) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f5601935827]
        /tmp/simple(_Z19cpu_thread_functionPv+0x46) [0x560d19780ed6]

Mutex #0 (0x0x560d19982040) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f5601935827]
        /tmp/simple(_Z19cpu_thread_functionPv+0x60) [0x560d19780ef0]

Mutex #2 (0x0x560d199820c0) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f5601935827]
        /tmp/simple(_Z19cpu_thread_functionPv+0x2c) [0x560d19780ebc]

mutrace: Showing 3 most contended mutexes:
                           Contention: Times lock was already taken when we tried to take it and we had to wait.    
 Times the mutex was locked     | 
            |   Times the owning| thread of the mutex changed
            |       |           |   Total time of the lock    Longest time lock was held
            |       |           |     |                         |
            v       v           v     v                         v
 Mutex #   Locked  Changed    Cont. tot.Time[ms] avg.Time[ms] max.Time[ms]  Flags
       1        6        5        3    10000.704     1666.784     2000.162 M-.--.  <-- Mutex
       0        4        3        3     9000.447     2250.112     3000.168 M-.--.
       2        6        5        2     6000.983     1000.164     1000.184 M-.--.
                                                                           ||||||
                                                                           /|||||
          Object:                                     M = Mutex, W = RWLock /||||
           State:                                 x = dead, ! = inconsistent /|||
             Use:                                 R = used in realtime thread /||
      Mutex Type:                 r = RECURSIVE, e = ERRRORCHECK, a = ADAPTIVE /|
  Mutex Protocol:                                      i = INHERIT, p = PROTECT /
     RWLock Kind: r = PREFER_READER, w = PREFER_WRITER, W = PREFER_WRITER_NONREC 

mutrace: Note that the flags column R is only valid in --track-rt mode!

mutrace: Total runtime is 13614.505 ms.

mutrace: Results for SMP with 16 processors.



best way to decode is to use gdb
---------------------------------
Eg., need to decode _ZN3vml22vml_aio_write_callbackEPKvNS_8VmlErrorE+0x8e [libvml.so]

Need to have source code:-
gdb libvml.so
(gdb) disass/rs _ZN3vml22vml_aio_write_callbackEPKvNS_8VmlErrorE+0x8e
325     void vml_aio_write_callback(const void *ctx, VmlError e) {
   0x000000000012de10 <+0>:     push   %rbp <-- see function start address 0x000000000012de10

Now find what is the addr of _ZN3vml22vml_aio_write_callbackEPKvNS_8VmlErrorE+0x8e  =  0x000000000012de10+0x8e =

(gdb) p/x 0x000000000012de10+0x8e
$13 = 0x12de9e

Now you can see 0x12de9e from  (gdb) disass/rs _ZN3vml22vml_aio_write_callbackEPKvNS_8VmlErrorE+0x8e

/usr/include/c++/7/bits/std_mutex.h:
106           if (__e)
   0x000000000012de9e <+142>:   85 c0   test   %eax,%eax

NOW how to find out code which calls the above:-
Use disass/m <-- see /m which shows only lines from the method
(gdb) disass/m _ZN3vml22vml_aio_write_callbackEPKvNS_8VmlErrorE+0x8e

   0x000000000012de85 <+117>:   callq  0x101e00 <_ZdlPvm@plt>

345     
346       {
347         std::lock_guard<decltype(io_ctx->all_completed_io_events_queue_mutex)> <-- this is close to 0x000000000012de9e!!!!
348             guard(io_ctx->all_completed_io_events_queue_mutex);
349         io_ctx->all_completed_io_events_queue.push_back(
   0x000000000012deaa <+154>:   lea    0x90(%r12),%rdi



--- old info


how to decode:- <-- this gives the function name and not the line number
 $ c++filt _Z19cpu_thread_functionPv+0x2c
  _Z19cpu_thread_functionPv+0x2c

 $ c++filt _Z19cpu_thread_functionPv
  cpu_thread_function(void*) 


Use gdb to decode the code function and line etc.,

Eg.,
Mutex #1 (0x0x561260fb00a0) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f8980d8d827]
        /tmp/simple(_Z2f4i+0x43) [0x561260dae384] <-- we will decode this
        /tmp/simple(_Z19cpu_thread_functionPv+0x2c) [0x561260dae3f5]
        /lib/x86_64-linux-gnu/libpthread.so.0(+0x76db) [0x7f8980b726db]


Need to decode _Z2f4i+0x43
$ c++filt _Z2f4i
f4(int)

Then use gdb to find the line number:-
  Ref: https://sourceware.org/gdb/current/onlinedocs/gdb/Machine-Code.html
  Ref: https://stackoverflow.com/questions/22769246/how-to-disassemble-one-single-function-using-objdump


C++ is a bit tricky, use gdb directly
        /home/krishna/mysql/bin/libfoo.so(bar+0x22d) [0x7f4445bf413d] <---- need to decode this
$gdb ./out/storage/vml/libfoo.so
(gdb) info func bar
All functions matching regular expression "bar":

File /home/krishna/debug-build/storage/vml/VmlManager.cc:
vml::VmlError vml::bar();
(gdb) disas/rs 'vml::bar()' <------------- NOT with in quotes
Dump of assembler code for function vml::bar():
/home/krishna/debug-build/storage/vml/VmlManager.cc:
697     extern "C" PUBLIC_SYMBOL VmlError bar() {
   0x000000000019bf10 <+0>:     55      push   %rbp
...
/home/krishna/debug-build/storage/vml/VmlManager.cc:
706         LOG_ERROR("bar: Error in clearing metadata %s",
   0x000000000019bfe5 <+213>:   48 8d 35 fc 3a 0a 00    lea    0xa3afc(%rip),%rsi        # 0x23fae8
   0x000000000019bfec <+220>:   48 89 df        mov    %rbx,%rdi
   0x000000000019bfef <+223>:   b9 02 00 00 00  mov    $0x2,%ecx
   0x000000000019bff4 <+228>:   ba c3 02 00 00  mov    $0x2c3,%edx <-----------see approx +0x22d
   0x000000000019bff9 <+233>:   e8 12 8b f6 ff  callq  0x104b10 <_ZN6google10LogMessageC1EPKcii@plt> <-- likely this
   0x000000000019bffe <+238>:   48 89 df        mov    %rbx,%rdi
   0x000000000019c001 <+241>:   e8 ba 58 f7 ff  callq  0x1118c0 <_ZN6google10LogMessage6streamEv@plt>



$ gdb -batch -ex "disassemble/rs f4" /tmp/simple <-- here we wanted to disass function f4() Now below see +0x43

Dump of assembler code for function f4(int):
simple.cc:
98      void f4(int d) {
   0x0000000000001341 <+0>:     55      push   %rbp
   0x0000000000001342 <+1>:     48 89 e5        mov    %rsp,%rbp
   0x0000000000001345 <+4>:     48 83 ec 10     sub    $0x10,%rsp
   0x0000000000001349 <+8>:     89 7d fc        mov    %edi,-0x4(%rbp)
..
100       pthread_mutex_lock(&mutex1);
   0x0000000000001356 <+21>:    48 8d 3d 03 1d 20 00    lea    0x201d03(%rip),%rdi        # 0x203060 <mutex1>
   0x000000000000135d <+28>:    e8 6e fd ff ff  callq  0x10d0 <pthread_mutex_lock@plt>

101       sleep(1);
   0x0000000000001362 <+33>:    bf 01 00 00 00  mov    $0x1,%edi
   0x0000000000001367 <+38>:    e8 e4 fc ff ff  callq  0x1050 <sleep@plt>

102       pthread_mutex_unlock(&mutex1);
   0x000000000000136c <+43>:    48 8d 3d ed 1c 20 00    lea    0x201ced(%rip),%rdi        # 0x203060 <mutex1> <------------------------this +0x43
   0x0000000000001373 <+50>:    e8 e8 fc ff ff  callq  0x1060 <pthread_mutex_unlock@plt>

103     
104       pthread_mutex_lock(&mutex2);
   0x0000000000001378 <+55>:    48 8d 3d 21 1d 20 00    lea    0x201d21(%rip),%rdi        # 0x2030a0 <mutex2>
   0x000000000000137f <+62>:    e8 4c fd ff ff  callq  0x10d0 <pthread_mutex_lock@plt>

105       sleep(2);
   0x0000000000001384 <+67>:    bf 02 00 00 00  mov    $0x2,%edi
   0x0000000000001389 <+72>:    e8 c2 fc ff ff  callq  0x1050 <sleep@plt>

112     }
   0x00000000000013c6 <+133>:   90      nop
   0x00000000000013c7 <+134>:   c9      leaveq 
   0x00000000000013c8 <+135>:   c3      retq   
End of assembler dump.



Eg., diassamble an address in an library

Mutex #46279 (0x0x7fbac5a00f80) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7fbac5c29827]
        /home/krishna/mysql/bin/libfoo.so(+0x128c45) [0x7fbac5647c45] <-- need to decode this +0x128c45 in libfoo.so
        /home/krishna/mysql/bin/libfoo.so(+0x1328f3) [0x7fbac56518f3]
        /home/krishna/mysql/bin/libfoo.so(+0x137981) [0x7fbac5656981]
        /home/krishna/mysql/bin/libfoo.so(+0x13870a) [0x7fbac565770a]

$gdb -batch -ex "disas/rs 0x128c45" ./out/storage/vml/libfoo.so
...
SEE the full function to get better context ... not putting it  here.

32          std::lock_guard<decltype(
33              io_context->all_completed_io_events_queue_mutex)>

/home/krishna/apis/NativeAioContext.cc:
40      }
/usr/include/c++/7/bits/unique_ptr.h:
78              delete __ptr;
   0x0000000000128c29 <+393>:   4c 89 ff        mov    %r15,%rdi
   0x0000000000128c2c <+396>:   be 10 00 00 00  mov    $0x10,%esi

/home/krishnay/apis/NativeAioContext.cc:
40      }

/usr/include/c++/7/bits/unique_ptr.h:
78              delete __ptr;
   0x0000000000128c3b <+411>:   e9 20 93 fd ff  jmpq   0x101f60 <_ZdlPvm@plt>

/usr/include/c++/7/bits/deque.tcc:
921             = this->_M_impl._M_finish._M_node - this->_M_impl._M_start._M_node + 1;
   0x0000000000128c40 <+416>:   48 8b 7d c0     mov    -0x40(%rbp),%rdi
   0x0000000000128c44 <+420>:   48 8b b3 b8 00 00 00    mov    0xb8(%rbx),%rsi    <-- +0x128c45 is here (looks like its deleting this node from dequeue and using lock)
   0x0000000000128c4b <+427>:   48 89 f8        mov    %rdi,%rax
   0x0000000000128c4e <+430>:   48 29 f0        sub    %rsi,%rax
   0x0000000000128c51 <+433>:   48 c1 f8 03     sar    $0x3,%rax

* system tap futex contention (print stack traces) mutex contention

SEE also mutexes.stp
Ref: https://sourceware.org/systemtap/examples/  process/futexes.stp - System-Wide Futex Contention

modified the script for stack traces

# Usage:-
 -x is PID
 -d is the library or executable path. when you run first time stap will show list of -d to add.
sudo stap -vv -x 1805 -DMAXACTION=10000  -DMAXSKIPPED=100000 -DSTP_NO_OVERLOAD -DMAXMAPENTRIES=100000 ~/futexes.stp  -d .... -d /home/narwhal/mysql/bin/mysqld-vml

  <-- stap will mention the location of path -d ... 
...
CTRL-C
To sort the below use this:-
 $ sort -r -n -k1 2.txt|grep mysqld-vml
Summary of lock contentions
452 max ms, 148 avg ms, mysqld-vml[1805] lock 0x7fd0f83d4d18 contended 65 times, 25 min WARNING WATCH THIS
383 max ms, 191 avg ms, mysqld-vml[1805] lock 0x7fd0f4833818 contended 4 times, 0 min WARNING WATCH THIS
656 max ms, 182 avg ms, mysqld-vml[1805] lock 0x55fb55d743e0 contended 21 times, 2 min WARNING WATCH THIS

2049 max ms, 13 avg ms, mysqld-vml[1805] lock 0x7fd0f83d7430 contended 909 times, 0 min ms WARNING WATCH THIS
 value |-------------------------------------------------- count
     0 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   822
    >0 |@@@@@                                               87

Lock sample run stack:
 __lll_lock_wait+0x1d [libpthread-2.27.so]
__pthread_mutex_lock+0x55 [libpthread-2.27.so]
_ZN3vml22aio_write_callbackEPKvNS_8VmlErrorE+0x8e [libvml.so]
_ZN3vmlL22HandlerIoCallbackEPKvNS_8VmlErrorE+0xbc [libvml.so]
_ZN3vml17HandlerAioContext14ThreadFunctionEP9AioEvents+0x241 [libvml.so]
_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN3vml16ThreadPoolThreadI4iocb9AioEventsNS3_8AioQueueEEC4EPNS3_10ThreadPoolIS5_S6_S7_EEEUlvE_EEEEE6_M_runEv+0x44 [libvml.so]




* OLD system tap futex contention (SEE previous section for stack traces all)

Ref: https://sourceware.org/systemtap/examples/
 process/futexes.stp - System-Wide Futex Contention
 process/futexes2.stp - System-Wide Shared Futex Contention

scripts# stap -v futexes.stp 
Pass 1: parsed user script and 465 library scripts using 114360virt/48976res/6596shr/42680data kb, in 250usr/50sys/298real ms.
Pass 2: analyzed script: 4 probes, 8 functions, 104 embeds, 9 globals using 116076virt/52352res/8068shr/44396data kb, in 100usr/440sys/551real ms.
Pass 3: translated to C into "/tmp/stapSU927u/stap_b948ea59e802474b7b021ce9b61d6fa4_67634_src.c" using 116448virt/52732res/8196shr/44768data kb, in 0usr/0sys/3real ms.
Pass 4: compiled C into "stap_b948ea59e802474b7b021ce9b61d6fa4_67634.ko" in 5090usr/1710sys/6340real ms.
Pass 5: starting run.
  C-c C-cmysqld[30986] lock 0x7fc150385928 contended 153 times, 6 avg us
mysqld[30986] lock 0x7fc150385838 contended 2 times, 113 avg us
mysqld[30986] lock 0x7fc15038583c contended 2 times, 122 avg us
mysqld[30986] lock 0x7fc1503857e8 contended 2 times, 81 avg us
simple[31319] lock 0x5601419760a0 contended 2 times, 1233633 avg us
simple[31386] lock 0x55b9426a3060 contended 2 times, 1500334 avg us
Pass 5: run completed in 20usr/440sys/7941real ms.

https://man7.org/linux/man-pages/man2/futex.2.html
 long futex(uint32_t *uaddr, int futex_op, uint32_t val, const struct timespec *timeout, uint32_t *uaddr2, uint32_t val3);

The address  they capture is uaddr in the above call (eg., simple[31319] lock 0x5601419760a0 contended 2 times, 1233633 avg us)
* drd valgrind 

Linux valgrind's drd can be used to track down long held mutexes.
Note: This does not find mutex contention.
Ref: https://www.valgrind.org/docs/manual/drd-manual.html

valgrind drd is very very slow (overnight did not complete). Valgrind runs on only one processor (so extreme slowdown and may not even rin the program).
rm  /home/narwhal/mysqld-vml.err;rm -rf /tmp/mysql.soc;  mkdir  /tmp/tablespaces; readlink -f /dev/disk/azure/scsi1/lun0-part* | xargs sudo chmod 777 ;export VML_LOG_TO_CONSOLE=1 ;   valgrind --tool=drd  --log-file=/home/narwhal/val.txt --exclusive-threshold=200 --first-race-only=yes --report-signal-unlocked=no --show-confl-seg=no --segment-merging=no --report-signal-unlocked=no  --fair-sched=yes 

rm  /home/narwhal/mysqld-vml.err;rm -rf /tmp/mysql.soc;  mkdir  /tmp/tablespaces; readlink -f /dev/disk/azure/scsi1/lun0-part* | xargs sudo chmod 777 ;export VML_LOG_TO_CONSOLE=1 ; valgrind --tool=drd  --exclusive-threshold=20 --first-race-only=yes --show-confl-seg=no /home/narwhal/mysql/bin/mysqld-vml --defaults-file=~/primary.cnf --use_vml --disable-log-bin  --datadir=/datadrive --log-error=/home/narwhal/mysqld-vml.err  --innodb-buffer-pool-dump-at-shutdown=OFF --innodb-physical-replica-shared-info-dir=/replica_shared_folder --core-file

Reports all locks that are held for more than 10ms (--exclusive-threshold=10)
krishna@krishna:~/linux_perf_cheatsheet$ valgrind --tool=drd  --exclusive-threshold=10 /tmp/simple
==53405== drd, a thread error detector
==53405== Copyright (C) 2006-2017, and GNU GPL'd, by Bart Van Assche.
==53405== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
==53405== Command: /tmp/simple
==53405== 
io_threads are running ...
cpu_threads are running ...
==53405== Thread 3: <-- Thread 3 acquired mutex at line simple.cc:51 an held it for 1001 ms
==53405== Acquired at:
==53405==    at 0x4C39193: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EBB: cpu_thread_function(void*) (simple.cc:49)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== Lock on mutex 0x30a0c0 was held during 1001 ms (threshold: 10 ms).
==53405==    at 0x4C3A123: pthread_mutex_unlock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108ECD: cpu_thread_function(void*) (simple.cc:51)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== mutex 0x30a0c0 was first observed at:
==53405==    at 0x4C390D3: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EBB: cpu_thread_function(void*) (simple.cc:49)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== 
==53405== Acquired at:
==53405==    at 0x4C39193: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108ED5: cpu_thread_function(void*) (simple.cc:53)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== Lock on mutex 0x30a080 was held during 2001 ms (threshold: 10 ms).
==53405==    at 0x4C3A123: pthread_mutex_unlock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EE7: cpu_thread_function(void*) (simple.cc:55)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== mutex 0x30a080 was first observed at:
==53405==    at 0x4C390D3: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108ED5: cpu_thread_function(void*) (simple.cc:53)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== 
==53405== Acquired at:
==53405==    at 0x4C39193: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EEF: cpu_thread_function(void*) (simple.cc:57)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== Lock on mutex 0x30a040 was held during 3001 ms (threshold: 10 ms).
==53405==    at 0x4C3A123: pthread_mutex_unlock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108F01: cpu_thread_function(void*) (simple.cc:59)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== mutex 0x30a040 was first observed at:
==53405==    at 0x4C390D3: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EEF: cpu_thread_function(void*) (simple.cc:57)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== 
=========================================================================================
* perf

READ GOOD GOODLinuxperftopbasics.pdf(in this folder) https://blog.dbi-services.com/linux-perf-top-basics-understand-the/

Ref: http://www.brendangregg.com/perf.html
Terminology I'm using, from lowest to highest overhead:
 - statistics/count: increment an integer counter on events
 - sample: collect details (eg, instruction pointer or stack) from a subset of events (once every ...)
 - trace: collect details from every event

installation
-------------
sudo apt install linux-tools-$(uname -r) linux-tools-generic

perf stat - gives summary performance counters for a program
----------------------------------------------------------------
This is: statistics/count: increment an integer counter on events


$ sudo perf stat /tmp/simple
 Performance counter stats for '/tmp/simple':

      17172.904652      task-clock (msec)         #    0.159 CPUs utilized <-- only 0.159 cpu is used/
            27,352      context-switches          #    0.002 M/sec <-- so many context switches                  
                43      cpu-migrations            #    0.003 K/sec <-- Migration is when a thread, usually after a context switch,
                                                                       get scheduled on a different CPU than it was scheduled before                 
               272      page-faults               #    0.016 K/sec                  
   <not supported>      cycles                                                      
   <not supported>      instructions                                                
   <not supported>      branches                                                    
   <not supported>      branch-misses                                               

     107.985321552 seconds time elapsed

perf-record : record program's profile (at some sampling frequency)
------------------------------------------------------------------

Use perf record --call-graph dwarf for application stack as well.
Use -g  Enables call-graph (stack chain/backtrace) recording for both kernel space and user space.

use -t thread id (for a hot thread)

Eg., sudo  perf record --call-graph dwarf -g -p $(pidof fio) sleep 10

Eg., sudo  perf record --call-graph dwarf -g -p 5627 sleep 20

This is sampling: collect details (eg, instruction pointer or stack) from a subset of events (once every ...)

$ sudo perf record /tmp/simple
sudo  perf record --call-graph dwarf -g -p $(pidof fio) sleep 10

$ sudo perf report --stdio
 or outside emacs
$  perf report  <-- nice

# Total Lost Samples: 0
#
# Samples: 71K of event 'cpu-clock'
# Event count (approx.): 17898500000
#
# Overhead  Command  Shared Object       Symbol                                 
# ........  .......  ..................  .......................................
#
    95.07%  simple   simple              [.] isPrime <--  for this program 95% of the CPU is spent in isPrime() method
     1.55%  simple   simple              [.] std::sqrt<int>
     1.44%  simple   libm-2.27.so        [.] __sqrt
     1.23%  simple   simple              [.] f1 <-- 1.23% CPU is spent on f1()
     0.13%  simple   [kernel.kallsyms]   [k] finish_task_switch
     0.10%  simple   simple              [.] sqrt@plt
     0.09%  simple   [kernel.kallsyms]   [k] exit_to_usermode_loop

To drill-down to the specific method GOOD
 - click on the iPrime -> Annotate isPrime -> This will show the source code and assembly(below)

Shows % of CPU time spent by each line in method isPrime(). Total is 100%. GOOD 
  |
  v
isPrime  /tmp/simple
             for (int i = 2; i <= limit; ++i) {
  0.16       movl   $0x2,-0x8(%rbp)
  8.17 23:   mov    -0x8(%rbp),%eax
  0.77       cmp    -0x4(%rbp),%eax
            jg     45
               if (x % i == 0) { <-- this is taking 66.41+8.01+3.11% of CPU in this method. why? branch pipeline stall.
  3.11       mov    -0x14(%rbp),%eax
  0.18       cltd
  8.01       idivl  -0x8(%rbp)
 66.41       mov    %edx,%eax
  0.31       test   %eax,%eax
            jne    3f
                 return false;
  0.31       mov    $0x0,%eax
  0.20      jmp    4a
             for (int i = 2; i <= limit; ++i) {
  8.01 3f:   addl   $0x1,-0x8(%rbp)
  2.39      jmp    23
               }
             }
             return true;
  0.02 45:   mov    $0x1,%eax
           }
  0.14 4a:   leaveq
  0.42      retq

Similar output can be obtained by this (can be done in emacs):-
  sudo perf annotate --stdio isPrime | cat



V.GOOD folded: With long call stack, it may be easier to read them folded (and this is what is used by Brendan Gregg Flame Graphs )
Ref: https://blog.dbi-services.com/linux-perf-top-basics-understand-the/

perf report --call-graph ,,,,caller -g folded --stdio

# Children      Self  Command  Shared Object      Symbol
# ........  ........  .......  .................  ..............................................
#
   100.00%     0.00%  a.out    libc-2.17.so       [.] __libc_start_main <-- function name
57.78% __libc_start_main;main;f2;f1 <-- 57.78% cpu cycles is on f1() with stack __libc_start_main->main()->f2->f1()
27.90% __libc_start_main;main;f1
10.87% __libc_start_main;main  <-- 10.87% cpu is on main () with stack __libc_start_main()->main()
2.24% __libc_start_main;main;f2
0.53% __libc_start_main;f2
    99.47%    10.87%  a.out    a.out              [.] main
57.78% main;f2;f1
27.90% main;f1
10.87% __libc_start_main;main
2.24% main;f2
    86.22%    85.68%  a.out    a.out              [.] f1 <--  85.68% CPU cycles in Self == Children (this does not call other functions)
57.78% __libc_start_main;main;f2;f1                      <-- 57.78% in  stack main()->f2()->f1()
27.90% __libc_start_main;main;f1
    60.82%     2.77%  a.out    a.out              [.] f2
57.78% f2;f1
2.24% __libc_start_main;main;f2
0.53% __libc_start_main;f2

Here are the number of sample in each call stack. For example, just looking at the top I can see that 57.78% is on main()->f2->f1(). So if I can optimize something there in the number of calls from f2() to f1(), I know that I can address a large part of the response time, and CPU resource. This even without optimizing f1() itself. Remember that there are two ways to improve the performance: do it faster and do it less.


How to profile only a library
-----------------------------
Ref: https://stackoverflow.com/questions/61323185/profiling-dynamic-library-in-linux-using-perf

Pick the application/process and profile it.
 $ sudo perf record -p 20261 
 ^C[ perf record: Woken up 4 times to write data ]
 [ perf record: Captured and wrote 3.690 MB perf.data (70750 samples) ]
eg.,
sudo perf record -p $(pidof fio)
Then filter the library as follows:
-  focus on shared library dso in interactive "perf report" (find any sample from the library,
   open menu and select focus on library.so; ).

- sudo perf report -d library.so --stdio


- You can also filter samples decoded from perf.data file like perf script | grep library.so | less

Eg.,
$  perf report -d libfoo.so -f --stdio 
[kernel.kallsyms] with build id ad19d53bdea8ee4257152fc235936d61a6529a01 not found, continuing without symbols
[vdso] with build id 6b07cfe7b86149f0a2ec51a362bc78486cc1f77e not found, continuing without symbols
# To display the perf.data header info, please use --header/--header-only options.
#
# dso: libfoo.so
#
# Total Lost Samples: 0
#
# Samples: 70K of event 'cpu-clock'
# Event count (approx.): 17687500000
#
# Overhead  Command     Symbol                                                                                    # ........  ..........  ..........................................................................................#
     0.75%  mysqld-foo  [.] foo_io_getevents
     0.32%  mysqld-foo  [.] std::_Deque_iterator<io_event, io_event&, io_event*>::_Deque_iterator
     0.20%  mysqld-foo  [.] std::chrono::__duration_cast_impl<std::chrono::duration<unsigned long, std::ratio<1l,      0.19%  mysqld-foo  [.] std::chrono::time_point<std::chrono::_V2::steady_clock, std::chrono::duration<long, st     0.17%  mysqld-foo  [.] std::chrono::operator-<std::chrono::_V2::steady_clock, std::chrono::duration<long, std     0.17%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::duration<long, std     0.16%  mysqld-foo  [.] foo::DispatcherWorkItem::Lock
     0.15%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::count
     0.07%  mysqld-foo  [.] std::lock_guard<std::mutex>::~lock_guard@plt
     0.07%  mysqld-foo  [.] std::deque<io_event, std::allocator<io_event> >::end
     0.06%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::duration<unsigned      0.06%  mysqld-foo  [.] std::chrono::duration_cast<std::chrono::duration<unsigned long, std::ratio<1l, 1000000     0.05%  mysqld-foo  [.] std::deque<io_event, std::allocator<io_event> >::begin
     0.05%  mysqld-foo  [.] std::operator==<io_event, io_event&, io_event*>
     0.04%  mysqld-foo  [.] std::chrono::_V2::steady_clock::now@plt
     0.04%  mysqld-foo  [.] std::operator!=<io_event, io_event&, io_event*>
     0.02%  mysqld-foo  [.] std::chrono::duration_cast<std::chrono::duration<unsigned long, std::ratio<1l, 1000000     0.02%  mysqld-foo  [.] std::chrono::duration<long, std::ratio<1l, 1000000000l> >::count@plt
     0.02%  mysqld-foo  [.] std::chrono::time_point<std::chrono::_V2::steady_clock, std::chrono::duration<long, st     0.02%  mysqld-foo  [.] std::this_thread::sleep_for<long, std::ratio<1l, 1000000l> >@plt
     0.01%  mysqld-foo  [.] std::chrono::duration<long, std::ratio<1l, 1000000l> >::duration<int, void>@plt
     0.01%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::count@plt
     

GOOD see where program is sleeping or context switching (eg., waiting for mutex)
--------------------------------------------------------------------------------
Ref: https://perf.wiki.kernel.org/index.php/Tutorial#Profiling_sleep_times

This feature shows where and how long a program is sleeping or waiting something.

The first step is collecting data. We need to collect sched_stat and sched_switch events. Sched_stat events are not enough, because they are generated in the context of a task, which wakes up a target task (e.g. releases a lock). We need the same event but with a call-chain of the target task. This call-chain can be extracted from a previous sched_switch event.

The second step is merging sched_start and sched_switch events. It can be done with help of "perf inject -s". <-- did not work for me

Use --call-graph dwarf for application stack as well.
add --e sched:sched_waking as well in the below command 
$ sudo perf record  --call-graph dwarf -e sched:sched_stat_sleep -e sched:sched_switch  -e sched:sched_process_exit  -e sched:sched_waking -g -o ~/perf.data.raw -p $(pidof mysqld-vml)
  C-c C-c[ perf record: Woken up 253 times to write data ]
[ perf record: Captured and wrote 66.781 MB /home/narwhal/perf.data.raw (8123 samples) ]

sudo perf inject -v -s -i ~/perf.data.raw -o ~/perf.data <-- this did not work properly
sudo perf report --stdio --show-total-period -i ~/perf.data <-- this did not show any data.


$ sudo perf report --stdio --show-total-period -i ~/perf.data.raw | cat
# To display the perf.data header info, please use --header/--header-only options.
#
#
# Total Lost Samples: 0
#
# Samples: 0  of event 'sched:sched_stat_sleep' <-- you will see one section for each event here sched_stat_sleep
# Event count (approx.): 0
#
# Children      Self        Period  Trace output
# ........  ........  ............  ............
#


# Samples: 8K of event 'sched:sched_switch' <-- section for sched_switch
# Event count (approx.): 8123
#
# Children      Self        Period  Trace output                                                                                                      
# ........  ........  ............  ..................................................................................................................
#
     8.22%     8.22%           668  prev_comm=mysqld-vml prev_pid=8356 prev_prio=120 prev_state=S ==> next_comm=swapper/15 next_pid=0 next_prio=120
            |
            ---__GI___clone (inlined)
               start_thread
               0x7f063a46d6de
               std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, void (*)()> > >::_M_run
               ?? (inlined)
               ?? (inlined)
               ?? (inlined)
               ?? (inlined)
               ?? (inlined)
               ?? (inlined)
               ?? (inlined)
               ?? (inlined)
               std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, void (*)()> > >::_M_run
               async_log_reader_thread
               |          
                --8.15%--os_event::wait_time_low
                          os_event::timed_wait
                          __pthread_cond_timedwait (inlined)
                          __pthread_cond_wait_common (inlined)
                          |          
                           --8.14%--futex_abstimed_wait_cancelable (inlined)
                                     entry_SYSCALL_64_after_hwframe
                                     do_syscall_64
                                     __x64_sys_futex
                                     do_futex
                                     futex_wait
                                     futex_wait_queue_me
                                     schedule
                                     __schedule
                                     __schedule
....

# Samples: 15K of event 'sched:sched_waking' <-- section for waking ...
# Event count (approx.): 15638
#
# Children      Self        Period  Trace output                                        
# ........  ........  ............  ....................................................
#
     7.78%     7.78%          1217  comm=mysqld-vml pid=8351 prio=120 target_cpu=011
            |          
             --7.70%--secondary_startup_64
                       start_secondary
                       cpu_startup_entry
                       do_idle
                       |          
                        --7.67%--default_idle_call
                                  arch_cpu_idle
                                  __sched_text_end
                                  native_safe_halt
                                  |          
                                   --7.65%--hv_stimer0_callback_vector
                                             hv_stimer0_vector_handler
                                             hv_stimer0_isr
                                             hrtimer_interrupt
                                             __hrtimer_run_queues
                                             hrtimer_wakeup
                                             wake_up_process
                                             try_to_wake_up
                                             try_to_wake_up


Perf Tracing - WORKS GOOD
--------------------------------------------
perf-probe - Define new dynamic tracepoints
Ref: https://linux.die.net/man/1/perf-probe

Add a probe on schedule() function 12th line with recording cpu local variable:
           ./perf probe schedule:12 cpu
           or
           ./perf probe --add='schedule:12 cpu'

perf probe -add='myfunc%return'
           

To remove probe:-
sudo perf probe -d PerformIoInternal

List probes:
sudo perf probe --funcs --no-demangle --filter='*' --exec /home/narwhal/orcasql-mysql/out/extra/vml/lib/libvml.so  | cat

_ZN3vml15MemChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21AzureFileChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE
_ZZN3vml15MemChunkHandler17PerformIoInternalEPKNS_9IoRequestEE19__PRETTY_FUNCTION__
_ZZN3vml21AzureFileChunkHandler17PerformIoInternalEPKNS_9IoRequestEE12__FUNCTION__
_ZZN3vml21AzureFileChunkHandler17PerformIoInternalEPKNS_9IoRequestEE19__PRETTY_FUNCTION__
_ZZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestEE12__FUNCTION__
_ZZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestEE19__PRETTY_FUNCTION__


Add a probe for function:-
$ sudo perf probe -v -x /home/narwhal/orcasql-mysql/out/extra/vml/lib/libvml.so --add  myalias=_ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE --no-demangle

Start the recording:-
sudo perf record -e probe_libvml:myalias -aR sleep 120

list all the calls recorded:-
sudo perf script --header -F comm,pid,tid,cpu,time,event,ip,sym,dso
..
      mysqld-vml 30058/30087 [009] 4504314.221237: probe_libvml:myalias:      7f3fd4f4550a vml::: 
      mysqld-vml 30058/30086 [008] 4504314.223833: probe_libvml:myalias:      7f3fd4f4550a vml:::
      ...



GOOD C++ perf probe http://notes.secretsauce.net/notes/2019/12/16_c-probes-with-perf.html
GOOD https://stackoverflow.com/questions/56363396/perf-dynamic-tracing-failed-to-add-events
In my case the "argument list too long" error was because I was passing a very long mangled C++ symbol name to perf probe; explicitly naming the probe point with the EVENT= syntax allowed the probe point to be successfully added:
$ sudo perf probe -x myelf --no-demangle --add myalias=_SomeVeryLongMangledNameWhee
$ sudo perf record -e 'probe_myelf:myalias' -a -- sleep 30


OLD OLD
Step 1: list all functions in program /tmp/simple or library
..................................................................
$ sudo perf probe --funcs --exec /tmp/simple 
..
f1
f2
f3
f4
frame_dummy
io_thread_function
isPrime
main
..

http://mysqlentomologist.blogspot.com/2020/07/dynamic-tracing-of-c-class-member.html
$sudo perf probe --funcs --exec  /home/krishna/orcasql-mysql/out/runtime_output_directory/libfoo.so| grep FileChunk
vml::FileChunkHandlerLinux::PerformFlushInternal
vml::FileChunkHandlerLinux::PerformIoInternal
vml::FileChunkHandlerLinux::PerformReadInternal



Step 2:
sudo perf probe  -f --exec /tmp/simple --add='f2 b'
Added new event:
  probe_simple:f2      (on f2 in /tmp/simple with b)

perf record -e probe_simple:f2 -aR sleep 1000

$ sudo perf probe  -x /tmp/simple --line f1 | cat
sudo perf probe  -x /tmp/simple --line f1 | cat
<f1@/home/krishna/linux_perf_cheatsheet/simple.cc:0>
      0  void f1(int c) {
           C1 c1;
      2    c1.m1 = 1;
      3    c1.m2 = 2;
      4    c1.m3 = 3;
      5    for (int i = 0; i > 0; i++) {
      6      i = i + 1;
           }
           // printf(".");
      9    int primeCount = 0;
     10    for (int i = 0; i < 1000000; ++i) {
     11      if (isPrime(i)) {
     12        ++primeCount;
             }
           }
     15  }
         
         void f2(int b) {
           f1(b + 1);

sudo perf probe --exec /tmp/simple --vars f1
sudo perf probe --exec /tmp/simple --vars f1
WARNING: terminal is not fully functional
-  (press RETURN) 
Available variables at f1
        @<f1+0>
                C1      c1
                int     c
                int     primeCount


krishna@krishna:~/linux_perf_cheatsheet$ krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe --funcs --no-demangle --exec  /home/krishna/orcasql-mysql/out/runtime_output_directory/libfoo.so | grep Internal
krishna@krishna:~/linux_perf_cheatsheet$ 
krishna@krishna:~/linux_perf_cheatsheet$ 
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe --funcs --no-demangle --filter='*' --exec  /home/krishna/orcasql-mysql/out/runtime_output_directory/libfoo.so | grep Internal
_ZN3vml15MemChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml16NamespaceManager16AllocateInternalEPNS_17FileChangeContextE
_ZN3vml16NamespaceManager16MoveFileInternalEPNS_15FileMoveContextEb
_ZN3vml16NamespaceManager18CreateFileInternalEPNS_17FileCreateContextE
_ZN3vml16NamespaceManager18DeallocateInternalEPNS_17FileChangeContextE
_ZN3vml16NamespaceManager18DeleteFileInternalEPNS_17FileDeleteContextEb
_ZN3vml16NamespaceManager19CloseHandleInternalEPNS_18CloseHandleContextEb
_ZN3vml16NamespaceManager25LookupReadContextInternalEPNS_13FileIOContextE
_ZN3vml16NamespaceManager26LookupFlushContextInternalEPNS_13FileIOContextE
_ZN3vml16NamespaceManager26LookupWriteContextInternalEPNS_13FileIOContextE
_ZN3vml16TestChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21AzureFileChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21FileChunkHandlerLinux19PerformReadInternalEPKNS_9IoRequestEP4iocbi
_ZN3vml21FileChunkHandlerLinux20PerformFlushInternalEPKNS_9IoRequestEP4iocbi
_ZN3vml21FileChunkHandlerLinux20PerformWriteInternalEPKNS_9IoRequestEP4iocbi
krishna@krishna:~/linux_perf_cheatsheet$ 
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe  -x /tmp/simple --line "_ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE" | cat
Specified source line is not found.
  Error: Failed to show lines.
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe  -x /tmp/simple --line _ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE | cat
Specified source line is not found.
  Error: Failed to show lines.
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe  -x /tmp/simple --line _ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE | cat
Specified source line is not found.
  Error: Failed to show lines.


sudo perf probe  -f --exec /tmp/simple --add='f1:9 c1'
C1 exceeds max-bitwidth. Cut down to 64 bits.
Added new event:
  probe_simple:f1_2    (on f1:9 in /tmp/simple with c1)

You can now use it in all perf tools, such as:

        perf record -e probe_simple:f1_2 -aR sleep 1



------------------

$ more /boot/config-4.15.0-123-generic | grep UPROBE
more /boot/config-4.15.0-123-generic | grep UPROBE
CONFIG_ARCH_SUPPORTS_UPROBES=y
CONFIG_UPROBES=y
CONFIG_UPROBE_EVENTS=y

CONFIG_FTRACE=y

man perf-probe

       Add probes at zfree() function on /bin/zsh

           ./perf probe -x /bin/zsh zfree or ./perf probe /bin/zsh zfree

       Add probes at malloc() function on libc

           ./perf probe -x /lib/libc.so.6 malloc or ./perf probe /lib/libc.so.6 malloc



sudo perf probe -l
sudo perf probe -l
WARNING: terminal is not fully functional
-  (press RETURN) 
  probe_simple:f4      (on f4@simple.cc in /tmp/simple)
krishna@krishna:~/linux_perf_cheatsheet$ krishna@krishna:~/linux_perf_cheatsheet$ history | grep f4
history | grep f4
 1771  perf probe -x /tmp/simple  f4
 1772  sudo perf probe -x /tmp/simple  f4
 1773  bpftrace -e 'uprobe:/tmp/simple:f4 { printf("FOO\n"); }'
 1774  sudo bpftrace -e 'uprobe:/tmp/simple:f4 { printf("FOO\n"); }'
 1775  perf record -e probe_simple:f4 -aR sleep 20
 1776  sudo perf record -e probe_simple:f4 -aR sleep 20
 1795  history | grep f4


sudo perf script
sudo perf script
WARNING: terminal is not fully functional
-  (press RETURN) 
          simple 35812 [009] 252606.865870: probe_simple:f4: (55d560117290)
          simple 35821 [000] 252615.987043: probe_simple:f4: (55d00b17f290)
          simple 35823 [009] 252615.987849: probe_simple:f4: (55d00b17f290)
          simple 35825 [011] 252615.988241: probe_simple:f4: (55d00b17f290)
          simple 35825 [011] 252622.330311: probe_simple:f4: (55d00b17f290)
          simple 35823 [009] 252625.330479: probe_simple:f4: (55d00b17f290)
          
https://www.percona.com/sites/default/files/ple19-slides/day1-pm/tracing-and-profiling-mysql.pdf

Adding uprobes to MySQL dynamically with perf
 The idea was to add dynamic probe to capture SQL queries
 This was done on Ubuntu 16.04 with recent Percona Server 5.7
 First I had to find out with gdb where is the query (hint: dispatch_command
has com_data parameter):
(gdb) p com_data->com_query.query
$4 = 0x7fb0dba8d021 "select 2"
 Then its just as easy as follows:
openxs@ao756:~$ sudo perf probe -x /usr/sbin/mysqld 'dispatch_command
com_data->com_query.query:string'
openxs@ao756:~$ sudo perf record -e 'probe_mysqld:dispatch_command*' -aR
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.676 MB perf.data (3 samples) ]
openxs@ao756:~$ sudo perf script >/tmp/queries.txt
openxs@ao756:~$ sudo perf probe --del dispatch_command


=========================================================================================
* bcc

Ref: https://github.com/iovisor/bcc/blob/master/INSTALL.md
Could not install properly for Ubuntu 18.04
But it has good example for tacing latencies.
Not able to trace C++ code.

These tools fail to run:
 - tools/ucalls: Summarize method calls or Linux syscalls in high-level languages. Examples.
 - tools/uflow: Print a method flow graph in high-level languages. Examples.
 - tools/ugc: Trace garbage collection events in high-level languages. Examples.
 - tools/uobjnew: Summarize object allocation events by object type and number of bytes allocated. Examples.
 - tools/ustat: Collect events such as GCs, thread creations, object allocations, exceptions and more in high-level languages. Examples.
 -tools/uthreads: Trace thread creation events in Java and raw pthreads. Examples.

Below did not show C++ code at all.
~/bcc/tools$ sudo ./funclatency.py /tmp/simple:* --milliseconds  -p $(pidof simple) --function --duration 20
Tracing 21 functions for "/tmp/simple:*"... Hit Ctrl-C to end.


Function = b'__gnu_cxx::__enable_if<std::__is_integer<int>::__value, double>::__type std::sqrt<int>(int)' [50381]
     msecs               : count     distribution
         0 -> 1          : 2677210  |****************************************|
         2 -> 3          : 3        |                                        |
         4 -> 7          : 2        |                                        |

avg = 0 msecs, total: 16098 msecs, count: 2678884

Detaching...
==============================
* bpftrace

  you can trace functions/line, args0, arg1, arg2, arg3 (like int, bool, char*, no structs/classes) and return values. product histogram etc.,
  
 bpftrace  is  a high-level tracing language for Linux enhanced Berkeley Packet Filter (eBPF) available in recent Linux kernels (4.x).

       
                   kernel       userland   
       
        static   tracepoints  USDT* probes 
       
        dynamic    kprobes      uprobes    
       
       USDT = user-level statically defined tracing
       static - are predefined probes in the code already
       dynamic - you can add probes at runtime (with out modifying the code).
       The bpftrace language is inspired by awk and C, and predecessor tracers such as DTrace and SystemTap.

Installation
-------------
Ref: https://github.com/iovisor/bpftrace/blob/master/INSTALL.md
For Ubuntu 18.04 (for 19.04 simpler)
sudo apt-get update
sudo apt-get install -y bison cmake flex g++ git libelf-dev zlib1g-dev libfl-dev systemtap-sdt-dev binutils-dev
sudo apt-get install -y llvm-7-dev llvm-7-runtime libclang-7-dev clang-7
git clone https://github.com/iovisor/bpftrace
mkdir bpftrace/build; cd bpftrace/build;
cmake -DCMAKE_BUILD_TYPE=Release ..
make -j8
sudo make install

!!Note: If things don't work reinstall!!


krishna@krishna  /linux_perf_cheatsheet$ sudo bpftrace -e 'uprobe:/tmp/simple:f4 { printf("f4: %d\n", arg1); }'
Attaching 1 probe...
f4: 0
f4: 0
f4: 0
f4: 0

$ sudo bpftrace -e 'uprobe:/tmp/simple:isP* { printf("isPrime: %d\n", arg1); }'

Not much functionality for user space:

See https://www.brendangregg.com/BPF/bpftrace-cheat-sheet.html
See https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#3-uprobeuretprobe-dynamic-tracing-user-level
  section "uprobe/uretprobe: Dynamic Tracing, User-Level"
     uprobe:library_name:function_name[+offset]
     uprobe:library_name:address
     uretprobe:library_name:function_name
  Section "4. uprobe/uretprobe: Dynamic Tracing, User-Level Arguments"
     probe: arg0, arg1, ..., argN
     uretprobe: retval

  If the traced binary has DWARF available, it is possible to access uprobe arguments by name.
  Syntax:
  uprobe: args->NAME

 The list of function's arguments can be retrieved using the verbose list option:
 bpftrace -lv 'uprobe:/bin/bash:rl_set_prompt'
 uprobe:/bin/bash:rl_set_prompt
     const char* prompt

    const char* prompt
    Example (requires debuginfo for /bin/bash installed):

  # bpftrace -e 'uprobe:/bin/bash:rl_set_prompt { printf("prompt: %s\n", str(args->prompt)); }'
  Attaching 1 probe...
  prompt: [user@localhost ~]$
     
list probes?
-----------------
$ sudo bpftrace -l 'uprobe:/tmp/simple'
uprobe:/tmp/simple:_GLOBAL__sub_I_debug
uprobe:/tmp/simple:_Z14sigint_handleri
uprobe:/tmp/simple:_Z18io_thread_functionPv
uprobe:/tmp/simple:_Z19cpu_thread_functionPv
uprobe:/tmp/simple:_Z2f1i
uprobe:/tmp/simple:_Z2f2i
uprobe:/tmp/simple:_Z2f3i
uprobe:/tmp/simple:_Z2f4i
uprobe:/tmp/simple:_Z41__static_initialization_and_destruction_0ii
uprobe:/tmp/simple:_Z7isPrimei
uprobe:/tmp/simple:_ZSt4sqrtIiEN9__gnu_cxx11__enable_ifIXsrSt12__is_integerIT_E7__valueEdE6__typeES3_

Ref:
man bpftrace
https://github.com/iovisor/bpftrace
https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md GOOD
http://www.brendangregg.com/BPF/bpftrace-cheat-sheet.html
https://github.com/iovisor/bpftrace/blob/master/docs/tutorial_one_liners.md
https://www.percona.com/sites/default/files/presentations/Scale18x-2020-bpfTrace-finally-dTrace-replacement.pdf
https://www.joyfulbikeshedding.com/blog/2019-01-31-full-system-dynamic-tracing-on-linux-using-ebpf-and-bpftrace.html#usdt-probe-example
=======================================================
* stap *systemtap

SystemTap is a tracing and probing tool that allows users to study and monitor the activities of the computer system (particularly, the kernel) in fine detail. It provides information similar to the output of tools like netstat, ps, top, and iostat, but is designed to provide more filtering and analysis options for collected information.

In Ubuntu distro works only for user process, not for kernel. "However, SystemTap never fully merged into the Linux kernel (parts did, like uprobes), so as an out-of-tree project it required maintenance to work at all, and Red Hat only did this for RHEL." Ref: http://www.brendangregg.com/blog/2018-10-08/dtrace-for-linux-2018.html

Ref: https://sourceware.org/systemtap/langref/ GOOD one
     https://sourceware.org/systemtap/documentation.html GOOD 
     https://sourceware.org/systemtap/SystemTap_Beginners_Guide/
     all functions https://manpages.debian.org/testing/systemtap-doc/index.html
     https://sourceware.org/systemtap/examples/index.html good examples

Ubuntu installation
---------------------------
Does not work https://wiki.ubuntu.com/Kernel/Systemtap

Download appropriate elfutils from: https://launchpad.net/ubuntu/+source/elfutils/
eg., for bionic wget https://launchpad.net/ubuntu/+archive/primary/+sourcefiles/elfutils/0.170-0.4ubuntu0.1/elfutils_0.170.orig.tar.bz2
bunzip2 elfutils_0.170.orig.tar.bz2
tar xf elfutils_0.170.orig.tar
 cd elfutils-0.170/
sudo apt install -y gcc
sudo apt install -y g++
sudo apt install -y make
sudo apt install zlib1g-dev
sudo apt install m4
./configure
make
sudo make install

#/home/narwhal/elfutils-0.170

https://sourceware.org/git/?p=systemtap.git;a=blob_plain;f=README;hb=HEAD

git clone git://sourceware.org/git/systemtap.git
(#OR   wget https://sourceware.org/systemtap/ftp/releases/systemtap-4.5.tar.gz;tar zxf systemtap-4.5.tar.gz;cd systemtap-4.5/)

cd systemtap/
./configure --with-elfutils=/home/krishna/elfutils-0.170

./configure  '--with-elfutils=/home/krishna/elfutils-0.170' python='/usr/bin/python2' pyexecdir='${exec_prefix}/lib/python2.7/dist-packages' python3='/usr/bin/python3'

make
sudo make install



Example: Print call trace
-------------------------------
wget https://sourceware.org/systemtap/examples/general/para-callgraph.stp
-v verbose
-c CMD Start  the  probes, run CMD, and exit when CMD finishes.
-x PID Sets  target()  to PID.
linux_perf_cheatsheet/scripts$ sudo stap para-callgraph.stp  'process("/tmp/simple").function("*")'  -v -c "/tmp/simple > /dev/null"

    microsecond           Function with args
    |         Thread id    |    
    |          |           v
   545 simple(8163):   ->f1 c=0x16
     0 simple(8166):->io_thread_function vargp=0x7ffd18fe773c
     0 simple(8167):->cpu_thread_function vargp=0x7ffd18fe773c
    25 simple(8167): ->f3 a=0x14
    39 simple(8167):  ->f2 b=0x15
    52 simple(8167):   ->f1 c=0x16
    65 simple(8167):   <-f1 
    70 simple(8167):  <-f2 
    75 simple(8167): <-f3 
  1127 simple(8165):   <-f1 
  1137 simple(8165):  <-f2 
  1142 simple(8165): <-f3 
  1455 simple(8163):   <-f1 
  1464 simple(8163):  <-f2 
  1469 simple(8163): <-f3 
6000710 simple(8167): ->f3 a=0x14
6000741 simple(8167):  ->f2 b=0x15
6000756 simple(8167):   ->f1 c=0x16
6000772 simple(8167):   <-f1 
6000777 simple(8167):  <-f2 
6000781 simple(8167): <-f3 


List matching probes and local variables of function f1:-
------------------------------------------------------------
$sudo stap  -L 'process("/tmp/simple").function("f1")'
krishna@krishna:~/linux_perf_cheatsheet/scripts$ process("/tmp/simple").function("f1@/home/krishna/linux_perf_cheatsheet/simple.cc:50") $c:int $c1:class C1 <-- shows variables that can be accessed 
void f1(int c) {
  C1 c1;
  c1.m1 = 1;
  c1.m2 = 2;
  c1.m3 = 3;
  for (int i = 0; i > 0; i++) {
    i = i + 1;
  }
  printf(".");
}


Listing variables availabe in a function
----------------------------------------

narwhal@replica1:~$ date;sudo stap -L  'process("/home/narwhal/mysql/lib/libvml.so").function("PerformSyncIoRequest")'
process("/home/narwhal/mysql/lib/libvml.so").function("PerformSyncIoRequest@/home/narwhal/xnerv/storage/vml/dispatcher/DispatcherWorkItem.cc:300") $this:class DispatcherWorkItem* const $dispatcherError:enum VmlError $curOffset:uint64_t

List matching probes in a file or library
------------------------------------------------------------
$ sudo stap -l 'process("/tmp/simple").function("*")'
[sudo] password for krishna: 
process("/tmp/simple").function("__do_global_dtors_aux")
process("/tmp/simple").function("__libc_csu_fini")
process("/tmp/simple").function("__libc_csu_init")
process("/tmp/simple").function("_fini")
process("/tmp/simple").function("_init")
process("/tmp/simple").function("_start")
process("/tmp/simple").function("cpu_thread_function@/home/krishna/linux_perf_cheatsheet/simple.cc:63")
process("/tmp/simple").function("deregister_tm_clones")
process("/tmp/simple").function("f1@/home/krishna/linux_perf_cheatsheet/simple.cc:50")
process("/tmp/simple").function("f2@/home/krishna/linux_perf_cheatsheet/simple.cc:61")
process("/tmp/simple").function("f3@/home/krishna/linux_perf_cheatsheet/simple.cc:62")
process("/tmp/simple").function("frame_dummy")
process("/tmp/simple").function("io_thread_function@/home/krishna/linux_perf_cheatsheet/simple.cc:82")
process("/tmp/simple").function("main@/home/krishna/linux_perf_cheatsheet/simple.cc:127")
process("/tmp/simple").function("open@/usr/include/x86_64-linux-gnu/bits/fcntl2.h:41")
process("/tmp/simple").function("printf@/usr/include/x86_64-linux-gnu/bits/stdio2.h:102")
process("/tmp/simple").function("register_tm_clones")
process("/tmp/simple").function("sigint_handler@/home/krishna/linux_perf_cheatsheet/simple.cc:45")
process("/tmp/simple").function("sprintf@/usr/include/x86_64-linux-gnu/bits/stdio2.h:31")

krishna@krishna:~/linux_perf_cheatsheet/scripts$ sudo stap -l 'process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("*")'
process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("AbortTx@/home/krishna/orcasql-mysql/storage/vml/metadata/UndurableStorage.cc:340")
process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("Acquire@/home/krishna/orcasql-mysql/storage/vml/io_fence/FileLockBasedIoFence.cc:28")
process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("Acquire@/home/krishna/orcasql-mysql/storage/vml/io_fence/IoFenceManager.cc:25")
process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("Acquire@/home/krishna/orcasql-mysql/storage/vml/io_fence/ScsiBasedIoFence.cc:492")
process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("AcquireWriteExclusiveAccess@/home/krishna/orcasql-mysql/storage/vml/io_fence/Scsi


Example: more comprehensive user process tracing
-------------------------------------------------
in another window start: /tmp/simple


sudo stap -v -e '
probe process("/tmp/simple").function("f1")
   {
     printf(" Program name:%s", execname());
     printf(" cpu:%d",  cpu());
     printf(" pid:%d", pid());
     printf(" tid:%d", tid());
     printf(" function:%s", ppfunc() );
     printf(" Local variables:%s",$$vars);
     // refer program variables using $ such as $c1
     printf(" Variable c1.m3:%d",$c1->m3);     
     
     printf("\n");
     print_ubacktrace();
   }

probe process("/tmp/simple").statement("*@simple.cc:58").nearest
   {
     // $$..$$ prints nested classes structures
     printf(" In function function:%s", ppfunc() );     
     printf(" Locals: %s", $$locals$$);
     printf("Params: %s", $$parms);
     // prints variables in scope: class members also     
     printf(" Variables in scope: %s", $$vars$$);
     printf("\n");
   }

probe process("/tmp/simple").thread.begin
   {
        printf(" tid:%d started", tid());
   }

probe process("/tmp/simple").thread.end
   {
        printf(" tid:%d ended", tid());
   }

probe process("/tmp/simple").syscall
   {
        printf("%s called %s\n", syscall_name($syscall),  $$parms);
   }

probe process("/tmp/simple").syscall.return
   {
        // does not work: time =  gettimeofday_ns() - @entry(gettimeofday_ns());
        printf("%s ret:%d\n", syscall_name($syscall), $return);
   }

global f3_time; 
probe process("/tmp/simple").function("f3").return // GOOD VERY GOOD FOR function latency
   {
      // operator <<< stores the value in the aaray "f3_time"
      f3_time <<< gettimeofday_ns() - @entry(gettimeofday_ns());
   }

probe end
   {
     printf(" function f3 time stats in nano seconds\n");
     print(" count:", @count(f3_time));
     print(" min:", @min(f3_time));
     print(" max:", @max(f3_time));
     print(" avg:", @avg(f3_time));     

     print(" Histogram:\n");
     print(@hist_log(f3_time));
   }

'



Example: mega code tracing and function latency measurement
---------------------------------------------------------------
GOOD
To call trace or measure a large/medium project use these steps

1. update variables in stap_process_find_function_probes.py and generate the list of functions and corresponding probes.
python3 stap_process_find_function_probes.py  > /tmp/function_probes.txt

2.
  - based on /tmp/function_probes.txt update the .call call and .return probes in mega-callgraph.stp
  - update verbose variable in mega-callgraph.stp
  - this requires about 8G memory during compilation!!
  - Adjust MAXMAPENTRIES to the number of function probes.
  - From my experiment the count displayed are much lower (eg., 33 instead of 100)
  - Run as follows
sudo stap -g --suppress-time-limits -v -DMAXMAPENTRIES=10000 -DMAXSKIPPED=100000  mega-callgraph.stp
Pass 1: parsed user script and 465 library scripts using 116376virt/51084res/6836shr/44696data kb, in 330usr/60sys/832real ms.
Pass 2: analyzed script: 3400 probes, 7556 functions, 4 embeds, 2268 globals using 286136virt/222432res/8232shr/214456data kb, in 377010usr/2650sys/400102real ms.
Pass 3: translated to C into "/tmp/stapQHy5dG/stap_d5aeeab3409fe551afedf1287cdf04a9_15083112_src.c" using 286136virt/222640res/8428shr/214456data kb, in 79320usr/490sys/79807real ms.
/tmp/stapQHy5dG/stap_d5aeeab3409fe551afedf1287cdf04a9_15083112_src.c: In function probe_8294:
/tmp/stapQHy5dG/stap_d5aeeab3409fe551afedf1287cdf04a9_15083112_src.c:794692:0: note: -Wmisleading-indentation is disabled from this point onwards, since column-tracking was disabled due to the size of the code/headers
             c->actionremaining -= 2;
 
Pass 4: compiled C into "stap_d5aeeab3409fe551afedf1287cdf04a9_15083112.ko" in 1010300usr/16230sys/1017915real ms.
Pass 5: starting run.


Sample output:- with verbose=1 and with call and return probes: process("/home/krishna/orcasql-mysql/out/storage/vml/libfoo.so").function("PerformWriteInternal").return
->PerformWriteInternal this={.m_aioContext=0x5622867d2f00, .m_filePath={._M_dataplus={._M_p="/tmp/chunk9.raw"}, ._M_string_length=15, <union>={._M_local_buf="/tmp/chunk9.raw", ._M_allocated_capacity=8460120955416310831}}, .m_fdBuffered=9, .m_fdUnbuffered=10, .m_isBlockDevice=0} ioRequest={.ioRequestType=1, .buf="8<l\277", .numBytes=16384, .offset=184614912, .cancelled=0, .chunkHandler=0x56228679b950, .cb=0x7f6837a60ffe, .cbParam=0x7f6624000e90, .ioAttrsAndStat=0x7f6624000f60} iocb={.data=0x0, .key=0, .__pad2=0, .aio_lio_opcode=0

<-PerformWriteInternal return=0x1 latency:2628 micro sec tid:5909 cpu:14


Sample output: without verbose=0 
Pass 1: parsed user script and 465 library scripts using 114388virt/49356res/6956shr/42708data kb, in 260usr/20sys/279real ms.
Pass 2: analyzed script: 27 probes, 29 functions, 4 embeds, 26 globals using 116376virt/52752res/8144shr/44696data kb, in 80usr/220sys/307real ms.
Pass 3: translated to C into "/tmp/stapIAZSXk/stap_093f662386cfef37de7929734d9fa9c1_38571_src.c" using 116524virt/53048res/8336shr/44844data kb, in 40usr/200sys/236real ms.
Pass 4: compiled C into "stap_093f662386cfef37de7929734d9fa9c1_38571.ko" in 6080usr/1530sys/7204real ms.
Pass 5: starting run.
function:isPrime, latency microsec mean:6, variance:167 std-dev:sqrt(167) count:11979134 total:71874804 
function:f1, latency microsec mean:21525725, variance:6435019932039 std-dev:sqrt(6435019932039) count:11 total:236782975  WATCH THIS
function:f2, latency microsec mean:21525779, variance:6435172397322 std-dev:sqrt(6435172397322) count:11 total:236783569  WATCH THIS
function:f3, latency microsec mean:21525818, variance:6435239316113 std-dev:sqrt(6435239316113) count:11 total:236783998  WATCH THIS
function:f4, latency microsec mean:28479143, variance:15604731554753 std-dev:sqrt(15604731554753) count:10 total:284791430  WATCH THIS
function:io_thread_function, latency microsec mean:109169027, variance:1916802280 std-dev:sqrt(1916802280) count:3 total:327507081  WATCH THIS
function:main, latency microsec mean:109219953, variance:0 std-dev:sqrt(0) count:1 total:109219953  WATCH THIS


how to do multiple probes in single function code
--------------------------------------------
probe process("/tmp/simple").function("cpu_thread_function"),process("/tmp/simple").function("f1"),process("/tmp/simple").function("f2"),process("/tmp/simple").function("f3"),process("/tmp/simple").function("f4"),process("/tmp/simple").function("io_thread_function"),process("/tmp/simple").function("isPrime"),process("/tmp/simple").function("main"),process("/tmp/simple").function("sigint_handler")
{
}



GOOD find a function latency
-------------------------------

below one monitors for 60 seconds
for low overhead probing use this
   date;sudo stap -v ./systemtap/function_latency.stp "/home/narwhal/mysql/lib/libvml.so" "vml_pwrite64" -T 60

for more overhead probing but more line level details use this:-

date;sudo stap -v ./linetimes.stp "/home/krishna/mysql/lib/libfoo.so" "vml_internal_fsync" -T 60
Mon Apr  5 22:13:18 UTC 2021
Pass 1: parsed user script and 480 library scripts using 125500virt/97300res/5808shr/91824data kb, in 290usr/60sys/353real ms.
Pass 2: analyzed script: 45 probes, 5 functions, 1 embed, 8 globals using 147752virt/120484res/6832shr/114076data kb, in 400usr/10sys/411real ms.
Pass 3: using cached /home/krishna/.systemtap/cache/48/stap_48f1f86025569a8d2a722bf883ded071_31011.c
Pass 4: using cached /home/krishna/.systemtap/cache/48/stap_48f1f86025569a8d2a722bf883ded071_31011.ko
Pass 5: starting run.
  C-c C-cvml_internal_fsync function total time stats in micro seconds
 count:1486 min:117 max:13333 avg:566 Histogram:
value |-------------------------------------------------- count
   16 |                                                      0
   32 |                                                      0
   64 |@@                                                   54
  128 |@@@@@@@@@@@@@@@@                                    345
  256 |                                                     16
  512 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  1034
 1024 |                                                     20
 2048 |                                                      4
 4096 |                                                     10
 8192 |                                                      3
16384 |                                                      0
32768 |                                                      0


/home/krishna/mysql/lib/libfoo.so vml_internal_fsync call count: 1486

region                                                        avg(us)    max(us)      count
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:573")          5         48       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:577")         10         89       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:579")          4         58       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:580")          4         68       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:582")          7         40       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:583")          7        441       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:589")          6         76       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:594")          7        169       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:609")          5         49       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:610")          6         56       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:622")          6        166       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:637")          7        328       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:639")          6         59       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:642")        425      13199       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:644")         10        127       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:646")          7        100       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:653")          7        102       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:664")          7         63       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:668")          7        175       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:680")          7        145       1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:681")          7         78       1486


control flow graph information
from
	to
---------------------------        
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:573")
	process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:577") 1486
process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_posix_io_apis.cc:577")
	process("/home/krishna/mysql/lib/libfoo.so").statement("vml_internal_fsync@/home/krishna/storage/vml/linux_apis/apis/vml_po

...



// usage sudo stap function_latency.stp "/tmp/simple" "f4"
global function_time;
probe process(@1).function(@2).return // GOOD  FOR function latency
{
  // for nano seconds use gettimeofday_ns() - @entry(gettimeofday_ns())
  function_time <<< gettimeofday_us() - @entry(gettimeofday_us());
}

probe end {
  printf("@2 function time stats in micro seconds\n");
  print(" count:", @count(function_time));
  print(" min:", @min(function_time));
  print(" max:", @max(function_time));
  print(" avg:", @avg(function_time));

  print(" Histogram:\n");
  print(@hist_log(function_time));
}


GOOD Show Time Spent on Each Line of a Function
---------------------------------------------
Ref: https://sourceware.org/systemtap/examples/index.html#profiling/linetimes.stp
Modified code a bit and it is under scripts/linetimes.stp

Eg., here is a sample function with line numbers. A few line times are annotated 

 90void f4(int d) {
 91  f3(d);                     
 92  pthread_mutex_lock(&mutex1);
 93  sleep(1);
 94  pthread_mutex_unlock(&mutex1);
 95
 96  pthread_mutex_lock(&mutex2);
 97  sleep(2);
 98  pthread_mutex_unlock(&mutex2);
 99
100  pthread_mutex_lock(&mutex3); <-- Avg latency is 2387387 us, max latency 2686463 us
101  sleep(3);                    <-- Avg latency is 3000163 us, max latency is 3000198 us
102  pthread_mutex_unlock(&mutex3); <-- avg(us):74 max: 99
103}


To find the list of funtions:
  /usr/bin/stap -l 'process("/home/krishna/mysql/bin/libfoo.so").function("*")' > j.txt
Very simple to run:- works for C++ also nicely
   $ sudo stap -v linetimes.stp "/home/krishna/mysql/bin/libfoo.so" "FooBarFunction"
   $ sudo stap -v linetimes.stp "/home/krishna/mysql/bin/foo.bin" "FooBarFunction" 
  Now run the program

Another way to run
  $sudo stap linetimes.stp "/tmp/simple" "f4" -c '/tmp/simple'
  io_threads are running ...
  cpu_threads are running ...

/tmp/simple f4 call count: 37

region                                                                                      avg(us)    max(us)
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:100")    2387387    2686463
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:101")    3000163    3000198
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:102")         74         99
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:103")         10         18
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:90")         17         50
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:91")     484091     538079
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:92")      71023    1792180
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:93")    1000154    1000179
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:94")         36         79
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:96")      81096    2000029
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:97")    2000150    2000166
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:98")         33         78


control flow graph information
from
        to
---------------------
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:100")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:101") 35
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:101")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:102") 34
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:102")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:103") 34
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:103")
        process("/tmp/simple").function("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:90").return 34
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:90")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:91") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:91")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:92") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:92")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:93") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:93")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:94") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:94")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:96") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:96")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:97") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:97")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:98") 36
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:98")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:100") 36
krishna@krishna:~/linux_perf_cheatsheet/scripts$ 

What probes are available:
-----------------------------
Ref: https://sourceware.org/systemtap/man/stapprobes.3stap.html (see sections USER-SPACE, Java)
process("PATH").function("NAME")
  - Places a probe near the beginning of the named function, so that parameters are available as context variables.
process("PATH").statement("*@FILE.c:123")
  -  Places a probe at the exact spot, exposing those local variables that are visible there.
process("PATH").library("PATH").function("NAME")
process("PATH").library("PATH").statement("*@FILE.c:123")
  -  Places a probe at the exact spot, exposing those local variables that are visible there.
process("PATH").library("PATH").statement("*@FILE.c:123").nearest
process("PATH").function("*").return
  - Places a probe at the moment after the return from the named function, so the return value is available as the "$return" context variable.
process("PATH").function("myfun").label("foo")
process("PATH").function("foo").callee("bar")
  - Places a probe on the callee function given in the .callee modifier, where the callee must be a function called by the target function given in .function. calls through function pointers are not available.
process("PATH").function("foo").callee("bar").return
process("PATH").function("foo").callee("bar").call
process("PATH").function("foo").callees(DEPTH)
  - Recursively places probes on callees. 
process(PID).function("NAME")
process(PID).function("myfun").label("foo")
process(PID).plt("NAME")
 - ?? A .plt probe will probe functions in the program linkage table corresponding to the rest of the probe point
process(PID).plt("NAME").return
process(PID).statement("*@FILE.c:123")
process(PID).statement("*@FILE.c:123").nearest <-- Places a probe at the nearest available line number for each line number given in the statement.
process(PID).statement(ADDRESS).absolute
  - use raw (unverified) virtual addresses
process("PATH").mark("LABEL")
  - This is for instrumented code(code should have STAP_PROBE1). A .mark probe gets called via a static probe which is defined in the application by STAP_PROBE1(PROVIDER,LABEL,arg1), which are macros defined in sys/sdt.h.


process(PID).begin
process("FULLPATH").begin
process.begin
 - A process.begin probe gets called when new process described by PID or FULLPATH gets created. In addition, it is called once from the context of each preexisting process, at systemtap script startup. This is useful to track live processes

process(PID).thread.begin
process("FULLPATH").thread.begin
process.thread.begin
  -  A process.thread.begin probe gets called when a new thread described by PID or FULLPATH gets created.
process(PID).end
process("FULLPATH").end
process.end
process(PID).thread.end
process("FULLPATH").thread.end
process.thread.end

process(PID).syscall
process("FULLPATH").syscall
process.syscall
 - The system call number is available in the $syscall context variable, and the first 6 arguments of the system call are available in the $argN (ex. $arg1, $arg2, ...) context variable.
 
process(PID).syscall.return
process("FULLPATH").syscall.return
process.syscall.return
  - the return value of the system call is available in the $return context variabl
  
process(PID).insn
process("FULLPATH").insn
process(PID).insn.block
process("FULLPATH").insn.block
 - A process.insn probe gets called for every single-stepped instruction of the process described by PID or FULLPATH. A process.insn.block probe gets called for every block-stepped instruction of the process described by PID or FULLPATH


What to print:
-------------------
Ref: https://sourceware.org/systemtap/tutorial.pdf
tid() The id of the current thread.
pid() The process (task group) id of the current thread.
uid() The id of the current user.
execname() The name of the current process.
cpu() The current cpu number.
gettimeofday_s() Number of seconds since epoch.
get_cycles() Snapshot of hardware cycle counter.
pp() A string describing the probe point being currently handled.
ppfunc() If known, the the function name in which this probe was placed.
$$vars If available, a pretty-printed listing of all local variables in scope.
print_backtrace() If possible, print a kernel backtrace.
print_ubacktrace() If possible, print a user-space backtrace.


Multiple probes can be specified using a ","
---------------------------------------------------

sudo stap -e 'probe process("/tmp/foo.so").function("f1"),process("/tmp/foo.so").function("f2") { printf("hello");}'



GOOD mutexes mutex contention 
--------------------------------------------
SEE also futexes.stp in this notes.

start process mysqld-vml

Ref: https://raw.githubusercontent.com/alanconway/systemtap/master/mutexes.stp
( i modified mutexes.stp slightly)

sudo stap ~/linux_perf_cheatsheet/scripts/mutexes.stp -x $(pidof mysqld-vml) -d /home/narwhal/orcasql-mysql/out/runtime_output_directory/mysqld-vml --ldd -v
Ctrl-C


=== mutex 0x7f05f8692388 contended 20725 times, 300098us total, 14us avg, 965us max
_Z14os_event_resetP8os_event+0x16 [mysqld-vml]
_Z23async_log_reader_threadv+0x5dc [mysqld-vml]
_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJ8RunnablePFvvEEEEEE6_M_runEv+0x63 [mysqld-vml]
_ZNKSt10error_code23default_error_conditionEv+0x2f [libstdc++.so.6.0.25]


==== mutex 0x55d077f0bb50 contended 2 times, 91us total, 45us avg, 60us max
_ZN3vml12IoDispatcher19GetChunkHandlerByIDEt+0x33 [libvml.so] <-- to decode this see "gdb libvml.so"



==========================================================
* strace


-c Count time, calls, and  errors for each system call and report a summary on program exit.
   This attempts to show system time (CPU time spent running in the kernel) independent of  wall clock time.

-e trace=set eg., -e trace=open,close,read,write

summary of system calls and times
---------------------------------------
$  strace -c -f /tmp/simple
strace: Process 32966 attached
strace: Process 32967 attached
strace: Process 32968 attached
strace: Process 32969 attached
strace: Process 32970 attached
strace: Process 32971 attached
io_threads are running ...
cpu_threads are running ...
% time     seconds  usecs/call     calls    errors syscall
------ ----------- ----------- --------- --------- ----------------
 72.99    0.908515        2232       407           nanosleep
 22.04    0.274316        3345        82           futex
  4.68    0.058269         194       300           pwrite64 <-- 4% of the system time(CPU time in kernel) is pwrite64
                                                                300 call. total CPU time in kernel 0.058269 sec.
                                                                Each call avg 194 micro seconds.
  0.07    0.000868          41        21           mprotect
  0.06    0.000686         114         6           munmap
  0.05    0.000617         103         6           clone
  0.04    0.000489          19        26           mmap
  0.02    0.000298         149         2           write
  0.02    0.000285          17        17         8 openat
  0.02    0.000270          39         7           set_robust_list
  0.01    0.000122          41         3           madvise
  0.00    0.000055           8         7           fstat
  0.00    0.000000           0         5           read
  0.00    0.000000           0         6           close
  0.00    0.000000           0         8         7 stat
  0.00    0.000000           0         3           brk
  0.00    0.000000           0         3           rt_sigaction
  0.00    0.000000           0         1           rt_sigprocmask
  0.00    0.000000           0         7         7 access
  0.00    0.000000           0         1           execve
  0.00    0.000000           0         1           arch_prctl
  0.00    0.000000           0         1           set_tid_address
  0.00    0.000000           0         1           prlimit64
------ ----------- ----------- --------- --------- ----------------
100.00    1.244790                   921        22 total


-p pid
-xx         Print all strings in hexadecimal string format.
-f   trace child/threads
-s strsize  Specify the maximum string size to print (the default is 32).
strace -f -p $(pidof mysqld) -e pwrite -s1 -xx 2>&1 | grep 'pwrite([FD1FD2],' |head -n 100000 | awk '{writes[$5]++}END {for(w in writes){print w, " ", writes[w]}}'
[5:56 PM] Anand Subramanian
    this should give the InnoDB log file writes being done
[5:56 PM] Anand Subramanian
    number/count of and what sized IOs

strace -f -e pwrite64 /tmp/simple -s1 -xx 2>&1 | grep pwrite64 | grep -v resumed | awk '{ print $5, " ", $0;}'


=============================
* time

time /tmp/simple
io_threads are running ...
cpu_threads are running ...

real    1m47.819s <- Elapsed real (wall clock) time used by the process, in seconds.
user    0m17.813s <-- Total number of CPU-seconds that the process used directly (in user mode), in seconds.
sys     0m0.077s  <-- Total number of CPU-seconds used by the system on behalf of the process (in kernel mode), in seconds.
==========================
* migration

Ref: https://stackoverflow.com/questions/45368742/linux-difference-between-migrations-and-switches

A thread can migrate to another CPU in the following cases:
 - During exec()
 - During fork()
 - During thread wake-up.
 - If thread affinity mask has changed.
 - When the current CPU is getting offline.

Process migration in computing comes in two flavors:[1]
- Non-preemptive process migration: Process migration that takes place before execution of
  the process starts (i.e. migration whereby a process need not be preempted).
  This type of process migration is relatively cheap, since relatively little administrative
  overhead is involved.
- Preemptive process migration: Process migration whereby a process is preempted, migrated
  and continues processing in a different execution environment.
  This type of process migration is relatively expensive, since it involves recording,
  migration and recreation of the process state as well as the reconstructing of any
  inter-process communication channels to which the migrating process is connected.


$ cat /proc/33514/sched
simple (33514, #threads: 7)
-------------------------------------------------------------------
se.exec_start                                :     231412663.439654
se.vruntime                                  :      13531310.384397
se.sum_exec_runtime                          :             3.964652
se.nr_migrations                             :                    0 <-- number of context switches.
nr_switches                                  :                    3
nr_voluntary_switches                        :                    3 <--  number of voluntary switches, i.e. the thread blocked and hence another thread is picked up.
nr_involuntary_switches                      :                    0 <-- the scheduler kicked the thread out as there is another hungry thread is ready to run.
se.load.weight                               :              1048576
se.runnable_weight                           :              1048576
se.avg.load_sum                              :                47280
se.avg.runnable_load_sum                     :                47280
se.avg.util_sum                              :             26015811
se.avg.load_avg                              :                 1023
se.avg.runnable_load_avg                     :                 1023
se.avg.util_avg                              :                  547
se.avg.last_update_time                      :      231412663439360
policy                                       :                    0
prio                                         :                  120
clock-delta                                  :                  191
mm->numa_scan_seq                            :                    1
numa_pages_migrated                          :                  184
numa_preferred_nid                           :                   -1
total_numa_faults                            :                14371
current_node=0, numa_group_id=0
numa_faults node=0 task_private=0 task_shared=0 group_private=0 group_shared=0
numa_faults node=1 task_private=0 task_shared=0 group_private=0 group_shared=0
========================================================================================
* optimizations * cpu optimization


** Branch prediction macros in GCC
Ref: https://www.geeksforgeeks.org/branch-prediction-macros-in-gcc/

#define likely(x)      __builtin_expect(!!(x), 1)
#define unlikely(x)    __builtin_expect(!!(x), 0)

const char *home_dir ;

home_dir = getenv("HOME");
if (likely(home_dir))
   printf("home directory: %s\n", home_dir);
else
   perror("getenv");

For above example, we have marked if condition as likely() true, so compiler will put true code immediately after branch, and false code within the branch instruction. In this way compiler can achieve optimization.
Accessing memory is the slowest CPU operation as compared to other CPU operations. To avoid this limitation, CPU uses CPU caches e.g L1-cache, L2-cache etc. The idea behind cache is, copy some part of memory into CPU itself. We can access cache memory much faster than any other memory. But the problem is, limited size of cache memory, we cant copy entire memory into cache. So, the CPU has to guess which memory is going to be used in the near future and load that memory into the CPU cache and above macros are hint to load memory into the CPU cache.


** Loop Optimization in Compiler Design
Ref: https://www.geeksforgeeks.org/loop-optimization-in-compiler-design/?ref=rp

*** Frequency Reduction (Code Motion):
In frequency reduction, the amount of code in loop is decreased. A statement or expression, which can be moved outside the loop body without affecting the semantics of the program, is moved outside the loop.

Initial code:

while(i<100)
{
   a = Sin(x)/Cos(x) + i;
   i++;
}

Optimized code:

t = Sin(x)/Cos(x);
while(i<100)
{
 a = t + i;
 i++;
}

*** Loop Unrolling: Loop unrolling is a loop transformation technique that helps to optimize the execution time of a program. We basically remove or reduce iterations. Loop unrolling increases the programs speed by eliminating loop control instruction and loop test instructions.
Example:

Initial code:-

for (int i=0; i<5; i++)
  printf("Pankaj\n");

Optimized code:-

printf("Pankaj\n");
printf("Pankaj\n");
printf("Pankaj\n");
printf("Pankaj\n");
printf("Pankaj\n");

*** Loop Jamming: Loop jamming is the combining the two or more loops in a single loop. It reduces the time taken to compile the many number of loops.
Example:

Initial Code:

for(int i=0; i<5; i++)
    a = i + 5;
for(int i=0; i<5; i++)
    b = i + 10;

Optimized code:
for(int i=0; i<5; i++)
{
  a = i + 5;
  b = i + 10;
}

*** Peephole Optimization in Compiler Design
Ref: https://www.geeksforgeeks.org/peephole-optimization-in-compiler-design/

Peephole optimization is a type of Code Optimization performed on a small part of the code. It is performed on the very small set of instructions in a segment of code.

Redundant load and store elimination: In this technique the redundancy is eliminated.

Initial code:
  y = x + 5;
  i = y;
  z = i;
  w = z * 3;

Optimized code: ( here variable "z" is redundant/removed)
  y = x + 5;
  i = y;
  w = y * 3;
Constant folding: The code that can be simplified by user itself, is simplified.

Initial code:
  x = 2 * 3;

Optimized code:
  x = 6;
  
Strength Reduction:The operators that consume higher execution time are replaced by the operators consuming less execution time.

Initial code:
  y = x * 2;
Optimized code:
  y = x + x;    or     y = x << 1;

Initial code:
  y = x / 2;
Optimized code:
  y = x >> 1;
  
Null sequences: Useless operations are deleted.

Combine operations: Several operations are replaced by a single equivalent operation.

** Basic optimizations

Ref: https://www.geeksforgeeks.org/basic-code-optimizations-in-c/

Avoid pointer Dereference in loop: Pointer dereferencing creates lots of trouble in memory. So better assign it to some temporary variable and then use that temporary variable in the loop.

Unoptimized:-
#include <stdio.h>
int main(void) {
  int a = 0;
  int *iptr = &a;

  // Dereferencing pointer inside loop
  // is costly
  for (int i = 1; i < 11; ++i) {
    *iptr = *iptr + i;
  }
  printf("Value of a : %d", a);
  return 0;
}

Optimized:-
#include <stdio.h>
int main(void) {
  int a = 0;
  int *iptr = &a;

  // Dereferencing pointer outside loop
  // and saving its value in a temp variable
  int temp = *iptr;

  for (int i = 1; i < 11; ++i) {

    // performing calculations on temp variable
    temp = temp + i;
  }

  // Updating pointer using final value of temp
  *iptr = temp;

  printf("Value of a : %d", a);
  return 0;
}

============================================================
* pgo profile guide optimization (two pass compilation)


GOOD See https://gist.github.com/daniel-j-h/c4b109bff0b717fc9b24

Ref:
  What Every Programmer Should Know About Memory https://akkadia.org/drepper/cpumemory.pdf
  https://ddmler.github.io/compiler/2018/06/29/profile-guided-optimization.html
The first step  is to create an instrumented version of our binary that will gather the runtime data

$ g++ -fprofile-generate simple.cc -o /tmp/simple -lpthread -rdynamic;

Normally you would run it multiple times with different input and so on to create a somewhat representative sample of your actual usage patterns. This will create a new .gcda file in this case its called simple.gcda. We will use this in our next step as the profile:

$g++ -fprofile-use=simple.gcda -O3 simple.cc -o /tmp/simple -lpthread -rdynamic;

==============================================================
* compiler optimizations 
gcc: how did gcc optimize my code
-------------------------------
Ref: https://gcc.gnu.org/onlinedocs/gcc-6.3.0/gcc/Developer-Options.html
  - fdump-tree-switch-options=filename Control the dumping at various stages of processing the intermediate language tree to a file.
   optimized Enable showing optimization information (only available in certain passes)

Ref: https://stackoverflow.com/questions/2391442/how-to-see-the-optimized-code-in-c

You can get an idea of optimization using the option -fdump-tree-optimized with gcc . and you'll get an optimised file. you cannot run the code but using that you can get an idea of optimization . dont forget to include -O2 or -O3 or some other level.

Eg.,
$ g++  -O3 -fdump-tree-optimized=optimized.txt  simple.cc -o /tmp/simple -lpthread -rdynamic;
optimized.txt file will contains the file that shows how g++ optimized the code with "-O3" option
$ time /tmp/simple
real    0m9.659s <-- 10 sec

$g++ -fdump-tree-optimized=unoptimized.txt  simple.cc -o /tmp/simple -lpthread -rdynamic;
unoptimized.txt file will contain the file that shows the unoptimized code
$ time /tmp/simple
Unoptimized takes very long time ...  may be 10 mins?

Original cpu_thread_function:-

void *cpu_thread_function(void *vargp) {
  uint32_t my_num = (*(uint32_t *)vargp);

  for (int loop_count = 0; loop_count < LOOP_COUNT; loop_count++) {
    f4(loop_count);
  }
}

From optimized.txt cpu_thread_function:-
  - Notice these things:
    -- conntents of f4() are put inside cpu_thread_function (inlined)
    -- f4() calls f3(). Here f3() as removed (as it is a redundant function: its return value not used, no printf in it, no global variables set)
void* cpu_thread_function(void*) (void * vargp)
{
  int i;
  double _10;
  unsigned int ivtmp_12;
  unsigned int ivtmp_31;

  <bb 2> [0.01%]:

  <bb 3> [0.15%]:
  # ivtmp_12 = PHI <ivtmp_31(8), 10(2)>
  goto <bb 7>; [100.00%]

  <bb 4> [14.29%]:
  _10 = (double) i_9;
  if (_10 u>= 0.0)
    goto <bb 6>; [98.99%]
  else
    goto <bb 5>; [1.01%]

  <bb 5> [0.14%]:
  __builtin_sqrt (_10);

  <bb 6> [14.29%]:

  <bb 7> [14.44%]:
  # i_6 = PHI <i_9(6), 0(3)>
  i_9 = i_6 + 1;
  if (i_9 == 1000000000)
    goto <bb 8>; [1.01%]
  else
    goto <bb 4>; [98.99%]

  <bb 8> [0.15%]:
  __builtin_putchar (46);
  __builtin_putchar (46);
  pthread_mutex_lock (&mutex1);
  pthread_mutex_unlock (&mutex1);
  pthread_mutex_lock (&mutex2);
  pthread_mutex_unlock (&mutex2);
  pthread_mutex_lock (&mutex3);
  pthread_mutex_unlock (&mutex3);
  __builtin_putchar (46);
  ivtmp_31 = ivtmp_12 + 4294967295;
  if (ivtmp_31 == 0)
    goto <bb 9>; [9.70%]
  else
    goto <bb 3>; [90.30%]

  <bb 9> [0.01%]:
  return;

}


From unoptimized.txt cpu_thread_function:-
  - Notice this:
    - no code optimization
    - while loop is replaced with "loop_count_1", "if" and "goto"
    
;; Function void* cpu_thread_function(void*) (_Z19cpu_thread_functionPv, funcdef_no=1729, decl_uid=42507, cgraph_uid=601, symbol_order=608)

void* cpu_thread_function(void*) (void * vargp)
{
  int loop_count;
  uint32_t my_num;

  <bb 2> [0.00%]:
  my_num_5 = MEM[(uint32_t *)vargp_4(D)];
  loop_count_6 = 0;

  <bb 3> [0.00%]:
  # loop_count_1 = PHI <loop_count_6(2), loop_count_8(4)>
  if (loop_count_1 > 9)
    goto <bb 5>; [0.00%]
  else
    goto <bb 4>; [0.00%]

  <bb 4> [0.00%]:
  f4 (loop_count_1);
  loop_count_8 = loop_count_1 + 1;
  goto <bb 3>; [0.00%]

  <bb 5> [0.00%]:
  return;

}


gcc: which optimizations are applied/missed
---------------------------------------------
Print information when an optimization is successfully applied.
$ g++ -O3 -fopt-info-optimized=optimized.all  simple.cc -o /tmp/simple -lpthread -rdynamic;

File optimized.all:-
....
simple.cc:189:26: note: loop turned into non-loop; it never loops.
simple.cc:189:26: note: loop with 3 iterations completely unrolled
...
File simple.cc:-
189  for (uint32_t i = 0; i < IO_THREAD_COUNT; i++) {
190    int *return_value;
191    pthread_join(cpu_threads[i], (void **)&return_value);
192  }

you can see the loop was unrolled (use $g++  -O3 -fdump-tree-optimized=optimized.txt  simple.cc -o /tmp/simple -lpthread -rdynamic;): 
  io_threads_nums[0] = 0;
  pthread_create (&cpu_threads, 0B, cpu_thread_function, &io_threads_nums);
  io_threads_nums[1] = 1;
  pthread_create (&MEM[(void *)&cpu_threads + 8B], 0B, cpu_thread_function, &MEM[(void *)&io_threads_nums + 4B]);
  io_threads_nums[2] = 2;
  pthread_create (&MEM[(void *)&cpu_threads + 16B], 0B, cpu_thread_function, &MEM[(void *)&io_threads_nums + 8B]);
  __builtin_puts (&"io_threads are running ..."[0]);
  __builtin_puts (&"cpu_threads are running ..."[0]);
  _32 = cpu_threads[0];
  pthread_join (_32, &return_value);
  return_value ={v} {CLOBBER};
  _38 = cpu_threads[1];
  pthread_join (_38, &return_value);
  return_value ={v} {CLOBBER};
  _3 = cpu_threads[2];
  pthread_join (_3, &return_value);
  return_value ={v} {CLOBBER};
  io_threads_nums ={v} {CLOBBER};
  cpu_threads ={v} {CLOBBER};


Which optimizations are missed ?
$ g++ -O3 -fopt-info-missed=missed.all  simple.cc -o /tmp/simple -lpthread -rdynamic;

missed.all file:
...
simple.cc:191:17: note: not vectorized: not enough data-refs in basic block.
simple.cc:191:17: note: not vectorized: not enough data-refs in basic block.
simple.cc:191:17: note: not vectorized: not enough data-refs in basic block.
..

gcc: which optimizations are enabled/disbaled at -O3
-------------------------------------------------------
Ref: https://stackoverflow.com/questions/14737371/how-to-find-out-which-optimizations-are-actually-applied-when-using-gcc

use -Q --help=optimizers 
$ g++  -O3 -Q --help=optimizers  simple.cc -o /tmp/simple -lpthread -rdynamic;
The following options control optimizations:
  -O<number>                            
  -Ofast                                
  -Og                                   
  -Os                                   
  -faggressive-loop-optimizations       [enabled]
  -falign-functions                     [disabled]
  -falign-jumps                         [disabled]
  -falign-labels                        [enabled]
  -falign-loops                         [disabled]
  -fassociative-math                    [disabled]
  -fasynchronous-unwind-tables          [enabled]
  -fauto-inc-dec                        [enabled]
  -fbranch-count-reg                    [enabled]
  -fcaller-saves                        [enabled]
  -fcode-hoisting                       [enabled]
  -fcombine-stack-adjustments           [enabled]
  -fcompare-elim                        [enabled]
  -fcprop-registers                     [enabled]
  -fcrossjumping                        [enabled]
  -fcse-follow-jumps                    [enabled]
  ..
  -finline                              [enabled]
  -finline-atomics                      [enabled]
  -finline-functions                    [enabled]
  -finline-functions-called-once        [enabled]
  -finline-small-functions              [enabled]
  -fipa-bit-cp                          [enabled]
  -fipa-cp                              [enabled]
  -fipa-cp-clone                        [enabled]
  -fipa-icf                             [enabled]
  -fipa-icf-functions                   [enabled]
  -fipa-icf-variables                   [enabled]
  -fipa-profile                         [enabled]
  ..xs
=======================================================================
C++
--

g++ lock.cc -latomic; 

#include <iostream>
#include <utility>
#include <atomic>

struct A { int a[100]; };
struct B { int x, y; };
std::atomic<uint64_t> counter;
int main()
{

  // Ref: https://en.cppreference.com/w/cpp/atomic/atomic/is_lock_free
  std::cout << "std::atomic<uint64_t> is lock_free:"
            << std::atomic<uint64_t>{}.is_lock_free() <<  '\n';
  // prints std::atomic<uint64_t> is lock_free:1
  
  std::cout << std::boolalpha
            << "std::atomic<A> is lock free? "
            << std::atomic<A>{}.is_lock_free() << '\n'
            << "std::atomic<B> is lock free? "
            << std::atomic<B>{}.is_lock_free() << '\n';
}


std::atomic<uint64_t> is lock_free:1
std::atomic<A> is lock free? false
std::atomic<B> is lock free? true
=================================
* process statistics

ultrauser@krishna1:~/metadataserver$ cat /proc/`pidof mysqld`/limits
Limit                     Soft Limit           Hard Limit           Units     
Max cpu time              unlimited            unlimited            seconds   
Max file size             unlimited            unlimited            bytes     
Max data size             unlimited            unlimited            bytes     
Max stack size            8388608              unlimited            bytes     
Max core file size        unlimited            unlimited            bytes     
Max resident set          unlimited            unlimited            bytes     
Max processes             515531               515531               processes 
Max open files            40960                40960                files     
Max locked memory         16777216             16777216             bytes     
Max address space         unlimited            unlimited            bytes     
Max file locks            unlimited            unlimited            locks     
Max pending signals       515531               515531               signals   
Max msgqueue size         819200               819200               bytes     
Max nice priority         0                    0                    
Max realtime priority     0                    0                    
Max realtime timeout      unlimited            unlimited            us        
ultrauser@krishna1:~/metadataserver$ 
ultrauser@krishna1:~/metadataserver$ 
ultrauser@krishna1:~/metadataserver$ ps -o thcount `pidof mysqld`
THCNT
 1539
ultrauser@krishna1:~/metadataserver$ cat /proc/`pidof mysqld`/status
Name:	mysqld
Umask:	0026
State:	S (sleeping)
Tgid:	6605
Ngid:	6605
Pid:	6605
PPid:	1
TracerPid:	0
Uid:	1000	1000	1000	1000
Gid:	1000	1000	1000	1000
FDSize:	32768
Groups:	4 20 24 25 27 29 30 44 46 108 114 1000 
NStgid:	6605
NSpid:	6605
NSpgid:	6604
NSsid:	6604
VmPeak:	46608288 kB
VmSize:	40890216 kB
VmLck:	       0 kB
VmPin:	       0 kB
VmHWM:	10974620 kB
VmRSS:	10498824 kB
RssAnon:	10475160 kB
RssFile:	   23664 kB
RssShmem:	       0 kB
VmData:	12563588 kB
VmStk:	     136 kB
VmExe:	   50784 kB
VmLib:	   51008 kB
VmPTE:	   26964 kB
VmSwap:	       0 kB
HugetlbPages:	       0 kB
CoreDumping:	0
THP_enabled:	1
Threads:	1539 <-- Thread count
SigQ:	0/515531
SigPnd:	0000000000000000
ShdPnd:	0000000000000000
SigBlk:	0000000000084805
SigIgn:	0000000000003000
SigCgt:	0000000180000200
CapInh:	0000000000000000
CapPrm:	0000000000000000
CapEff:	0000000000000000
CapBnd:	0000003fffffffff
CapAmb:	0000000000000000
NoNewPrivs:	0
Seccomp:	0
Speculation_Store_Bypass:	vulnerable
Cpus_allowed:	ffffffff,ffffffff
Cpus_allowed_list:	0-63
Mems_allowed:	00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000003
Mems_allowed_list:	0-1
voluntary_ctxt_switches:	25684
nonvoluntary_ctxt_switches:	295
ultrauser@krishna1:~/metadataserver$ watch ps -o thcount `pidof mysqld`


Total number of threads used in all threads:
ultrauser@krishna1:~/metadataserver$ ps -eo nlwp | tail -n +2 | awk '{ num_threads += $1 } END { print num_threads }'
2519
ultrauser@krishna1:~/metadataserver$

Ref: https://stackoverflow.com/questions/268680/how-can-i-monitor-the-thread-count-of-a-process-on-linux

==============================
Approach to find issues
-----------------------

while running the performance or stress test: capture performance results and stats together continuously.
This helps in identifying issues more easily:- eg., memory growing over time, CPU difference, kernel buffers growing etc.,

Eg.,
  cd scripts
  ./automate_perf_runs.sh <-- this runs sysbench on remote host. also starts running periodic_stats_collector.sh

the script periodic_stats_collector.sh collects these periodically:-
ssh ${adminUser}@$hostip1 'bash -s' <<EOF
  sleep 60
  TERM=dumb
  while true; do
   sleep 60
   date
   echo "free -m"
   free -m
   echo "vmstat --timestamp  --wide 2 3"
   vmstat --timestamp  --wide 2 3
   echo "iostat -xmc -y 2 3"
   iostat -xmc -y 2 3
   echo "dstat -a 2 3"
   dstat -a 2 3
   echo "nping --tcp -p 22 10.0.0.4"
   echo "page faults: pid,min_flt,maj_flt,cmd"
   ps -o pid,min_flt,maj_flt,cmd -A | grep mysqld
   ...

Sample output:- here we see sysbench and Linux stats simultaniously together continously.


Threads started!

[ 10s ] thds: 300 tps: 114800.08 qps: 114800.08 (r/w/o: 81776.22/21615.48/11408.38) lat (ms,95%): 6.91 err/s: 0.00 reconn/s: 0.00
Thu May 27 02:17:30 UTC 2021
free -m
              total        used        free      shared  buff/cache   available
Mem:          64320       11911       49131           1        3276       51720
Swap:             0           0           0
vmstat --timestamp  --wide 2 3
procs -----------------------memory---------------------- ---swap-- -----io---- -system-- --------cpu-------- -----timestamp-----
 r  b         swpd         free         buff        cache   si   so    bi    bo   in   cs  us  sy  id  wa  st                 UTC
 0  0            0     50310720      2136268      1219296    0    0    30  1434  779   49  23  13  64   0   0 2021-05-27 02:17:30
92  1            0     50308812      2136328      1219308    0    0     4 33962 395047 513989  53  30  16   0   0 2021-05-27 02:17:32
[ 20s ] thds: 300 tps: 133588.95 qps: 133588.95 (r/w/o: 95274.58/25088.78/13225.59) lat (ms,95%): 6.79 err/s: 0.00 reconn/s: 0.00
64  1            0     50311296      2136384      1219344    0    0     4 34716 400445 514116  55  31  14   0   0 2021-05-27 02:17:34
iostat -xmc -y 2 3
Linux 5.4.0-1047-azure (replica1) 	05/27/21 	_x86_64_	(32 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          28.20    0.00   15.57    0.20    0.00   56.02

Device            r/s     w/s     rMB/s     wMB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00
sda              0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00
sdb              1.00  200.00      0.00      9.25     0.00    16.50   0.00   7.62    0.50    7.98   1.29     4.00    47.36   0.55  11.00
sdc              0.00  516.00      0.00     10.46     0.00  2150.00   0.00  80.65    0.00    0.64   0.00     0.00    20.76   1.02  52.60
sdd              0.00  879.50      0.00     13.62     0.00     0.00   0.00   0.00    0.00   12.61   9.32     0.00    15.86   0.15  13.40

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          54.49    0.00   30.10    0.29    0.00   15.12

Device            r/s     w/s     rMB/s     wMB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00
sda              0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     0.00     0.00   0.00   0.00
sdb              1.50   86.00      0.01     31.46     0.00    31.00   0.00  26.50   33.00   33.30   2.78     4.00   374.58   3.79  33.20
sdc              0.00  846.00      0.00     19.37     0.00  4111.00   0.00  82.93    0.00    0.72   0.00     0.00    23.44   1.10  92.80
sdd              0.00  868.50      0.00     13.48     0.00     0.00   0.00   0.00    0.00   10.08   6.97     0.00    15.90   0.12  10.80

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          55.20    0.00   30.81    0.27    0.00   13.72

  






=====================================
GOOD approach to find the CPU bottleneck
===========================================
Need to find the hot CPU core and the code running it

GOOD 0) pidstat is a very good tool to view by thread CPU, IO, faults, stack etc.,
-----------------------------------------------------------------------
Ref: https://www.percona.com/blog/2020/04/23/a-simple-approach-to-troubleshooting-high-cpu-in-mysql/ this finds the hot cpu and corresponding MySQL query (percona enhancement)

-p Select tasks (processes) for which statistics are to be  reported.
-d I/O, -w  task switching activity, -s Report stack utilization, -R Report realtime priority and scheduling policy information, -r Report page faults and memory utilization,  -v Report values of some kernel tables

$  pidstat -h  -d -w -s -u -R -r -v  -t -p 27298 1
Linux 5.4.0-92-generic (narwhal) 	01/16/2022 	_x86_64_	(16 CPU)

# Time        UID      TGID       TID    %usr %system  %guest   %wait    %CPU   CPU  minflt/s  majflt/s     VSZ     RSS   %MEM StkSize  StkRef   kB_rd/s   kB_wr/s kB_ccwr/s iodelay   cswch/s nvcswch/s threads   fd-nr prio policy  Command
04:23:11 PM  1000     27298         -    2.69    1.08    0.00    0.00    3.76    10      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0      0.00      0.00      98      54    0 NORMAL  mysqld-vml
04:23:11 PM  1000         -     27298    0.00    0.00    0.00    0.00    0.00    10      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0      0.00      0.00      98      54    0 NORMAL  |__mysqld-vml
04:23:11 PM  1000         -     27299    0.00    0.00    0.00    0.00    0.00    12      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0      0.00      0.00      98      54    0 NORMAL  |__mysqld-vml-ust
04:23:11 PM  1000         -     27371    0.54    0.00    0.00    0.54    0.54     5      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0     97.85      0.00      98      54    0 NORMAL  |__mysqld-vml
04:23:11 PM  1000         -     27372    0.54    0.00    0.00    0.00    0.54    13      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0     97.85      0.00      98      54    0 NORMAL  |__mysqld-vml
04:23:11 PM  1000         -     27373    0.54    0.00    0.00    0.00    0.54     5      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0     97.85      0.00      98      54    0 NORMAL  |__mysqld-vml
04:23:11 PM  1000         -     27374    0.54    0.00    0.00    0.00    0.54     7      0.00      0.00 7835376  445856   1.85     132      56      0.00      0.00      0.00       0     97.85      0.00      98      54    0 NORMAL  |__mysqld-vml



1) First find the hot thread that is busy (usually not all threads are busy)
-----------------------------------------------------------------------------


outside emacs:-
This will 
$ top -H
Press "f" -> select "P" and hit enter  -> ESC
press "1" to cpus as well 
Ref: https://www.cs.swarthmore.edu/~newhall/unixhelp/top.php

top - 00:02:08 up 43 min,  4 users,  load average: 139.43, 114.62, 62.71
Threads: 788 total,  26 running, 684 sleeping,   0 stopped,   1 zombie
%Cpu0  : 63.3 us, 25.4 sy,  0.0 ni,  0.4 id,  0.4 wa,  0.0 hi, 10.4 si,  0.0 st
%Cpu1  : 63.5 us, 24.6 sy,  0.0 ni,  0.7 id,  0.2 wa,  0.0 hi, 11.1 si,  0.0 st
%Cpu2  : 60.4 us, 27.6 sy,  0.0 ni,  0.9 id,  0.0 wa,  0.0 hi, 11.1 si,  0.0 st
%Cpu3  : 63.9 us, 25.9 sy,  0.0 ni,  1.1 id,  0.0 wa,  0.0 hi,  9.1 si,  0.0 st
KiB Mem : 16398256 total,   176588 free, 11185804 used,  5035864 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  4880832 avail Mem

   Thread                                                                    CPU core
   |                                                                             |   
  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND       P
 7386 narwhal   20   0 12.558g 0.010t  35956 R  4.3 64.9   3:41.62 mysqld-vml    3 <-- PID 7386, CPU 4.3, CPU 3
 9865 narwhal   20   0   45328   4712   3336 R  2.0  0.0   0:10.03 top           2
 7364 narwhal   20   0 12.558g 0.010t  35956 S  1.8 64.9   0:06.21 mysqld-vml    2
10075 narwhal   20   0 12.558g 0.010t  35956 S  1.8 64.9   0:06.90 mysqld-vml    1
10116 narwhal   20   0 12.558g 0.010t  35956 S  1.8 64.9   0:06.85 mysqld-vml    2
 7387 narwhal   20   0 12.558g 0.010t  35956 D  1.6 64.9   0:31.76 mysqld-vml    1
 9952 narwhal   20   0 12.558g 0.010t  35956 S  1.6 64.9   0:06.86 mysqld-vml    1
 9986 narwhal   20   0 12.558g 0.010t  35956 S  1.6 64.9   0:06.82 mysqld-vml    3
 9996 narwhal   20   0 12.558g 0.010t  35956 S  1.6 64.9   0:06.92 mysqld-vml    1
10006 narwhal   20   0 12.558g 0.010t  35956 S  1.6 64.9   0:06.93 mysqld-vml    0
10021 narwhal   20   0 12.558g 0.010t  35956 S  1.6 64.9   0:06.97 mysqld-vml    1
10022 narwhal   20   0 12.558g 0.010t  35956 S  1.6 64.9   0:06.85 mysqld-vml    1



find the hot thread perf report and code
--------------------------------------
-t thread id
-F frequency 50HZ (low overhead)
 perf record -F50   --call-graph dwarf -g -t  10160 sleep 10

perf report  --call-graph ,,,,caller -g folded --stdio | cat
   # Samples: 487  of event 'cpu-clock:pppH'
   # Event count (approx.): 9740000000
   #
   # Children      Self  Command     Shared Object        Symbol                                                                                                       
   # ........  ........  ..........  ...................  .............................................................................................................
   #
       95.07%    23.61%  mysqld-vml  mysqld-vml           [.] log_writer <-- log_writer self 23.61% children:95%
Children are listed below nicely -->       
   53.39% log_writer;log_advance_ready_for_write_lsn
   23.61% clone (inlined);start_thread;0x7f2df086a6de;std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, void (*)(log_t*), log_t*> > >::_M_run;log_writer
   11.09% log_writer;ThreadQuiesce::should_quiesce
   1.64% log_writer;log_files_write_buffer;os_event_set;__pthread_cond_broadcast (inlined);futex_wake (inlined);entry_SYSCALL_64_after_hwframe;do_syscall_64;__x64_sys_futex;do_futex;futex_wake;wake_up_q;try_to_wake_up;_raw_spin_unlock_irqrestore
   0.62% log_writer;log_files_write_buffer;fil_redo_io;Fil_shard::do_redo_io;os_file_write_page;os_file_io;vml_pwrite64
   
   
old 
Use perf to capture CPU of the hot thread : 7386
  $ sudo  perf record --call-graph dwarf -g -p 7386 sleep 5

narwhal@replica1:~$ sudo perf report --stdio

$ sudo perf report --stdio
 or outside emacs
$  perf report  <-- nice


# Samples: 18K of event 'cpu-clock:pppH'
# Event count (approx.): 4572000000
#
# Children      Self  Command     Shared Object        Symbol                        # ........  ........  ..........  ...................  ..............................#
    68.33%     0.00%  mysqld-vml  [unknown]            [.] 0xffffffffffffffff
            |
            ---0xffffffffffffffff
               |          
               |--53.26%--dispatch_command
               |          |          
               |          |--44.46%--mysqld_stmt_execute
               |          |          Prepared_statement::execute_loop
               |          |          Prepared_statement::execute
               |          |          mysql_execute_command
               |          |          |          
               |          |          |--24.23%--Sql_cmd_dml::execute
               |          |          |          |          
               |          |          |          |--12.29%--Sql_cmd_dml::execute_inner               |          |          |          |          |          
               |          |          |          |          |--7.26%--SELECT_LEX::opti               |          |          |          |          |          |          
...skipping...


find the hot pid code stack (collects few times and summarizes)
-----------------------------------------------------------------


GOOD https://www.percona.com/blog/2017/04/05/evaluation-of-profiling-tools-for-pmp/
time quickstack  -c 100000 --single_line -p `pidof mysqld-vml` > junk.txt

time quickstack  -c 1000  -p `pidof mysqld-vml` > junk.txt

real	0m3.031s
user	0m1.323s
sys	0m1.108s

time quickstack  -c 1000 --single_line  -p `pidof mysqld-vml` > junk.txt

real	0m1.031s
user	0m0.348s
sys	0m0.295s


Don't resolve symbols

$ time eu-stack -q -p 59961 > junk1.txt

real	0m0.230s
user	0m0.037s
sys	0m0.182s
# use this to resolve symbols
eu-addr2line 0x00007f2257d2b61f -p 59961 --functions  --pretty-print
__clone at ../sysdeps/unix/sysv/linux/x86_64/clone.S:97

TODO REF: https://stackoverflow.com/questions/12394935/getting-stacktrace-of-all-threads-without-attaching-gdb
V.GOOD 5.6 eu-stack https://developpaper.com/profiling-and-performance-optimization-summary/ https://github.com/brendangregg/FlameGraph



eu-stack Print a stack for each thread in a process or core file.
narwhal@narwhal:~/orcasql-mysql/automation_scripts$ time eu-stack -p 59961
PID 59961 - process
TID 59961:
#0  0x00007f2257d1ebb9 __poll
#1  0x000056417d853c2a Mysqld_socket_listener::listen_for_connection_event()
#2  0x000056417d65f130 mysqld_main(int, char**)
#3  0x00007f2257c2bc87 __libc_start_main
#4  0x000056417d64a30a _start


V.GOOD V.GOOD


Ref: http://poormansprofiler.org/

Rationale:- Sampling tools like oprofile or dtrace's profile provider don't really provide methods to see what [multithreaded] programs are blocking on - only where they spend CPU time. Though there exist advanced techniques (such as systemtap and dtrace call level probes), it is overkill to build upon that. Poor man doesn't have time. Poor man needs food.

Method:- For a poor developer to understand what a program is doing, he needs to see stacks. Once upon a time (back in Linux 2.4) there was a 'pstack' tool for that, Solaris has it too.
Modern Linux systems though do not have such facilities, and one needs to improvise, like.. use debuggers - they can walk threads and provide stacks.

Sample output:- shows where multiple threads are blocked on (during multiple snapshots)

bash -x ~/linux_perf_cheatsheet/scripts/gdb_poor_man_stacks.sh 
    400  in futex_abstimed_wait_cancelable <-- __pthread_cond_wait_common in mutex=, <-- __pthread_cond_timedwait in mutex=, <--  in __gthread_cond_timedwait <-- std::condition_variable::__wait_until_impl<std::chrono::duration<long, in l> <-- std::condition_variable::wait_until<std::chrono::duration<long, in l> <-- vml::ConcurrentQueue<vml::PfsRequestData>::WaitAndPop in pointer>: <-- vml::PfsQueue::Pop in at <--  in vml::ThreadPoolThread<vml::PfsIoRequest, <--  in ?? <--  in start_thread <--  in clone
     37  in ?? <--  in weak_io_getevents <--  in vml::AioQueue::Pop <--  in vml::ThreadPoolThread<iocb, <--  in ?? <--  in start_thread <--  in clone
     10  in futex_abstimed_wait_cancelable <-- __pthread_cond_wait_common in mutex=, <-- __pthread_cond_timedwait in mutex=, <--  in __gthread_cond_timedwait <-- std::condition_variable::__wait_until_impl<std::chrono::duration<long, in l> <-- std::condition_variable::wait_until<std::chrono::duration<long, in l> <-- std::condition_variable::wait_until<std::chrono::_V::system_clock, in int, <-- std::condition_variable::wait_for<long in std::ratio<, <-- vml_io_getevents in out>, <--  in LinuxAIOHandler::collect <--  in LinuxAIOHandler::poll <--  in os_aio_linux_handler <-- os_aio_handler in m=m@entry=, <--  in fil_aio_wait <--  in io_handler_thread <--  in std::__invoke_impl<void, <-- std::__invoke<void in long), <-- std::_Bind<void in long))(unsigned <-- std::_Bind<void in long))(unsigned <-- Runnable::operator()<void in long), <-- std::__invoke_impl<void, in void <-- std::__invoke<Runnable, in (*)(unsigned <-- std::thread::_Invoker<std::tuple<Runnable, in (*)(unsigned <-- std::thread::_Invoker<std::tuple<Runnable, in (*)(unsigned <-- std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, in (*)(unsigned <--  in ?? <--  in start_thread <--  in clone

more gdb_poor_man_stacks.sh:-


#!/bin/bash
nsamples=1
sleeptime=0
pid=$(pidof mysqld-vml)

for x in $(seq 1 $nsamples)
do
  gdb -ex "set pagination 0" -ex "thread apply all bt" -batch -p $pid
  sleep $sleeptime
done | \
awk '
  BEGIN { s = ""; }
  /^Thread/ { print s; s = ""; }
  /^\#/ { fn= $2 " in " $4;  gsub(/0x[0-f]+/, "",fn);  gsub(/[0-9]+/, "",fn);  if (s != "" ) { s = s " <-- " fn} else { s = fn} }
  END {gsub(/[[:blank:]]/, "", s); print s }' | \
sort | uniq -c | sort -r -n -k 1,1




#system("eu-addr2line $2 -p 59961 --functions  --pretty-print");

sample stack (just for reference)
  gdb -ex "set pagination 0" -ex "thread apply all bt" -batch -p 59961

  Thread 440 (Thread 0x7f1f55b6d700 (LWP 60409)):
  #0  0x00007f2259fb1065 in futex_abstimed_wait_cancelable (private=<optimized out>, abstime=0x7f1f55b62150, expected=0, futex_word=0x7f2194364688) at ../sysdeps/unix/sysv/linux/futex-internal.h:205
  #1  __pthread_cond_wait_common (abstime=0x7f1f55b62150, mutex=0x7f2194364638, cond=0x7f2194364660) at pthread_cond_wait.c:539
  #2  __pthread_cond_timedwait (cond=0x7f2194364660, mutex=0x7f2194364638, abstime=0x7f1f55b62150) at pthread_cond_wait.c:667
  #3  0x00007f2259a9c6d4 in __gthread_cond_timedwait (__abs_timeout=0x7f1f55b62150, __mutex=<optimized out>, __cond=0x7f2194364660) at /usr/include/x86_64-linux-gnu/c++/7/bits/gthr-default.h:871
  #4  std::condition_variable::__wait_until_impl<std::chrono::duration<long, std::ratio<1l, 1000000000l> > > (__atime=..., __lock=..., this=0x7f2194364660) at /usr/include/c++/7/condition_variable:178
  #5  std::condition_variable::wait_until<std::chrono::duration<long, std::ratio<1l, 1000000000l> > > (__atime=..., __lock=..., this=0x7f2194364660) at /usr/include/c++/7/condition_variable:106
  #6  vml::ConcurrentQueue<vml::PfsRequestData>::WaitAndPop (hasMore=<synthetic pointer>: <optimized out>, timeoutsecs=5, this=0x7f21943645e8) at /home/narwhal/orcasql-mysql/extra/vml/main/src/include/ConcurrentQueue.h:40
  #7  vml::PfsQueue::Pop (this=0x7f21943645c0) at /home/narwhal/orcasql-mysql/extra/vml/main/src/handlers/PfsRestHandler.cc:332
  #8  0x00007f2259aa7464 in vml::ThreadPoolThread<vml::PfsIoRequest, vml::PfsEvents, vml::PfsQueue>::DoWork (this=0x7f2194375370, threadPool=0x7f219436e160) at /home/narwhal/orcasql-mysql/extra/vml/main/src/include/ThreadPool.h:283
  #9  0x00007f225866e6df in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
  #10 0x00007f2259faa6db in start_thread (arg=0x7f1f55b6d700) at pthread_create.c:463
  #11 0x00007f2257d2b61f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
  

OLD  OLD
291 pthread_cond_wait@@GLIBC_2.3.2,one_thread_per_connection_end,handle_one_connection
57 read,my_real_read,my_net_read,do_command,handle_one_connection,start_thread
26 pthread_cond_wait@@GLIBC_2.3.2,os_event_wait_low,os_aio_simulated_handle,fil_aio_wait,io_handler_thread,start_thread
3 pthread_cond_wait@@GLIBC_2.3.2,os_event_wait_low,srv_purge_worker_thread
1 select,os_thread_sleep,srv_purge_thread
1 select,os_thread_sleep,srv_master_thread
1 select,os_thread_sleep,srv_lock_timeout_and_monitor_thread
1 select,os_thread_sleep,srv_error_monitor_thread
1 pread64,os_file_pread,os_file_read,fil_io,buf_read_page_low,buf_read_page,buf_page_get_gen,btr_cur_search_to_nth_level,row_search_index_entry,row_upd_step,row_update_for_mysql,ha_innodb::delete_row,handler::ha_delete_row,mysql_delete,mysql_execute_command,mysql_parse,Query_log_event::do_apply_event,apply_event_and_update_pos,handle_slave_sql
1 pread64,os_file_pread,os_file_read,fil_io,buf_read_page_low,buf_read_page,buf_page_get_gen,btr_cur_search_to_nth_level,row_search_for_mysql,ha_innodb::index_read,handler::index_read_idx_map,join_read_const,join_read_const_table,make_join_statistics,JOIN::optimize,mysql_select,handle_select,execute_sqlcom_select,mysql_execute_command,mysql_parse,dispatch_command,do_command,handle_one_connection
1 do_sigwait,sigwait,signal_hand
                        
Full technology demonstration:-

#!/bin/bash
nsamples=1
sleeptime=0
pid=$(pidof mysqld)

for x in $(seq 1 $nsamples)
do
  gdb -ex "set pagination 0" -ex "thread apply all bt" -batch -p $pid
  sleep $sleeptime
done | \
awk '
  BEGIN { s = ""; }
  /^Thread/ { print s; s = ""; }
  /^\#/ { if (s != "" ) { s = s "," $4} else { s = $4 } }
  END { print s }' | \
sort | uniq -c | sort -r -n -k 1,1

find the hot pid code stack (collect few times )
--------------------------------------------------

V.GOOD
pidof mysqld-vml | xargs -n1 sudo gdb --batch -ex "thread apply all bt" -p

(or)

  sudo gdb  /home/narwhal/mysql/bin/mysqld-vml
  set width 0
  set height 0
  set pagination no
  set confirm off
  attach 7386
  thread apply all bt
  detach
  quit
  

Thread 1 (Thread 0x7f580061a700 (LWP 7386)):
#0  Link_buf<unsigned long>::advance_tail_until<log_advance_ready_for_write_lsn(log_t&)::<lambda(lsn_t, lsn_t)> > (stop_condition=..., this=0x7f5a94433d00) at /home/narwhal/orcasql-mysql/storage/innobase/include/ut0link_buf.h:293
#1  log_advance_ready_for_write_lsn (log=...) at /home/narwhal/orcasql-mysql/storage/innobase/log/log0buf.cc:1190
#2  0x0000564547e9e688 in <lambda(bool)>::operator() (wait=<optimized out>, __closure=<optimized out>) at /home/narwhal/orcasql-mysql/storage/innobase/log/log0write.cc:2392
#3  os_event_wait_for<log_writer(log_t*)::<lambda(bool)> > (condition=..., timeout=<optimized out>, spins_limit=<optimized out>, event=<synthetic pointer>: <optimized out>) at /home/narwhal/orcasql-mysql/storage/innobase/include/os0event.ic:86
#4  Log_thread_waiting::wait<log_writer(log_t*)::<lambda(bool)> > (stop_condition=..., this=<synthetic pointer>) at /home/narwhal/orcasql-mysql/storage/innobase/log/log0write.cc:1097
#5  log_writer (log_ptr=0x7f5a94433c40) at /home/narwhal/orcasql-mysql/storage/innobase/log/log0write.cc:2424
#6  0x0000564547e5ed7c in std::__invoke_impl<void, void (*&)(log_t*), log_t*&> (__f=<optimized out>) at /usr/include/c++/7/bits/invoke.h:60
#7  std::__invoke<void (*&)(log_t*), log_t*&> (__fn=<synthetic pointer>: <optimized out>) at /usr/include/c++/7/bits/invoke.h:95
#8  std::_Bind<void (*(log_t*))(log_t*)>::__call<void, , 0ul>(std::tuple<>&&, std::_Index_tuple<0ul>) (__args=..., this=<synthetic pointer>) at /usr/include/c++/7/functional:467
#9  std::_Bind<void (*(log_t*))(log_t*)>::operator()<, void>() (this=<synthetic pointer>) at /usr/include/c++/7/functional:551
#10 Runnable::operator()<void (*)(log_t*), log_t*> (f=@0x7f5a9454a4a0: 0x564547e9e430 <log_writer(log_t*)>, this=0x7f5a9454a4a8) at /home/narwhal/orcasql-mysql/storage/innobase/include/os0thread-create.h:92
#11 std::__invoke_impl<void, Runnable, void (*)(log_t*), log_t*> (__f=...) at /usr/include/c++/7/bits/invoke.h:60
#12 std::__invoke<Runnable, void (*)(log_t*), log_t*> (__fn=...) at /usr/include/c++/7/bits/invoke.h:95
#13 std::thread::_Invoker<std::tuple<Runnable, void (*)(log_t*), log_t*> >::_M_invoke<0ul, 1ul, 2ul> (this=0x7f5a9454a498) at /usr/include/c++/7/thread:234
#14 std::thread::_Invoker<std::tuple<Runnable, void (*)(log_t*), log_t*> >::operator() (this=0x7f5a9454a498) at /usr/include/c++/7/thread:243
#15 std::thread::_State_impl<std::thread::_Invoker<std::tuple<Runnable, void (*)(log_t*), log_t*> > >::_M_run (this=0x7f5a9454a490) at /usr/include/c++/7/thread:186
#16 0x00007f5adbe206df in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#17 0x00007f5add8ba6db in start_thread (arg=0x7f580061a700) at pthread_create.c:463
#18 0x00007f5adb4dd71f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
(gdb) Detaching from program: /home/narwhal/mysql/bin/mysqld-vml, process 7386

====================================
CPU and thread timechart GOOD
-------------------------
You can see over time line:
 - on each CPU: which processes are running. Is CPU sleeping, blocked on IO
 - For each process thread: see when it is running, idle, sleeping, waiting for cpum blocked on io

Record for short time say 1-2 seconds (other wise hard to see the svg graph browser will not show it properly)
To capture:
sudo rm perf.data output.svg; sudo perf timechart record  sleep 2
[ perf record: Woken up 65 times to write data ]
[ perf record: Captured and wrote 17.979 MB perf.data (176856 samples) ] <-- if too any points. browser can't render svg file. better to have less than 50k points

To generate graph use this:
svg image will have width of 100L
narwhal@narwhal:~$ sudo perf timechart --width=100000   | cat
Written 2.0 seconds of trace to output.svg.


start webserver
  python -m SimpleHTTPServer 8080
For browser open svg file:
  http://10.34.178.64:8080/output.svg

To view it using ascii use this :
sudo perf script | less

         Swapper means idle        Time stamp
          |         PID  CPU number |         event name          event params--->
          v          v    |         |         |
         swapper     0 [002] 1547661.907140:  sched:sched_wakeup: comm=simple pid=22393 prio=120 target_cpu=002
         Above says simple thread 22393  wakes up CPU 2, which causes an idle exist.
        
         swapper     0 [002] 1547661.907321:  sched:sched_wakeup: comm=simple pid=22393 prio=120 target_cpu=002
         swapper     0 [002] 1547661.907500:  sched:sched_wakeup: comm=simple pid=22393 prio=120 target_cpu=002
         swapper     0 [002] 1547661.907680:  sched:sched_wakeup: comm=simple pid=22393 prio=120 target_cpu=002
         ..
         simple 22393 [002] 1547661.907887:  sched:sched_switch: prev_comm=simple prev_pid=22393 prev_prio=120 prev_state=S ==> next_comm=swapper/2 next_pid=0 next_prio=120
         I think above says simple thread went to sleep and CPU 2 is context switched to idle "swapper" 


You can follow a thread as follows
narwhal@narwhal:~$ sudo perf script | grep 22393 | more
         swapper     0 [002] 1547661.907871:  sched:sched_switch: prev_comm=swapper/2 prev_pid=0 prev_prio=120 prev_state=R ==> next_comm=simple next_pid=22393 next_prio=120
          simple 22393 [002] 1547661.907887:  sched:sched_switch: prev_comm=simple prev_pid=22393 prev_prio=120 prev_state=S ==> next_comm=swapper/2 next_pid=0 next_prio=120
         swapper     0 [002] 1547661.908041:  sched:sched_wakeup: comm=simple pid=22393 prio=120 target_cpu=002
         swapper     0 [002] 1547661.908052:  sched:sched_switch: prev_comm=swapper/2 prev_pid=0 prev_prio=120 prev_state=R ==> next_comm=simple next_pid=22393 next_prio=120
          simple 22393 [002] 1547661.908066:  sched:sched_switch: prev_comm=simple prev_pid=22393 prev_prio=120 prev_state=S ==> next_comm=swapper/2 next_pid=0 next_prio=120
         swapper     0 [002] 1547661.908221:  sched:sched_wakeup: comm=simple pid=22393 prio=120 target_cpu=002
         swapper     0 [002] 1547661.908232:  sched:sched_switch: prev_comm=swapper/2 prev_pid=0 prev_prio=120 prev_state=R ==> next_comm=simple next_pid=22393 next_prio=120

Above Ref: https://learning.oreilly.com/library/view/energy-efficient-servers/9781430266389/9781430266372_Ch07.xhtml#Sec11

To view the stack trace of the hot thread use these:
  - See: find the hot pid code stack (collect few times )
  - see: find the hot pid perf report and code
==========================================================================================
Disabling a hyperthreaded core

# echo "0" > /sys/devices/system/cpu/cpu3/online
bash: echo: write error: Device or resource busy

Need to disable at boot time or ?
https://unix.stackexchange.com/questions/417672/how-to-disable-one-cpu


===========================
Changing thread priority

 Ref: https://stackoverflow.com/questions/3649281/how-to-increase-thread-priority-in-pthreads
 Ref: https://www.geeksforgeeks.org/chrt-command-in-linux-with-examples/

 $chrt -m
 SCHED_OTHER min/max priority    : 0/0
 SCHED_FIFO min/max priority     : 1/99
 SCHED_RR min/max priority       : 1/99
 SCHED_BATCH min/max priority    : 0/0
 SCHED_IDLE min/max priority     : 0/0



'Normal' scheduling policies: (from sched_setscheduler(2))

   SCHED_OTHER   the standard round-robin time-sharing policy;
   SCHED_BATCH   for "batch" style execution of processes; and
   SCHED_IDLE    for running very low priority background jobs.

Real-time scheduling policies:
   SCHED_FIFO    a first-in, first-out policy; and
   SCHED_RR      a round-robin policy.
===========================

disabling hyperthreading did not work on Azure
--------------------------------------------------

Otheroption is using "taskset", move critical processes on a core and non-critical process out of that coreSwitchback GTX Mittens - Men's
REF: https://serverfault.com/questions/235825/disable-hyperthreading-from-within-linux-no-access-to-bios

changin grub maxcpus=2 did not work
---------------------------------------
Ref: https://unix.stackexchange.com/questions/417672/how-to-disable-one-cpu
cat /etc/default/grub

GRUB_CMDLINE_LINUX_DEFAULT="quiet splash maxcpus=2"

sudo update-grub
reboot

   $ grep . /sys/devices/system/cpu/cpu*/online
   /sys/devices/system/cpu/cpu1/online:1
   /sys/devices/system/cpu/cpu2/online:1
   /sys/devices/system/cpu/cpu3/online:1

Setting /sys/devices/system/cpu/cpu3/online is failing
--------------------------------------------------------
   
   $ grep . /sys/devices/system/cpu/cpu*/online
   /sys/devices/system/cpu/cpu1/online:1
   /sys/devices/system/cpu/cpu2/online:1
   /sys/devices/system/cpu/cpu3/online:1
   narwhal@replica1:~/performance/tools$ sudo bash
   root@replica1:~/performance/tools# echo "0" > /sys/devices/system/cpu/cpu3/online
   bash: echo: write error: Device or resource busy
   root@replica1:~/performance/tools# grep . /sys/devices/system/cpu/cpu*/online
   /sys/devices/system/cpu/cpu1/online:1
   /sys/devices/system/cpu/cpu2/online:1
   /sys/devices/system/cpu/cpu3/online:1

=================================================
GOOD gdb tracing:  dprintf fast tracing
--------------------------------------
This prints inline. you can also log to a file (need to find exact steps)

WORKS GOOD: m_filePath is a C++ string
gdb -p $(pgrep -n mysqld-vml) -batch  -ex 'dprintf vml::FileChunkHandlerLinux::PerformIoInternal,"File:%s offset=%d, bytes=%d foo\n",*(char**)  &m_filePath, ioRequest->offset,  ioRequest->numBytes' -ex 'continue'

C++ string print like this: %s and *(char**)  &m_filePath
  Ref: https://stackoverflow.com/questions/6776961/how-to-inspect-stdstring-in-gdb-with-no-source-code

How to print timestamp for every log: DID not find an answer.
  http://mysqlentomologist.blogspot.com/2019/11/dynamic-tracing-of-mysql-server-with.html
  (gdb) set height 0
  (gdb) set log on
  Copying output to gdb.txt.
  (gdb) b dispatch_command
  Breakpoint 1 at 0xbe9660: file /mnt/workspace/percona-server-5.7-debian-binary-rocks-new/label_exp/min-xenial-x64/test/percona-server-5.7-5.7.28-31/sql/sql_parse.cc, line 1254.
  (gdb) command 1
  Type commands for breakpoint(s) 1, one per line.
  End with a line saying just "end".
  >shell date >> ./gdb.txt <-- uses shell date. for nanosecond use date +'%H:%m:%S.%N' 
  >p com_data->com_query.query
  >continue
  >end
  (gdb) continue
  
(gdb) set debug timestamp <-- not working

You can even log to a file or stdout
Ref: https://doc.ecoscentric.com/gnutools/doc/gdb/Dynamic-Printf.html
(gdb) set dprintf-style call
(gdb) set dprintf-function fprintf
(gdb) set dprintf-channel mylog <-- this is fp defined in code
(gdb) dprintf 25,"at line 25, glob=%d\n",glob
Dprintf 1 at 0x123456: file main.c, line 25.
(gdb) info break
1       dprintf        keep y   0x00123456 in main at main.c:25
  call (void) fprintf (mylog,"at line 25, glob=%d\n",glob
  continue
(gdb)


===================================================
gdb tracing:  tracepoints (you can trace only ints. no C++ strings, pointers)
----------------------------------------

tracepoints work only with gdbserver
 Ref: https://sourceware.org/gdb/onlinedocs/gdb/Set-Tracepoints.html#Set-Tracepoints
 Ref: https://suchakra.wordpress.com/2016/06/29/fast-tracing-with-gdb/

# stop all processed
kill -9 $(pgrep -n mysqld-vml);killall -9 gdb

#start mysqld-vml process and attach gdbserver to it
gdbserver :12345 --attach $(pgrep -n mysqld-vml)


# start gdb and connect to gdbserver
gdb ./out/runtime_output_directory/mysqld-vml
target remote :12345

//m_filePath is a C++ string
(gdb) trace FileChunkHandlerLinux::PerformIoInternal
action 
collect ioRequest->offset
collect ioRequest->numBytes
end
// C++ / string / memory pointers don't work
// collect *(char**)  &m_filePath
// info trace
//(gdb) delete trace       // remove all tracepoints
set height 0
set trace-buffer-size unlimited
# start tracing
tstart
# allow tracing after disconnecting to gdbserver
set disconnected-tracing on
detach
Trace is running and will continue after detach; detach anyway? (y or n) y

<now run tests>

#again connect
target remote :12345
# stop tracing
tstop
# now dump the traces collected
set height 0
tfind start
while ($trace_frame != -1)
 printf "offset:%d, bytes:%d\n",  ioRequest->offset, ioRequest->numBytes
 tfind 
end

//printf "chunk:%s, offset:%d, bytes:%d\n", *(char**)m_filePath, ioRequest->offset, ioRequest->numBytes
Sample output:-
  Found trace frame 22, tracepoint 1
  offset:16777728, bytes:512
  Found trace frame 23, tracepoint 1
  offset:0, bytes:0
  Found trace frame 24, tracepoint 1
  offset:1048576, bytes:16384
  Found trace frame 25, tracepoint 1
  offset:0, bytes:0
  Found trace frame 26, tracepoint 1
  offset:117522432, bytes:16384
  Found trace frame 27, tracepoint 1
  offset:0, bytes:0
  Found trace frame 28, tracepoint 1
  offset:0, bytes:0
  Found trace frame 29, tracepoint 1
  offset:16778752, bytes:512
  Found trace frame 30, tracepoint 1
  offset:0, bytes:0
  
========================================
* network optimization

https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-tcpip-performance-tuning

 ethtool -K eth0 tso on // turn on large_send on


ethtool -k  eth0| grep -i offload
tcp-segmentation-offload: on <-- tso
udp-fragmentation-offload: off
generic-segmentation-offload: on
generic-receive-offload: on
large-receive-offload: on
rx-vlan-offload: on [fixed]
tx-vlan-offload: on [fixed]
l2-fwd-offload: off [fixed]
hw-tc-offload: off [fixed]
esp-hw-offload: off [fixed]
esp-tx-csum-hw-offload: off [fixed]
rx-udp_tunnel-port-offload: off [fixed]
tls-hw-tx-offload: off [fixed]
tls-hw-rx-offload: off [fixed]


$ ethtool -k  eth0
Features for eth0:
rx-checksumming: on
tx-checksumming: on
	tx-checksum-ipv4: on
	tx-checksum-ip-generic: off [fixed]
	tx-checksum-ipv6: on
	tx-checksum-fcoe-crc: off [fixed]
	tx-checksum-sctp: off [fixed]
scatter-gather: on
	tx-scatter-gather: on
	tx-scatter-gather-fraglist: off [fixed]
tcp-segmentation-offload: on
	tx-tcp-segmentation: on
	tx-tcp-ecn-segmentation: off [fixed]
	tx-tcp-mangleid-segmentation: on
	tx-tcp6-segmentation: on
udp-fragmentation-offload: off
generic-segmentation-offload: on
generic-receive-offload: on
large-receive-offload: on
rx-vlan-offload: on [fixed]
tx-vlan-offload: on [fixed]
ntuple-filters: off [fixed]
receive-hashing: on
highdma: on [fixed]
rx-vlan-filter: off [fixed]
vlan-challenged: off [fixed]
tx-lockless: off [fixed]
netns-local: off [fixed]
tx-gso-robust: off [fixed]
tx-fcoe-segmentation: off [fixed]
tx-gre-segmentation: off [fixed]
tx-gre-csum-segmentation: off [fixed]
tx-ipxip4-segmentation: off [fixed]
tx-ipxip6-segmentation: off [fixed]
tx-udp_tnl-segmentation: off [fixed]
tx-udp_tnl-csum-segmentation: off [fixed]
tx-gso-partial: off [fixed]
tx-sctp-segmentation: off [fixed]
tx-esp-segmentation: off [fixed]
tx-udp-segmentation: off [fixed]
fcoe-mtu: off [fixed]
tx-nocache-copy: off
loopback: off [fixed]
rx-fcs: off [fixed]
rx-all: off [fixed]
tx-vlan-stag-hw-insert: off [fixed]
rx-vlan-stag-hw-parse: off [fixed]
rx-vlan-stag-filter: off [fixed]
l2-fwd-offload: off [fixed]
hw-tc-offload: off [fixed]
esp-hw-offload: off [fixed]
esp-tx-csum-hw-offload: off [fixed]
rx-udp_tunnel-port-offload: off [fixed]
tls-hw-tx-offload: off [fixed]
tls-hw-rx-offload: off [fixed]
rx-gro-hw: off [fixed]
tls-hw-record: off [fixed]
* Azure accelerate networking

Concept: Create an Azure VM with Accelerated Networking using Azure CLI | Microsoft Docs

Tip 226 - How to enable Accelerated Networking in existing Azure Virtual Machines | Azure Tips and Tricks (microsoft.github.io)

Azure VM NICS use Mellanox nic (use lspci and  ethtool -k  eth0 to see offload)
pb-connectx-3-pro-card-vpi.pdf (mellanox.com)

offloads



narwhal@replica1:~$ lspci
0000:00:00.0 Host bridge: Intel Corporation 440BX/ZX/DX - 82443BX/ZX/DX Host bridge (AGP disabled) (rev 03)
0000:00:07.0 ISA bridge: Intel Corporation 82371AB/EB/MB PIIX4 ISA (rev 01)
0000:00:07.1 IDE interface: Intel Corporation 82371AB/EB/MB PIIX4 IDE (rev 01)
0000:00:07.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 02)
0000:00:08.0 VGA compatible controller: Microsoft Corporation Hyper-V virtual VGA
1368:00:02.0 Ethernet controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function]

which offload are on ?

narwhal@replica1:~$ ethtool -k  eth0 
Features for eth0:
rx-checksumming: on
tx-checksumming: on
        tx-checksum-ipv4: on
        tx-checksum-ip-generic: off [fixed]
        tx-checksum-ipv6: on
        tx-checksum-fcoe-crc: off [fixed]
        tx-checksum-sctp: off [fixed]
scatter-gather: on
        tx-scatter-gather: on
        tx-scatter-gather-fraglist: off [fixed]
tcp-segmentation-offload: on
        tx-tcp-segmentation: on
        tx-tcp-ecn-segmentation: off [fixed]
        tx-tcp-mangleid-segmentation: off
        tx-tcp6-segmentation: on
udp-fragmentation-offload: off
generic-segmentation-offload: on
generic-receive-offload: on
large-receive-offload: off
rx-vlan-offload: on [fixed]
tx-vlan-offload: on [fixed]
ntuple-filters: off [fixed]
receive-hashing: on
highdma: on [fixed]
rx-vlan-filter: off [fixed]
vlan-challenged: off [fixed]
tx-lockless: off [fixed]
netns-local: off [fixed]
tx-gso-robust: off [fixed]
tx-fcoe-segmentation: off [fixed]
tx-gre-segmentation: off [fixed]
tx-gre-csum-segmentation: off [fixed]
tx-ipxip4-segmentation: off [fixed]
tx-ipxip6-segmentation: off [fixed]
tx-udp_tnl-segmentation: off [fixed]
tx-udp_tnl-csum-segmentation: off [fixed]
tx-gso-partial: off [fixed]
tx-sctp-segmentation: off [fixed]
tx-esp-segmentation: off [fixed]
tx-udp-segmentation: off [fixed]
fcoe-mtu: off [fixed]
tx-nocache-copy: off
loopback: off [fixed]
rx-fcs: off [fixed]
rx-all: off [fixed]
tx-vlan-stag-hw-insert: off [fixed]
rx-vlan-stag-hw-parse: off [fixed]
rx-vlan-stag-filter: off [fixed]
l2-fwd-offload: off [fixed]
hw-tc-offload: off [fixed]
esp-hw-offload: off [fixed]
esp-tx-csum-hw-offload: off [fixed]
rx-udp_tunnel-port-offload: off [fixed]
tls-hw-tx-offload: off [fixed]
tls-hw-rx-offload: off [fixed]
rx-gro-hw: off [fixed]
tls-hw-record: off [fixed]

Are offloads working ?

narwhal@replica1:~$ ethtool -S  eth0 | grep vf_
     vf_rx_packets: 1170
     vf_rx_bytes: 5484461
     vf_tx_packets: 7333
     vf_tx_bytes: 5316679
     vf_tx_dropped: 0
     cpu0_vf_rx_packets: 271
     cpu0_vf_rx_bytes: 102450
     cpu0_vf_tx_packets: 2119
     cpu0_vf_tx_bytes: 1940038
     cpu1_vf_rx_packets: 10
     cpu1_vf_rx_bytes: 15694
     cpu1_vf_tx_packets: 844
     cpu1_vf_tx_bytes: 341109
     cpu2_vf_rx_packets: 224
     cpu2_vf_rx_bytes: 4278058
     cpu2_vf_tx_packets: 2316
     cpu2_vf_tx_bytes: 777403
     cpu3_vf_rx_packets: 665
     cpu3_vf_rx_bytes: 1088259
     cpu3_vf_tx_packets: 2054
     cpu3_vf_tx_bytes: 2258129
narwhal@replica1:~$ 
