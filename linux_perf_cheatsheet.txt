
========================================================
* top
------

Ref: man top
                         system load avg over the last 1, 5 and 15 minutes
      current time       load average = running + waiting threads
        |    time since last boot                    |
        |         |                                  |
        v         v                                  v

top - 08:54:25 up 37 days,  8:58, 11 users,  load average: 1.77, 0.57, 0.19

Tasks: 321 total,   1 running, 204 sleeping,   0 stopped,   0 zombie
        ^ 
       total tasks or threads         time waiting for I/O completion (disk)
                                 time in kernel| idle handler
                                     |         |       time spent servicing hardware interrupts
                                     |         |        |
                                     v         v        v
                                     
%Cpu(s):  4.9 us,  1.5 sy,  0.0 ni, 93.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st <-+
                                                                                  |
          ^           ^       ^niced user processes              ^        time stolen from this vm by the hypervisor
          |           |                                          |
          |       time kernel processes                   time spent servicing software interrupts
         time running un-niced user processes                         cache: read from the disk
                                                                       v
                                                                       
KiB Mem : 24210912 total,  7884172 free,  2635336 used, 13691404 buff/cache

^          ^                                                      ^ 
|         total = free + used +  buff/cache                 buffers:yet to be written to disk
Physical memory in KiB(kibibyte) = 1024 bytes
KiB Swap:        0 total,        0 free,        0 used. 21357152 avail Mem 

Task's priority. From -20 to 19, with -20 being most important
                |  Niceness: -20 (most favorable) to 19 (least favorable ).
                |   |     Everything in-use and/or reserved 
                |   |     |       RES: occupying physical memory
                |   |     |        |                  %physical memory
                v   v     v        v                   v

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                
31194 krishna   20   0  357412  45168  12188 S 104.3  0.2   2:57.76 handler_perf_te <-- CPU 104% out 1600% (16 cores)      
31192 krishna   20   0   42924   4180   3396 R   0.7  0.0   0:00.76 top                                                    
31130 krishna   20   0  330372  38348  19236 S   0.3  0.2   0:01.67 emacs                                                  
    1 root      20   0   78156   6544   3916 S   0.0  0.0   0:59.73 systemd                                                
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.55 kthreadd                                               
    4 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/0:0H                                           
    5 root      20   0       0      0      0 I   0.0  0.0   0:01.63 kworker/u128:0                                         
    7 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 mm_percpu_wq                                           
    8 root      20   0       0      0      0 S   0.0  0.0   1:04.08 ksoftirqd/0                                            
    9 root      20   0       0      0      0 I   0.0  0.0  15:59.09 rcu_sched                                              
   10 root      20   0       0      0      0 I   0.0  0.0   0:00.00 rcu_bh                                                 
   11 root      rt   0       0      0      0 S   0.0  0.0   0:01.01 migration/0                                            
   12 root      rt   0       0      0      0 S   0.0  0.0   0:09.33 watchdog/0                                             
   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0                                                
   14 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1                                                
   15 root      rt   0       0      0      0 S   0.0  0.0   0:08.38 watchdog/1                                             
   16 root      rt   0       0      0      0 S   0.0  0.0   0:00.80 migration/1                                            
   17 root      20   0       0      0      0 S   0.0  0.0   0:30.31 ksoftirqd/1                                            
   19 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/1:0H                                           
   20 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/2                                                
   21 root      rt   0       0      0      0 S   0.0  0.0   0:09.78 watchdog/2                                             
   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.83 migration/2                                            


           The status of the task which can be one of:
               D = uninterruptible sleep
               R = running
               S = sleeping
               T = stopped by job control signal
               t = stopped by debugger during trace
               Z = zombie


- load average is very roughly (number of process that need to run / number of CPU cores)
  and measures how overloaded a server is.
- A simple rule of thumb: If the 15 min load average exceeds
   0.7 (after dividing by the number of CPU cores), then the server may be overloaded.

Some keys
---------
H - displays threads (GOOD)

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                    SWAP
  20351 krishna   20     9686912 450672  62500 S 20.1  1.9 780:05.43 mysqld
  20350 krishna   20     9686912 450672  62500 R 18.8  1.9 772:32.13 mysqld
  20343 krishna   20     9686912 450672  62500 S 18.4  1.9 779:22.46 mysqld
  20346 krishna   20     9686912 450672  62500 S 18.1  1.9 780:28.93 mysqld
  20349 krishna   20     9686912 450672  62500 S 18.1  1.9 783:59.11 mysqld
  20342 krishna   20     9686912 450672  62500 S 17.1  1.9 771:57.36 mysqld
  20344 krishna   20     9686912 450672  62500 S 17.1  1.9 777:53.31 mysqld
  20347 krishna   20     9686912 450672  62500 S 17.1  1.9 777:07.96 mysqld
  20345 krishna   20     9686912 450672  62500 S 16.1  1.9 770:59.48 mysqld
  20348 krishna   20     9686912 450672  62500 S 16.1  1.9 778:22.14 mysqld

  
0 - does not display) '0's in the output
    (this reduces screen clutter)

1 - shows multiple CPUs (toggle)
Eg.,
%Cpu0  :  0.3 us,  1.7 sy,  0.0 ni, 98.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  5.2 us,  2.8 sy,  0.0 ni, 92.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu2  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu3  :  0.3 us,  0.3 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st

2 - shows NUMA Node
%Cpu(s):  1.5 us,  2.1 sy,  0.0 ni, 96.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Node0 :  1.1 us,  1.3 sy,  0.0 ni, 97.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Node1 :  2.0 us,  2.8 sy,  0.0 ni, 95.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st


3 - displays a specific NUMA node
 eg., press 1(show cpus), 3(display specific NUMA node) & 1 (show NUMA node 1)
 %Node1 :  2.0 us,  3.4 sy,  0.0 ni, 94.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu8  :  3.7 us,  3.7 sy,  0.0 ni, 92.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu9  :  1.6 us,  4.7 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu10 :  1.5 us,  1.5 sy,  0.0 ni, 96.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu11 :  0.7 us,  3.0 sy,  0.0 ni, 96.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu12 :  1.5 us,  4.5 sy,  0.0 ni, 94.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu13 :  3.1 us,  3.8 sy,  0.0 ni, 93.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu14 :  1.6 us,  2.3 sy,  0.0 ni, 96.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 %Cpu15 :  2.2 us,  3.7 sy,  0.0 ni, 94.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
 

f  :Fields-Management These  keys display a separate screen where you can change which fields are displayed


SORTING 
--------
                command   sorted-field
                M         %MEM        
                N         PID         
                P         %CPU        
                T         TIME+       


==================================================================
* /proc/meminfo

Ref: https://www.kernel.org/doc/Documentation/filesystems/proc.txt

$ cat /proc/meminfo
MemTotal:       24210912 kB <-- physical ram size
MemFree:         7465412 kB 
MemAvailable:   20939500 kB <-- memory is available for starting new applications
Buffers:          560476 kB <-- temporary storage for raw disk blocks
Cached:         12487660 kB <-- in-memory cache for files read from the disk (the page cache)
SwapCached:            0 kB
Active:          6260388 kB <-- Kernel memory that has been used more recently
Inactive:        9389976 kB <-- Kernel memory which has been less recently used (It is more eligible to be reclaimed for other purposes)
Active(anon):    1369780 kB <-- user space processes recently used memory
Inactive(anon):  1233564 kB <-- user space processes less recently used memory
Active(file):    4890608 kB <-- Kernel cache for files that was read from disk (recently used)
Inactive(file):  8156412 kB <-- Kernel cache for files that was read from disk (less recently used)
                               Note: Cached = Active(file) + Inactive(file)
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:                36 kB
Writeback:             0 kB
AnonPages:       2600360 kB
Mapped:            78340 kB
Shmem:              1056 kB
Slab:             819012 kB
SReclaimable:     644364 kB
SUnreclaim:       174648 kB
KernelStack:        7248 kB
PageTables:        16568 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    12105456 kB
Committed_AS:    3328516 kB
VmallocTotal:   34359738367 kB
VmallocUsed:           0 kB
VmallocChunk:          0 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
CmaTotal:              0 kB
CmaFree:               0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
DirectMap4k:     1134528 kB
DirectMap2M:    23506944 kB
DirectMap1G:     1048576 kB

===================================
* vmstat


krishna@krishna:~$ vmstat 2 10 
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache    si   so    bi    bo   in   cs us sy id wa st
 1  0      0 7454868 562308 13136452  0    1    12    23    0    1  0  0 98  1  0
 0  0      0 7454744 562308 13136452  0    0     0     0   12  100  0  0 100  0  0
 0  0      0 7454868 562316 13136444  0    0     0     6    8   90  0  0 100  0  0
 0  0      0 7454868 562316 13136444  0    0     0     0    6   74  0  0 100  0  0
 0  0      0 7454996 562316 13136452  0    0     0     0   16  110  0  0 100  0  0
 0  0      0 7455120 562316 13136452  0    0     0     0    6   63  0  0 100  0  0
 0  0      0 7455120 562316 13136452  0    0     0     0    6   84  0  0 100  0  0
 0  0      0 7455244 562316 13136452  0    0     0     0   11   83  0  0 100  0  0
 0  0      0 7455368 562316 13136452  0    0     0     0   33  189  0  0 100  0  0
 0  0      0 7455368 562316 13136452  0    0     0     0   14   80  0  0 100  0  0
 ^
 r: The number of runnable processes (running or waiting for run time).
 b: The number of processes in uninterruptible sleep.

krishna@krishna:~$ 
=======================================
* iotop

gives info by process

$sudo iotop

Total DISK READ :       0.00 B/s | Total DISK WRITE :       2.49 M/s
Actual DISK READ:       0.00 B/s | Actual DISK WRITE:      49.77 K/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO>    COMMAND
  496 be/3 root        0.00 B/s   26.80 K/s  0.00 %  5.79 % [jbd2/dm-0-8]
32086 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.34 % [kworker/u130:3]
38666 be/4 krishna     0.00 B/s    2.46 M/s  0.00 %  0.06 % cc1plus -quiet -I /home/krishna/~orcasql-mysql/source_downloads/g
    1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init maybe-ubiquity
    2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]
    4 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H]
    5 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/u128:0]
    7 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [mm_percpu_wq]
    8 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]
    9 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]
   10 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_bh]
   11 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]
   12 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/0]
   13 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/0]
   14 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/1]
   15 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/1]
   16 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/1]
   17 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/1]
   19 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/1:0H]
   20 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/2]
   21 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/2]
   22 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/2]
   23 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/2]
   25 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/2:0H]
   26 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/3]
   27 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/3]
   28 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/3]
   29 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/3]
   31 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/3:0H]

=================================
* iostat

gives info by devices
==========================

* branch
- conditional branches mispredicted( Bcm) will be high for this:
 
enum E { A, B, C };
enum E e;
int i;
...
switch (e)
{
  case A: i += 1; break;
  case B: i += 2; break;
  case C: i += 3; break;
}

can be replaced with code like this:

enum E { A, B, C };
enum E e;
int table[] = { 1, 2, 3 };
int i;
...
i += table[e]
Ref: https://valgrind.org/docs/manual/cg-manual.html

==========================
* cachegrind * callgrind
Callgrind is a profiling tool that records the call history among functions in a program's run as a call-graph.
Shows the following:-
  - number of instructions executed, their relationship to source lines, the caller/callee relationship between functions, and the numbers of such calls
  - cache simulation and/or branch prediction (similar to Cachegrind) can produce further information about the runtime behavior of an application

Ref: https://valgrind.org/docs/manual/cl-manual.html
     https://accu.org/journals/overload/20/111/floyd_1886/ good

Installation:-
sudo apt-get install  valgrind
sudo apt-get install  kcachegrind


Ref: https://www.valgrind.org/docs/manual/cg-manual.html
I cache reads
 - Ir - which equals the number of instructions executed
 - I1mr - I1 cache read misses (I1mr)
 - ILmr - LL cache instruction read misses
D cache reads
 - Dr -  which equals the number of memory reads
 - D1mr - D1 cache read misses
 - DLmr -  LL cache data read misses
D cache writes
 - Dw - which equals the number of memory writes
 - D1mw - D1 cache write misses
 - DLmw - LL cache data write misses
Bc  - Conditional branches executed
Bcm - conditional branches mispredicted
Bi  - Indirect branches executed:-
     - Rather than specifying the address of the next instruction to execute, as in a direct branch,
       the argument specifies where the address is located.
     - An example is 'jump indirect on the r1 register', which means that the next instruction to be
       executed is at the address in register r1. The address to be jumped to is not known until the
       instruction is executed. Indirect branches can also depend on the value of a memory location.
     Eg.,
       - subroutine call instructions can be indirect, with the address of the subroutine to be
          called specified in memory.
       - Function Pointers are typically implemented with indirect subroutine calls.
Bim - indirect branches mispredicted


$ g++ -g3  simple.cc -o /tmp/simple -lpthread -rdynamic;
$ valgrind --tool=callgrind --branch-sim=yes --cacheuse=yes --collect-systime=msec --callgrind-out-file=clg.out /tmp/simple
 Callgrind, a call-graph generating cache profiler
 Copyright (C) 2002-2017, and GNU GPL'd, by Josef Weidendorfer et al.
 Using Valgrind-3.16.1 and LibVEX; rerun with -h for copyright info
 Command: /tmp/simple  <--  the command line invocation of the program under examination.
 
warning: L3 cache found, using its data for the LL simulation.
For interactive control, run 'callgrind_control -h'. <--- this might be useful to reset counters etc.,
io_threads are running ...
cpu_threads are running ...

                                           2063 I1 cache read misses
 v-- which events are recorded                 v           
 Events    : Ir         Dr         Dw        I1mr D1mr  D1mw ILmr DLmr DLmw Bc        Bcm     Bi      Bim AcCost1 SpLoss1 AcCost2 SpLoss2  sysCount sysTime
 Collected : 3701868262 1331974479 369526140 2063 14574 2925 1909 7994 2044 653672173 2724902 4959114 730 5404230 681470  1349229 247606   727      762732
              ^                                     
             3701868262 Instruction reads (ie., instructions executed)

 I   refs:      3,701,868,262 <- I - instructions cache reads (ie., instructions executed)
 I1  misses:            2,063 <- I1 cache instruction misses
 LLi misses:            1,909 <- LL cache instruction misses (Last Level instruction - LLi)
 I1  miss rate:          0.00% <- I1 cache miss %
 LLi miss rate:          0.00% <- Last Level insruction cache miss %
 
 D   refs:      1,701,500,619  (1,331,974,479 rd + 369,526,140 wr) <-- Data cache memory (ie., memory reads + writes)
 D1  misses:           17,499  (       14,574 rd +       2,925 wr) <-- D1 cache misses (reads + writes)
 LLd misses:           10,038  (        7,994 rd +       2,044 wr) <-- Last level data misses 
 D1  miss rate:           0.0% (          0.0%   +         0.0%  ) <-- D1 cache misses (NOT: write miss means read from storage, update and write to storage)
 LLd miss rate:           0.0% (          0.0%   +         0.0%  ) <-- Last level data miss rate.
 
 LL refs:              19,562  (       16,637 rd +       2,925 wr)
 LL misses:            11,947  (        9,903 rd +       2,044 wr)
 LL miss rate:            0.0% (          0.0%   +         0.0%  )
 
 Branches:        658,631,287  (  653,672,173 cond +   4,959,114 ind)
 Mispredicts:       2,725,632  (    2,724,902 cond +         730 ind)
 Mispred rate:            0.4% (          0.4%     +         0.0%   )
krishna@krishna:~/linux_perf_cheatsheet$ 

viewing output with gui: Use vnc to view kcachegrind output:- GOOD
-----------------------------------------------------------
  sudo apt-get install kcachegrind
  vncpasswd, vncserver
  In vncviewer login to the system and run this
   $kcachegrind chg.out 

 Navigation:-
    On right side click "Types" tab -> select say "Mispredicted cond branch"
    On left side you see see all Bcm ordered in descinding order.
    Click highest self  -> isPrime(int) 99.40.
    Click Source Tab -> is will show these lines
      14% for (int i = 2; i <= limit; ++i) {
      86%  if (x % i == 0) {
   Click on "Call Graph" see see graph of caller/callee relation

viewing output with text editor
----------------------------------
krishna@krishna:~/linux_perf_cheatsheet$ callgrind_annotate clg.out > junk.txt 2>&1 ; cat junk.txt | grep -v /usr/local/bin/callgrind_annotate
Profile data file 'clg.out' (creator: callgrind-3.16.1)

I1 cache: 32768 B, 64 B, 8-way associative <-- 32K I1 cache 
D1 cache: 32768 B, 64 B, 8-way associative <-- 32K D1 cache
LL cache: 20971520 B, 64 B, 20-way associative <-- 20M Last level cache
Timerange: Basic block 0 - 1012368268
Trigger: Program termination
Profiled target:  /tmp/simple (PID 25316, part 1)
Events recorded:  Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw Bc Bcm Bi Bim AcCost1 SpLoss1 AcCost2 SpLoss2 sysCount sysTime
Events shown:     Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw Bc Bcm Bi Bim AcCost1 SpLoss1 AcCost2 SpLoss2 sysCount sysTime
Event sort order: Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw Bc Bcm Bi Bim AcCost1 SpLoss1 AcCost2 SpLoss2 sysCount sysTime
Thresholds:       99 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Include dirs:     
User annotated:   
Auto-annotation:  on

This line shows PROGRAM TOTALS                                           D1 cache read misses
                Data cache reads.    Data cache writes     I1 cache read misses    |
|                      |                      |                    |               |          D1 cache write misses                                       Conditional branches executed           
v                      v                      v                    v               v               |          Last cache read misses          write misses    |                 conditional branches mispredicted     indirect branches mispredicted                      number of system calls done      
-------------------------------------------------------------------------------                    v              v                             v             v                   v               Branch count           v                                                         v         elapsed time spent in system calls
Ir                     Dr                     Dw                   I1mr           D1mr            D1mw           ILmr           DLmr           DLmw           Bc                   Bcm                Bi                 Bim          AcCost1    SpLoss1    AcCost2    SpLoss2    sysCount     sysTime          
--------------------------------------------------------------------------------
3,701,868,280 (100.0%) 1,331,974,479 (100.0%) 369,526,140 (100.0%) 2,063 (100.0%) 14,574 (100.0%) 2,925 (100.0%) 1,909 (100.0%) 7,994 (100.0%) 2,044 (100.0%) 653,672,173 (100.0%) 2,724,902 (100.0%) 4,959,114 (100.0%) 730 (100.0%) 0          0          0          0          741 (100.0%) 778,891 (100.0%)  PROGRAM TOTALS
^                       
+-- so many instructions cache reads (ie., instructions executed) 



Best way to act based on the output: Ref: https://valgrind.org/docs/manual/cg-manual.html
 - Look at large Ir in line-by-line source code annotations
 - After that, we have found that LL misses are typically a much bigger source of slow-downs than L1 misses.
   So it's worth looking for any snippets of code with high DLmr or DLmw counts
 - Looking at the Bcm and Bim misses can also be helpful.
    In particular, Bim misses are often caused by switch statements, and in some cases these
    switch statements can be replaced with table-driven code.
    
 
THIS SHOWS code level details:-- The way to read is walk along a column. to see the code for a cell go the right most column

Eg.,  for (int i = 2; i <= limit; ++i) {
      1,592,156,757 (43.01%)- Ir -  Instructions are executed by the line
      319,421,877 (48.87%)  - Bc - branch conditional
      393,503 (14.44%)      - Bcm - branch condition misses

Eg., for line if (x % i == 0) {
     1,914,170,514 (51.71%) - Ir - Instructions are executed by the line
     319,028,419 (48.81%)   - Bc - - branch conditional
     2,314,953 (84.96%)     - Bcm - branch condition misses
     
--------------------------------------------------------------------------------
-- Auto-annotated source: simple.cc
--------------------------------------------------------------------------------
Ir                     Dr                   Dw                   I1mr       D1mr       D1mw       ILmr       DLmr       DLmw       Bc                   Bcm                Bi           Bim        AcCost1        SpLoss1      AcCost2      SpLoss2      sysCount     sysTime          

            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           
   19,810,528 ( 0.54%)           0            9,905,264 ( 2.68%) 1 ( 0.05%) 0          0          1 ( 0.05%) 0          0                    0                  0            0          0              0           36 ( 0.00%)   0           36 ( 0.00%)   .                .           bool isPrime(int x) {
   24,763,160 ( 0.67%)   4,952,632 ( 0.37%)   9,905,264 ( 2.68%) 0          0          5 ( 0.17%) 0          0          3 ( 0.15%)           0                  0            0          0              0          140 ( 0.00%)   0           84 ( 0.00%)   .                .             int limit = std::sqrt(x);
   84,194,744 ( 2.27%)  29,715,792 ( 2.23%)  19,810,528 ( 5.36%) 2 ( 0.10%) 1 ( 0.01%) 0          1 ( 0.05%) 0          0            4,952,632 ( 0.76%)         3 ( 0.00%) 4,952,632 (99.87%) 1 ( 0.14%)     0            0            0            0           33 ( 4.45%)  31,201 ( 4.01%)  => /usr/include/c++/7/cmath:__gnu_cxx::__enable_if<std::__is_integer<int>::__value, double>::__type std::sqrt<int>(int) (4,952,632x)
1,592,156,757 (43.01%) 638,843,754 (47.96%) 319,421,879 (86.44%) 0          0          0          0          0          0          319,421,877 (48.87%)   393,503 (14.44%)   0          0              0            0            0            0          457 (61.67%) 384,278 (49.34%)    for (int i = 2; i <= limit; ++i) {
1,914,170,514 (51.71%) 638,056,838 (47.90%)           0          0          0          0          0          0          0          319,028,419 (48.81%) 2,314,953 (84.96%)   .          .              .            .            .            .            .                .               if (x % i == 0) {
    9,118,344 ( 0.25%)           .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .                 return false;
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .               }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             }
      393,458 ( 0.01%)           .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             return true;
    9,905,260 ( 0.27%)   9,905,260 ( 0.74%)           0          0          0          0          0          0          0                    0                  0            0          0              0            0            0            0            5 ( 0.67%) 173,223 (22.24%)  }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           
           24 ( 0.00%)           0                   12 ( 0.00%) 1 ( 0.05%) 0          3 ( 0.10%) 1 ( 0.05%) 0          3 ( 0.15%)           0                  0            0          0              0           84 ( 0.00%)   0           84 ( 0.00%)   .                .           void f1(int c) {
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             C1 c1;
            6 ( 0.00%)           0                    6 ( 0.00%) 1 ( 0.05%) 0          0          1 ( 0.05%) 0          0                    0                  0            0          0              0           10 ( 0.00%)   0           10 ( 0.00%)   .                .             c1.m1 = 1;
            6 ( 0.00%)           0                    6 ( 0.00%) .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             c1.m2 = 2;
            6 ( 0.00%)           0                    6 ( 0.00%) .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             c1.m3 = 3;
           18 ( 0.00%)           6 ( 0.00%)           6 ( 0.00%) 0          0          0          0          0          0                    6 ( 0.00%)         4 ( 0.00%)   .          .              .            .            .            .            .                .             for (int i = 0; i > 0; i++) {
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .               i = i + 1;
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             // printf(".");
            6 ( 0.00%)           0                    6 ( 0.00%) .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             int primeCount = 0;
   19,810,538 ( 0.54%)   4,952,636 ( 0.37%)   4,952,636 ( 1.34%) 0          0          0          0          0          0            4,952,636 ( 0.76%)         4 ( 0.00%)   0          0              0            0            0            0            4 ( 0.54%)   3,760 ( 0.48%)    for (int i = 0; i < 1000000; ++i) {
   24,763,156 ( 0.67%)   4,952,632 ( 0.37%)   4,952,632 ( 1.34%) 0          0          0          0          0          0            4,952,630 ( 0.76%)        24 ( 0.00%)   0          0              0            0            0            0            4 ( 0.54%)   4,347 ( 0.56%)      if (isPrime(i)) {
3,654,512,765 (98.72%) 1,321,474,276 (99.21%) 359,042,935 (97.16%) 3 ( 0.15%) 1 ( 0.01%) 5 ( 0.17%) 2 ( 0.10%) 0          3 ( 0.15%) 643,402,928 (98.43%) 2,708,459 (99.40%) 4,952,632 (99.87%) 1 ( 0.14%)     0            0            0            0          495 (66.80%) 588,702 (75.58%)  => simple.cc:isPrime(int) (4,952,632x)
      393,458 ( 0.01%)           0              393,458 ( 0.11%) 0          0          1 ( 0.03%) 0          0          0                    0                  0            0          0              0           56 ( 0.00%)   .            .            .                .                 ++primeCount;
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .               }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .             }
           12 ( 0.00%)           8 ( 0.00%)           .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           }
            .                    .                    .          .          .          .          .          .          .                    .                  .            .          .              .            .            .            .            .                .           



valgrind --tool=cachegrind --log-file=cg.out --branch-sim=yes ./badprime

# run cache and branch-predictor profiler
# 
#$ valgrind --tool=cachegrind --branch-sim=yes --cache-sim=yes --cachegrind-out-file=chg.out /tmp/simple


# run call graph simulator and branch-predictor emulator
# 
$ valgrind --tool=callgrind --branch-sim=yes --cacheuse=yes --callgrind-out-file=clg.out /tmp/simple

callgrind_annotate clg.out > junk.txt 2>&1 ; cat junk.txt | grep -v /usr/local/bin/callgrind_annotate


============================
https://github.com/iovisor/bcc/blob/master/tools/trace_example.txt userspace
https://github.com/iovisor/bcc
https://github.com/iovisor/bcc/blob/master/tools/wakeuptime_example.txt
./wakeuptime -u          # don't include kernel threads (user only)
==========================================================================
* mutrace Measuring mutex lock contention

Ref: http://0pointer.de/blog/projects/mutrace.html

sudo apt-get install mutrace

Note:
 - This tool report lock contention (valgrind drd does not report contention)
 - link with -rdynamic for better traces
   gcc -O -g3  simple.cc -o /tmp/simple -lpthread -rdynamic;
 - program has to exit to capture traces
 - use higher --hash-size=100000 (if you see messages like mutrace: WARNING: 1739093 internal hash collisions detected. Results might not be as reliable as they could be.mutrace:          Try to increase --hash-size=, which is currently at 3371.)
  - program should not crash
  
~/linux_perf_cheatsheet$ mutrace  --hash-size=100000 /tmp/simple
mutrace: 0.2 sucessfully initialized for process simple (pid 53366).
io_threads are running ...
cpu_threads are running ...

  C-c C-cTerminating due to signal:2

mutrace: Showing statistics for process simple (pid 53366).
mutrace: 3 mutexes used.

Mutex #1 (0x0x560d19982080) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f5601935827]
        /tmp/simple(_Z19cpu_thread_functionPv+0x46) [0x560d19780ed6]

Mutex #0 (0x0x560d19982040) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f5601935827]
        /tmp/simple(_Z19cpu_thread_functionPv+0x60) [0x560d19780ef0]

Mutex #2 (0x0x560d199820c0) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f5601935827]
        /tmp/simple(_Z19cpu_thread_functionPv+0x2c) [0x560d19780ebc]

mutrace: Showing 3 most contended mutexes:
                           Contention: Times lock was already taken when we tried to take it and we had to wait.    
 Times the mutex was locked     | 
            |   Times the owning| thread of the mutex changed
            |       |           |   Total time of the lock    Longest time lock was held
            |       |           |     |                         |
            v       v           v     v                         v
 Mutex #   Locked  Changed    Cont. tot.Time[ms] avg.Time[ms] max.Time[ms]  Flags
       1        6        5        3    10000.704     1666.784     2000.162 M-.--.  <-- Mutex
       0        4        3        3     9000.447     2250.112     3000.168 M-.--.
       2        6        5        2     6000.983     1000.164     1000.184 M-.--.
                                                                           ||||||
                                                                           /|||||
          Object:                                     M = Mutex, W = RWLock /||||
           State:                                 x = dead, ! = inconsistent /|||
             Use:                                 R = used in realtime thread /||
      Mutex Type:                 r = RECURSIVE, e = ERRRORCHECK, a = ADAPTIVE /|
  Mutex Protocol:                                      i = INHERIT, p = PROTECT /
     RWLock Kind: r = PREFER_READER, w = PREFER_WRITER, W = PREFER_WRITER_NONREC 

mutrace: Note that the flags column R is only valid in --track-rt mode!

mutrace: Total runtime is 13614.505 ms.

mutrace: Results for SMP with 16 processors.


how to decode:- <-- this gives the function name and not the line number
 $ c++filt _Z19cpu_thread_functionPv+0x2c
  _Z19cpu_thread_functionPv+0x2c

 $ c++filt _Z19cpu_thread_functionPv
  cpu_thread_function(void*) 


Use gdb to decode the code function and line etc.,

Eg.,
Mutex #1 (0x0x561260fb00a0) first referenced by:
        /usr/lib/mutrace/libmutrace.so(pthread_mutex_lock+0x47) [0x7f8980d8d827]
        /tmp/simple(_Z2f4i+0x43) [0x561260dae384] <-- we will decode this
        /tmp/simple(_Z19cpu_thread_functionPv+0x2c) [0x561260dae3f5]
        /lib/x86_64-linux-gnu/libpthread.so.0(+0x76db) [0x7f8980b726db]


Need to decode _Z2f4i+0x43
$ c++filt _Z2f4i
f4(int)

Then use gdb to find the line number:-
  Ref: https://stackoverflow.com/questions/22769246/how-to-disassemble-one-single-function-using-objdump


$ gdb -batch -ex "disassemble/rs f4" /tmp/simple <-- here we wanted to disass function f4() Now below see +0x43

Dump of assembler code for function f4(int):
simple.cc:
98      void f4(int d) {
   0x0000000000001341 <+0>:     55      push   %rbp
   0x0000000000001342 <+1>:     48 89 e5        mov    %rsp,%rbp
   0x0000000000001345 <+4>:     48 83 ec 10     sub    $0x10,%rsp
   0x0000000000001349 <+8>:     89 7d fc        mov    %edi,-0x4(%rbp)
..
100       pthread_mutex_lock(&mutex1);
   0x0000000000001356 <+21>:    48 8d 3d 03 1d 20 00    lea    0x201d03(%rip),%rdi        # 0x203060 <mutex1>
   0x000000000000135d <+28>:    e8 6e fd ff ff  callq  0x10d0 <pthread_mutex_lock@plt>

101       sleep(1);
   0x0000000000001362 <+33>:    bf 01 00 00 00  mov    $0x1,%edi
   0x0000000000001367 <+38>:    e8 e4 fc ff ff  callq  0x1050 <sleep@plt>

102       pthread_mutex_unlock(&mutex1);
   0x000000000000136c <+43>:    48 8d 3d ed 1c 20 00    lea    0x201ced(%rip),%rdi        # 0x203060 <mutex1> <------------------------this +0x43
   0x0000000000001373 <+50>:    e8 e8 fc ff ff  callq  0x1060 <pthread_mutex_unlock@plt>

103     
104       pthread_mutex_lock(&mutex2);
   0x0000000000001378 <+55>:    48 8d 3d 21 1d 20 00    lea    0x201d21(%rip),%rdi        # 0x2030a0 <mutex2>
   0x000000000000137f <+62>:    e8 4c fd ff ff  callq  0x10d0 <pthread_mutex_lock@plt>

105       sleep(2);
   0x0000000000001384 <+67>:    bf 02 00 00 00  mov    $0x2,%edi
   0x0000000000001389 <+72>:    e8 c2 fc ff ff  callq  0x1050 <sleep@plt>

112     }
   0x00000000000013c6 <+133>:   90      nop
   0x00000000000013c7 <+134>:   c9      leaveq 
   0x00000000000013c8 <+135>:   c3      retq   
End of assembler dump.

* system tap futex contention

Ref: https://sourceware.org/systemtap/examples/
 process/futexes.stp - System-Wide Futex Contention
 process/futexes2.stp - System-Wide Shared Futex Contention

scripts# stap -v futexes.stp 
Pass 1: parsed user script and 465 library scripts using 114360virt/48976res/6596shr/42680data kb, in 250usr/50sys/298real ms.
Pass 2: analyzed script: 4 probes, 8 functions, 104 embeds, 9 globals using 116076virt/52352res/8068shr/44396data kb, in 100usr/440sys/551real ms.
Pass 3: translated to C into "/tmp/stapSU927u/stap_b948ea59e802474b7b021ce9b61d6fa4_67634_src.c" using 116448virt/52732res/8196shr/44768data kb, in 0usr/0sys/3real ms.
Pass 4: compiled C into "stap_b948ea59e802474b7b021ce9b61d6fa4_67634.ko" in 5090usr/1710sys/6340real ms.
Pass 5: starting run.
  C-c C-cmysqld[30986] lock 0x7fc150385928 contended 153 times, 6 avg us
mysqld[30986] lock 0x7fc150385838 contended 2 times, 113 avg us
mysqld[30986] lock 0x7fc15038583c contended 2 times, 122 avg us
mysqld[30986] lock 0x7fc1503857e8 contended 2 times, 81 avg us
simple[31319] lock 0x5601419760a0 contended 2 times, 1233633 avg us
simple[31386] lock 0x55b9426a3060 contended 2 times, 1500334 avg us
Pass 5: run completed in 20usr/440sys/7941real ms.

https://man7.org/linux/man-pages/man2/futex.2.html
 long futex(uint32_t *uaddr, int futex_op, uint32_t val, const struct timespec *timeout, uint32_t *uaddr2, uint32_t val3);

The address  they capture is uaddr in the above call (eg., simple[31319] lock 0x5601419760a0 contended 2 times, 1233633 avg us)
* drd valgrind 

Linux valgrind's drd can be used to track down long held mutexes.
Note: This does not find mutex contention.
Ref: https://www.valgrind.org/docs/manual/drd-manual.html

Reports all locks that are held for more than 10ms (--exclusive-threshold=10)
krishna@krishna:~/linux_perf_cheatsheet$ valgrind --tool=drd  --exclusive-threshold=10 /tmp/simple
==53405== drd, a thread error detector
==53405== Copyright (C) 2006-2017, and GNU GPL'd, by Bart Van Assche.
==53405== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
==53405== Command: /tmp/simple
==53405== 
io_threads are running ...
cpu_threads are running ...
==53405== Thread 3: <-- Thread 3 acquired mutex at line simple.cc:51 an held it for 1001 ms
==53405== Acquired at:
==53405==    at 0x4C39193: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EBB: cpu_thread_function(void*) (simple.cc:49)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== Lock on mutex 0x30a0c0 was held during 1001 ms (threshold: 10 ms).
==53405==    at 0x4C3A123: pthread_mutex_unlock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108ECD: cpu_thread_function(void*) (simple.cc:51)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== mutex 0x30a0c0 was first observed at:
==53405==    at 0x4C390D3: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EBB: cpu_thread_function(void*) (simple.cc:49)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== 
==53405== Acquired at:
==53405==    at 0x4C39193: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108ED5: cpu_thread_function(void*) (simple.cc:53)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== Lock on mutex 0x30a080 was held during 2001 ms (threshold: 10 ms).
==53405==    at 0x4C3A123: pthread_mutex_unlock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EE7: cpu_thread_function(void*) (simple.cc:55)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== mutex 0x30a080 was first observed at:
==53405==    at 0x4C390D3: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108ED5: cpu_thread_function(void*) (simple.cc:53)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== 
==53405== Acquired at:
==53405==    at 0x4C39193: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EEF: cpu_thread_function(void*) (simple.cc:57)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== Lock on mutex 0x30a040 was held during 3001 ms (threshold: 10 ms).
==53405==    at 0x4C3A123: pthread_mutex_unlock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108F01: cpu_thread_function(void*) (simple.cc:59)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== mutex 0x30a040 was first observed at:
==53405==    at 0x4C390D3: pthread_mutex_lock (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x108EEF: cpu_thread_function(void*) (simple.cc:57)
==53405==    by 0x4C36413: ??? (in /usr/lib/valgrind/vgpreload_drd-amd64-linux.so)
==53405==    by 0x4E556DA: start_thread (pthread_create.c:463)
==53405==    by 0x518EA3E: clone (clone.S:95)
==53405== 
=========================================================================================
* perf

Ref: http://www.brendangregg.com/perf.html
Terminology I'm using, from lowest to highest overhead:
 - statistics/count: increment an integer counter on events
 - sample: collect details (eg, instruction pointer or stack) from a subset of events (once every ...)
 - trace: collect details from every event

installation
-------------
sudo apt install linux-tools-$(uname -r) linux-tools-generic

perf stat - gives summary performance counters for a program
----------------------------------------------------------------
This is: statistics/count: increment an integer counter on events

$ sudo perf stat /tmp/simple
 Performance counter stats for '/tmp/simple':

      17172.904652      task-clock (msec)         #    0.159 CPUs utilized <-- only 0.159 cpu is used/
            27,352      context-switches          #    0.002 M/sec <-- so many context switches                  
                43      cpu-migrations            #    0.003 K/sec <-- Migration is when a thread, usually after a context switch,
                                                                       get scheduled on a different CPU than it was scheduled before                 
               272      page-faults               #    0.016 K/sec                  
   <not supported>      cycles                                                      
   <not supported>      instructions                                                
   <not supported>      branches                                                    
   <not supported>      branch-misses                                               

     107.985321552 seconds time elapsed

perf-record : record program's profile (at some sampling frequency)
------------------------------------------------------------------

This is sampling: collect details (eg, instruction pointer or stack) from a subset of events (once every ...)

$ sudo perf record /tmp/simple
$ perf report --stdio
 or outside emacs
$  perf report  <-- nice

# Total Lost Samples: 0
#
# Samples: 71K of event 'cpu-clock'
# Event count (approx.): 17898500000
#
# Overhead  Command  Shared Object       Symbol                                 
# ........  .......  ..................  .......................................
#
    95.07%  simple   simple              [.] isPrime <--  for this program 95% of the CPU is spent in isPrime() method
     1.55%  simple   simple              [.] std::sqrt<int>
     1.44%  simple   libm-2.27.so        [.] __sqrt
     1.23%  simple   simple              [.] f1 <-- 1.23% CPU is spent on f1()
     0.13%  simple   [kernel.kallsyms]   [k] finish_task_switch
     0.10%  simple   simple              [.] sqrt@plt
     0.09%  simple   [kernel.kallsyms]   [k] exit_to_usermode_loop

To drill-down to the specific method GOOD
 - click on the iPrime -> Annotate isPrime -> This will show the source code and assembly(below)

Shows % of CPU time spent by each line in method isPrime(). Total is 100%. GOOD 
  |
  v
isPrime  /tmp/simple
             for (int i = 2; i <= limit; ++i) {
  0.16       movl   $0x2,-0x8(%rbp)
  8.17 23:   mov    -0x8(%rbp),%eax
  0.77       cmp    -0x4(%rbp),%eax
            jg     45
               if (x % i == 0) { <-- this is taking 66.41+8.01+3.11% of CPU in this method. why? branch pipeline stall.
  3.11       mov    -0x14(%rbp),%eax
  0.18       cltd
  8.01       idivl  -0x8(%rbp)
 66.41       mov    %edx,%eax
  0.31       test   %eax,%eax
            jne    3f
                 return false;
  0.31       mov    $0x0,%eax
  0.20      jmp    4a
             for (int i = 2; i <= limit; ++i) {
  8.01 3f:   addl   $0x1,-0x8(%rbp)
  2.39      jmp    23
               }
             }
             return true;
  0.02 45:   mov    $0x1,%eax
           }
  0.14 4a:   leaveq
  0.42      retq

Similar output can be obtained by this (can be done in emacs):-
  sudo perf annotate --stdio isPrime | cat


How to profile only a library
-----------------------------
Ref: https://stackoverflow.com/questions/61323185/profiling-dynamic-library-in-linux-using-perf

Pick the application/process and profile it.
 $ sudo perf record -p 20261 
 ^C[ perf record: Woken up 4 times to write data ]
 [ perf record: Captured and wrote 3.690 MB perf.data (70750 samples) ]

Then filter the library as follows:
-  focus on shared library dso in interactive "perf report" (find any sample from the library,
   open menu and select focus on library.so; ).

- perf report -d library.so

- You can also filter samples decoded from perf.data file like perf script | grep library.so | less

Eg.,
$  perf report -d libfoo.so -f --stdio 
[kernel.kallsyms] with build id ad19d53bdea8ee4257152fc235936d61a6529a01 not found, continuing without symbols
[vdso] with build id 6b07cfe7b86149f0a2ec51a362bc78486cc1f77e not found, continuing without symbols
# To display the perf.data header info, please use --header/--header-only options.
#
# dso: libfoo.so
#
# Total Lost Samples: 0
#
# Samples: 70K of event 'cpu-clock'
# Event count (approx.): 17687500000
#
# Overhead  Command     Symbol                                                                                    # ........  ..........  ..........................................................................................#
     0.75%  mysqld-foo  [.] foo_io_getevents
     0.32%  mysqld-foo  [.] std::_Deque_iterator<io_event, io_event&, io_event*>::_Deque_iterator
     0.20%  mysqld-foo  [.] std::chrono::__duration_cast_impl<std::chrono::duration<unsigned long, std::ratio<1l,      0.19%  mysqld-foo  [.] std::chrono::time_point<std::chrono::_V2::steady_clock, std::chrono::duration<long, st     0.17%  mysqld-foo  [.] std::chrono::operator-<std::chrono::_V2::steady_clock, std::chrono::duration<long, std     0.17%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::duration<long, std     0.16%  mysqld-foo  [.] foo::DispatcherWorkItem::Lock
     0.15%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::count
     0.07%  mysqld-foo  [.] std::lock_guard<std::mutex>::~lock_guard@plt
     0.07%  mysqld-foo  [.] std::deque<io_event, std::allocator<io_event> >::end
     0.06%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::duration<unsigned      0.06%  mysqld-foo  [.] std::chrono::duration_cast<std::chrono::duration<unsigned long, std::ratio<1l, 1000000     0.05%  mysqld-foo  [.] std::deque<io_event, std::allocator<io_event> >::begin
     0.05%  mysqld-foo  [.] std::operator==<io_event, io_event&, io_event*>
     0.04%  mysqld-foo  [.] std::chrono::_V2::steady_clock::now@plt
     0.04%  mysqld-foo  [.] std::operator!=<io_event, io_event&, io_event*>
     0.02%  mysqld-foo  [.] std::chrono::duration_cast<std::chrono::duration<unsigned long, std::ratio<1l, 1000000     0.02%  mysqld-foo  [.] std::chrono::duration<long, std::ratio<1l, 1000000000l> >::count@plt
     0.02%  mysqld-foo  [.] std::chrono::time_point<std::chrono::_V2::steady_clock, std::chrono::duration<long, st     0.02%  mysqld-foo  [.] std::this_thread::sleep_for<long, std::ratio<1l, 1000000l> >@plt
     0.01%  mysqld-foo  [.] std::chrono::duration<long, std::ratio<1l, 1000000l> >::duration<int, void>@plt
     0.01%  mysqld-foo  [.] std::chrono::duration<unsigned long, std::ratio<1l, 1000000000l> >::count@plt
     

Perf Tracing - painful for C++ not good
--------------------------------------------

perf-probe - Define new dynamic tracepoints
Ref: https://linux.die.net/man/1/perf-probe

Step 1: list all functions in program /tmp/simple or library
..................................................................
$ sudo perf probe --funcs --exec /tmp/simple 
..
f1
f2
f3
f4
frame_dummy
io_thread_function
isPrime
main
..

http://mysqlentomologist.blogspot.com/2020/07/dynamic-tracing-of-c-class-member.html
$sudo perf probe --funcs --exec  /home/krishna/orcasql-mysql/out/runtime_output_directory/libvml.so| grep FileChunk
vml::FileChunkHandlerLinux::PerformFlushInternal
vml::FileChunkHandlerLinux::PerformIoInternal
vml::FileChunkHandlerLinux::PerformReadInternal



Step 2:
sudo perf probe  -f --exec /tmp/simple --add='f2 b'
Added new event:
  probe_simple:f2      (on f2 in /tmp/simple with b)

perf record -e probe_simple:f2 -aR sleep 1000

$ sudo perf probe  -x /tmp/simple --line f1 | cat
sudo perf probe  -x /tmp/simple --line f1 | cat
<f1@/home/krishna/linux_perf_cheatsheet/simple.cc:0>
      0  void f1(int c) {
           C1 c1;
      2    c1.m1 = 1;
      3    c1.m2 = 2;
      4    c1.m3 = 3;
      5    for (int i = 0; i > 0; i++) {
      6      i = i + 1;
           }
           // printf(".");
      9    int primeCount = 0;
     10    for (int i = 0; i < 1000000; ++i) {
     11      if (isPrime(i)) {
     12        ++primeCount;
             }
           }
     15  }
         
         void f2(int b) {
           f1(b + 1);

sudo perf probe --exec /tmp/simple --vars f1
sudo perf probe --exec /tmp/simple --vars f1
WARNING: terminal is not fully functional
-  (press RETURN) 
Available variables at f1
        @<f1+0>
                C1      c1
                int     c
                int     primeCount


krishna@krishna:~/linux_perf_cheatsheet$ krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe --funcs --no-demangle --exec  /home/krishna/orcasql-mysql/out/runtime_output_directory/libvml.so | grep Internal
krishna@krishna:~/linux_perf_cheatsheet$ 
krishna@krishna:~/linux_perf_cheatsheet$ 
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe --funcs --no-demangle --filter='*' --exec  /home/krishna/orcasql-mysql/out/runtime_output_directory/libvml.so | grep Internal
_ZN3vml15MemChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml16NamespaceManager16AllocateInternalEPNS_17FileChangeContextE
_ZN3vml16NamespaceManager16MoveFileInternalEPNS_15FileMoveContextEb
_ZN3vml16NamespaceManager18CreateFileInternalEPNS_17FileCreateContextE
_ZN3vml16NamespaceManager18DeallocateInternalEPNS_17FileChangeContextE
_ZN3vml16NamespaceManager18DeleteFileInternalEPNS_17FileDeleteContextEb
_ZN3vml16NamespaceManager19CloseHandleInternalEPNS_18CloseHandleContextEb
_ZN3vml16NamespaceManager25LookupReadContextInternalEPNS_13FileIOContextE
_ZN3vml16NamespaceManager26LookupFlushContextInternalEPNS_13FileIOContextE
_ZN3vml16NamespaceManager26LookupWriteContextInternalEPNS_13FileIOContextE
_ZN3vml16TestChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21AzureFileChunkHandler17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE
_ZN3vml21FileChunkHandlerLinux19PerformReadInternalEPKNS_9IoRequestEP4iocbi
_ZN3vml21FileChunkHandlerLinux20PerformFlushInternalEPKNS_9IoRequestEP4iocbi
_ZN3vml21FileChunkHandlerLinux20PerformWriteInternalEPKNS_9IoRequestEP4iocbi
krishna@krishna:~/linux_perf_cheatsheet$ 
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe  -x /tmp/simple --line "_ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE" | cat
Specified source line is not found.
  Error: Failed to show lines.
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe  -x /tmp/simple --line _ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE | cat
Specified source line is not found.
  Error: Failed to show lines.
krishna@krishna:~/linux_perf_cheatsheet$ sudo perf probe  -x /tmp/simple --line _ZN3vml21FileChunkHandlerLinux17PerformIoInternalEPKNS_9IoRequestE | cat
Specified source line is not found.
  Error: Failed to show lines.


sudo perf probe  -f --exec /tmp/simple --add='f1:9 c1'
C1 exceeds max-bitwidth. Cut down to 64 bits.
Added new event:
  probe_simple:f1_2    (on f1:9 in /tmp/simple with c1)

You can now use it in all perf tools, such as:

        perf record -e probe_simple:f1_2 -aR sleep 1



------------------

$ more /boot/config-4.15.0-123-generic | grep UPROBE
more /boot/config-4.15.0-123-generic | grep UPROBE
CONFIG_ARCH_SUPPORTS_UPROBES=y
CONFIG_UPROBES=y
CONFIG_UPROBE_EVENTS=y

CONFIG_FTRACE=y

man perf-probe

       Add probes at zfree() function on /bin/zsh

           ./perf probe -x /bin/zsh zfree or ./perf probe /bin/zsh zfree

       Add probes at malloc() function on libc

           ./perf probe -x /lib/libc.so.6 malloc or ./perf probe /lib/libc.so.6 malloc



sudo perf probe -l
sudo perf probe -l
WARNING: terminal is not fully functional
-  (press RETURN) 
  probe_simple:f4      (on f4@simple.cc in /tmp/simple)
krishna@krishna:~/linux_perf_cheatsheet$ krishna@krishna:~/linux_perf_cheatsheet$ history | grep f4
history | grep f4
 1771  perf probe -x /tmp/simple  f4
 1772  sudo perf probe -x /tmp/simple  f4
 1773  bpftrace -e 'uprobe:/tmp/simple:f4 { printf("FOO\n"); }'
 1774  sudo bpftrace -e 'uprobe:/tmp/simple:f4 { printf("FOO\n"); }'
 1775  perf record -e probe_simple:f4 -aR sleep 20
 1776  sudo perf record -e probe_simple:f4 -aR sleep 20
 1795  history | grep f4


sudo perf script
sudo perf script
WARNING: terminal is not fully functional
-  (press RETURN) 
          simple 35812 [009] 252606.865870: probe_simple:f4: (55d560117290)
          simple 35821 [000] 252615.987043: probe_simple:f4: (55d00b17f290)
          simple 35823 [009] 252615.987849: probe_simple:f4: (55d00b17f290)
          simple 35825 [011] 252615.988241: probe_simple:f4: (55d00b17f290)
          simple 35825 [011] 252622.330311: probe_simple:f4: (55d00b17f290)
          simple 35823 [009] 252625.330479: probe_simple:f4: (55d00b17f290)
          
https://www.percona.com/sites/default/files/ple19-slides/day1-pm/tracing-and-profiling-mysql.pdf

Adding uprobes to MySQL dynamically with perf
 The idea was to add dynamic probe to capture SQL queries
 This was done on Ubuntu 16.04 with recent Percona Server 5.7
 First I had to find out with gdb where is the query (hint: dispatch_command
has com_data parameter):
(gdb) p com_data->com_query.query
$4 = 0x7fb0dba8d021 "select 2"
 Then its just as easy as follows:
openxs@ao756:~$ sudo perf probe -x /usr/sbin/mysqld 'dispatch_command
com_data->com_query.query:string'
openxs@ao756:~$ sudo perf record -e 'probe_mysqld:dispatch_command*' -aR
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.676 MB perf.data (3 samples) ]
openxs@ao756:~$ sudo perf script >/tmp/queries.txt
openxs@ao756:~$ sudo perf probe --del dispatch_command


=========================================================================================
* bcc

Ref: https://github.com/iovisor/bcc/blob/master/INSTALL.md
Could not install properly for Ubuntu 18.04
But it has good example for tacing latencies.
Not able to trace C++ code.

These tools fail to run:
 - tools/ucalls: Summarize method calls or Linux syscalls in high-level languages. Examples.
 - tools/uflow: Print a method flow graph in high-level languages. Examples.
 - tools/ugc: Trace garbage collection events in high-level languages. Examples.
 - tools/uobjnew: Summarize object allocation events by object type and number of bytes allocated. Examples.
 - tools/ustat: Collect events such as GCs, thread creations, object allocations, exceptions and more in high-level languages. Examples.
 -tools/uthreads: Trace thread creation events in Java and raw pthreads. Examples.

Below did not show C++ code at all.
~/bcc/tools$ sudo ./funclatency.py /tmp/simple:* --milliseconds  -p $(pidof simple) --function --duration 20
Tracing 21 functions for "/tmp/simple:*"... Hit Ctrl-C to end.


Function = b'__gnu_cxx::__enable_if<std::__is_integer<int>::__value, double>::__type std::sqrt<int>(int)' [50381]
     msecs               : count     distribution
         0 -> 1          : 2677210  |****************************************|
         2 -> 3          : 3        |                                        |
         4 -> 7          : 2        |                                        |

avg = 0 msecs, total: 16098 msecs, count: 2678884

Detaching...
==============================
* bpftrace

 bpftrace  is  a high-level tracing language for Linux enhanced Berkeley Packet Filter (eBPF) available in recent Linux kernels (4.x).

       
                   kernel       userland   
       
        static   tracepoints  USDT* probes 
       
        dynamic    kprobes      uprobes    
       
       USDT = user-level statically defined tracing
       static - are predefined probes in the code already
       dynamic - you can add probes at runtime (with out modifying the code).
       The bpftrace language is inspired by awk and C, and predecessor tracers such as DTrace and SystemTap.

Installation
-------------
Ref: https://github.com/iovisor/bpftrace/blob/master/INSTALL.md
For Ubuntu 18.04 (for 19.04 simpler)
sudo apt-get update
sudo apt-get install -y bison cmake flex g++ git libelf-dev zlib1g-dev libfl-dev systemtap-sdt-dev binutils-dev
sudo apt-get install -y llvm-7-dev llvm-7-runtime libclang-7-dev clang-7
git clone https://github.com/iovisor/bpftrace
mkdir bpftrace/build; cd bpftrace/build;
cmake -DCMAKE_BUILD_TYPE=Release ..
make -j8
sudo make install

!!Note: If things don't work reinstall!!


krishna@krishna  /linux_perf_cheatsheet$ sudo bpftrace -e 'uprobe:/tmp/simple:f4 { printf("f4: %d\n", arg1); }'
Attaching 1 probe...
f4: 0
f4: 0
f4: 0
f4: 0

$ sudo bpftrace -e 'uprobe:/tmp/simple:isP* { printf("isPrime: %d\n", arg1); }'

Not much functionality for user space:
See https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md#3-uprobeuretprobe-dynamic-tracing-user-level
  section "uprobe/uretprobe: Dynamic Tracing, User-Level"
     uprobe:library_name:function_name[+offset]
     uprobe:library_name:address
     uretprobe:library_name:function_name
  Section "4. uprobe/uretprobe: Dynamic Tracing, User-Level Arguments"
     probe: arg0, arg1, ..., argN
     uretprobe: retval


list probes?
-----------------
$ sudo bpftrace -l 'uprobe:/tmp/simple'
uprobe:/tmp/simple:_GLOBAL__sub_I_debug
uprobe:/tmp/simple:_Z14sigint_handleri
uprobe:/tmp/simple:_Z18io_thread_functionPv
uprobe:/tmp/simple:_Z19cpu_thread_functionPv
uprobe:/tmp/simple:_Z2f1i
uprobe:/tmp/simple:_Z2f2i
uprobe:/tmp/simple:_Z2f3i
uprobe:/tmp/simple:_Z2f4i
uprobe:/tmp/simple:_Z41__static_initialization_and_destruction_0ii
uprobe:/tmp/simple:_Z7isPrimei
uprobe:/tmp/simple:_ZSt4sqrtIiEN9__gnu_cxx11__enable_ifIXsrSt12__is_integerIT_E7__valueEdE6__typeES3_

Ref:
man bpftrace
https://github.com/iovisor/bpftrace
https://github.com/iovisor/bpftrace/blob/master/docs/reference_guide.md GOOD
http://www.brendangregg.com/BPF/bpftrace-cheat-sheet.html
https://github.com/iovisor/bpftrace/blob/master/docs/tutorial_one_liners.md
https://www.percona.com/sites/default/files/presentations/Scale18x-2020-bpfTrace-finally-dTrace-replacement.pdf
https://www.joyfulbikeshedding.com/blog/2019-01-31-full-system-dynamic-tracing-on-linux-using-ebpf-and-bpftrace.html#usdt-probe-example
=======================================================
* stap *systemtap

SystemTap is a tracing and probing tool that allows users to study and monitor the activities of the computer system (particularly, the kernel) in fine detail. It provides information similar to the output of tools like netstat, ps, top, and iostat, but is designed to provide more filtering and analysis options for collected information.

In Ubuntu distro works only for user process, not for kernel. "However, SystemTap never fully merged into the Linux kernel (parts did, like uprobes), so as an out-of-tree project it required maintenance to work at all, and Red Hat only did this for RHEL." Ref: http://www.brendangregg.com/blog/2018-10-08/dtrace-for-linux-2018.html

Ref: https://sourceware.org/systemtap/langref/ GOOD one
     https://sourceware.org/systemtap/SystemTap_Beginners_Guide/
     all functions https://manpages.debian.org/testing/systemtap-doc/index.html
     https://sourceware.org/systemtap/examples/index.html good examples

Example: Print call trace
-------------------------------
wget https://sourceware.org/systemtap/examples/general/para-callgraph.stp
-v verbose
-c CMD Start  the  probes, run CMD, and exit when CMD finishes.
-x PID Sets  target()  to PID.
linux_perf_cheatsheet/scripts$ sudo stap para-callgraph.stp  'process("/tmp/simple").function("*")'  -v -c "/tmp/simple > /dev/null"

    microsecond           Function with args
    |         Thread id    |    
    |          |           v
   545 simple(8163):   ->f1 c=0x16
     0 simple(8166):->io_thread_function vargp=0x7ffd18fe773c
     0 simple(8167):->cpu_thread_function vargp=0x7ffd18fe773c
    25 simple(8167): ->f3 a=0x14
    39 simple(8167):  ->f2 b=0x15
    52 simple(8167):   ->f1 c=0x16
    65 simple(8167):   <-f1 
    70 simple(8167):  <-f2 
    75 simple(8167): <-f3 
  1127 simple(8165):   <-f1 
  1137 simple(8165):  <-f2 
  1142 simple(8165): <-f3 
  1455 simple(8163):   <-f1 
  1464 simple(8163):  <-f2 
  1469 simple(8163): <-f3 
6000710 simple(8167): ->f3 a=0x14
6000741 simple(8167):  ->f2 b=0x15
6000756 simple(8167):   ->f1 c=0x16
6000772 simple(8167):   <-f1 
6000777 simple(8167):  <-f2 
6000781 simple(8167): <-f3 


List matching probes and local variables of function f1:-
------------------------------------------------------------
$sudo stap  -L 'process("/tmp/simple").function("f1")'
krishna@krishna:~/linux_perf_cheatsheet/scripts$ process("/tmp/simple").function("f1@/home/krishna/linux_perf_cheatsheet/simple.cc:50") $c:int $c1:class C1 <-- shows variables that can be accessed 
void f1(int c) {
  C1 c1;
  c1.m1 = 1;
  c1.m2 = 2;
  c1.m3 = 3;
  for (int i = 0; i > 0; i++) {
    i = i + 1;
  }
  printf(".");
}


List matching probes in a file or library
------------------------------------------------------------
$ sudo stap -l 'process("/tmp/simple").function("*")'
[sudo] password for krishna: 
process("/tmp/simple").function("__do_global_dtors_aux")
process("/tmp/simple").function("__libc_csu_fini")
process("/tmp/simple").function("__libc_csu_init")
process("/tmp/simple").function("_fini")
process("/tmp/simple").function("_init")
process("/tmp/simple").function("_start")
process("/tmp/simple").function("cpu_thread_function@/home/krishna/linux_perf_cheatsheet/simple.cc:63")
process("/tmp/simple").function("deregister_tm_clones")
process("/tmp/simple").function("f1@/home/krishna/linux_perf_cheatsheet/simple.cc:50")
process("/tmp/simple").function("f2@/home/krishna/linux_perf_cheatsheet/simple.cc:61")
process("/tmp/simple").function("f3@/home/krishna/linux_perf_cheatsheet/simple.cc:62")
process("/tmp/simple").function("frame_dummy")
process("/tmp/simple").function("io_thread_function@/home/krishna/linux_perf_cheatsheet/simple.cc:82")
process("/tmp/simple").function("main@/home/krishna/linux_perf_cheatsheet/simple.cc:127")
process("/tmp/simple").function("open@/usr/include/x86_64-linux-gnu/bits/fcntl2.h:41")
process("/tmp/simple").function("printf@/usr/include/x86_64-linux-gnu/bits/stdio2.h:102")
process("/tmp/simple").function("register_tm_clones")
process("/tmp/simple").function("sigint_handler@/home/krishna/linux_perf_cheatsheet/simple.cc:45")
process("/tmp/simple").function("sprintf@/usr/include/x86_64-linux-gnu/bits/stdio2.h:31")

krishna@krishna:~/linux_perf_cheatsheet/scripts$ sudo stap -l 'process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("*")'
process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("AbortTx@/home/krishna/orcasql-mysql/storage/vml/metadata/UndurableStorage.cc:340")
process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("Acquire@/home/krishna/orcasql-mysql/storage/vml/io_fence/FileLockBasedIoFence.cc:28")
process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("Acquire@/home/krishna/orcasql-mysql/storage/vml/io_fence/IoFenceManager.cc:25")
process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("Acquire@/home/krishna/orcasql-mysql/storage/vml/io_fence/ScsiBasedIoFence.cc:492")
process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("AcquireWriteExclusiveAccess@/home/krishna/orcasql-mysql/storage/vml/io_fence/Scsi


Example: more comprehensive user process tracing
-------------------------------------------------
in another window start: /tmp/simple


sudo stap -v -e '
probe process("/tmp/simple").function("f1")
   {
     printf(" Program name:%s", execname());
     printf(" cpu:%d",  cpu());
     printf(" pid:%d", pid());
     printf(" tid:%d", tid());
     printf(" function:%s", ppfunc() );
     printf(" Local variables:%s",$$vars);
     // refer program variables using $ such as $c1
     printf(" Variable c1.m3:%d",$c1->m3);     
     
     printf("\n");
     print_ubacktrace();
   }

probe process("/tmp/simple").statement("*@simple.cc:58").nearest
   {
     // $$..$$ prints nested classes structures
     printf(" In function function:%s", ppfunc() );     
     printf(" Locals: %s", $$locals$$);
     printf("Params: %s", $$parms);
     // prints variables in scope: class members also     
     printf(" Variables in scope: %s", $$vars$$);
     printf("\n");
   }

probe process("/tmp/simple").thread.begin
   {
        printf(" tid:%d started", tid());
   }

probe process("/tmp/simple").thread.end
   {
        printf(" tid:%d ended", tid());
   }

probe process("/tmp/simple").syscall
   {
        printf("%s called %s\n", syscall_name($syscall),  $$parms);
   }

probe process("/tmp/simple").syscall.return
   {
        // does not work: time =  gettimeofday_ns() - @entry(gettimeofday_ns());
        printf("%s ret:%d\n", syscall_name($syscall), $return);
   }

global f3_time;
probe process("/tmp/simple").function("f3").return
   {
      // operator <<< stores the value in the aaray "f3_time"
      f3_time <<< gettimeofday_ns() - @entry(gettimeofday_ns());
   }

probe end
   {
     printf(" function f3 time stats in nano seconds\n");
     print(" count:", @count(f3_time));
     print(" min:", @min(f3_time));
     print(" max:", @max(f3_time));
     print(" avg:", @avg(f3_time));     

     print(" Histogram:\n");
     print(@hist_log(f3_time));
   }

'



Example: mega code tracing and function latency measurement
---------------------------------------------------------------
GOOD
To call trace or measure a large/medium project use these steps

1. update variables in stap_process_find_function_probes.py and generate the list of functions and corresponding probes.
python3 stap_process_find_function_probes.py  > /tmp/function_probes.txt

2.
  - based on /tmp/function_probes.txt update the .call call and .return probes in mega-callgraph.stp
  - update verbose variable in mega-callgraph.stp
  - this requires about 8G memory during compilation!!
  - Adjust MAXMAPENTRIES to the number of function probes.
  - From my experiment the count displayed are much lower (eg., 33 instead of 100)
  - Run as follows
sudo stap -g --suppress-time-limits -v -DMAXMAPENTRIES=10000 -DMAXSKIPPED=100000  mega-callgraph.stp
Pass 1: parsed user script and 465 library scripts using 116376virt/51084res/6836shr/44696data kb, in 330usr/60sys/832real ms.
Pass 2: analyzed script: 3400 probes, 7556 functions, 4 embeds, 2268 globals using 286136virt/222432res/8232shr/214456data kb, in 377010usr/2650sys/400102real ms.
Pass 3: translated to C into "/tmp/stapQHy5dG/stap_d5aeeab3409fe551afedf1287cdf04a9_15083112_src.c" using 286136virt/222640res/8428shr/214456data kb, in 79320usr/490sys/79807real ms.
/tmp/stapQHy5dG/stap_d5aeeab3409fe551afedf1287cdf04a9_15083112_src.c: In function probe_8294:
/tmp/stapQHy5dG/stap_d5aeeab3409fe551afedf1287cdf04a9_15083112_src.c:794692:0: note: -Wmisleading-indentation is disabled from this point onwards, since column-tracking was disabled due to the size of the code/headers
             c->actionremaining -= 2;
 
Pass 4: compiled C into "stap_d5aeeab3409fe551afedf1287cdf04a9_15083112.ko" in 1010300usr/16230sys/1017915real ms.
Pass 5: starting run.


Sample output:- with verbose=1 and with call and return probes: process("/home/krishna/orcasql-mysql/out/storage/vml/libvml.so").function("PerformWriteInternal").return
->PerformWriteInternal this={.m_aioContext=0x5622867d2f00, .m_filePath={._M_dataplus={._M_p="/tmp/chunk9.raw"}, ._M_string_length=15, <union>={._M_local_buf="/tmp/chunk9.raw", ._M_allocated_capacity=8460120955416310831}}, .m_fdBuffered=9, .m_fdUnbuffered=10, .m_isBlockDevice=0} ioRequest={.ioRequestType=1, .buf="8<l\277", .numBytes=16384, .offset=184614912, .cancelled=0, .chunkHandler=0x56228679b950, .cb=0x7f6837a60ffe, .cbParam=0x7f6624000e90, .ioAttrsAndStat=0x7f6624000f60} iocb={.data=0x0, .key=0, .__pad2=0, .aio_lio_opcode=0

<-PerformWriteInternal return=0x1 latency:2628 micro sec tid:5909 cpu:14


Sample output: without verbose=0 
Pass 1: parsed user script and 465 library scripts using 114388virt/49356res/6956shr/42708data kb, in 260usr/20sys/279real ms.
Pass 2: analyzed script: 27 probes, 29 functions, 4 embeds, 26 globals using 116376virt/52752res/8144shr/44696data kb, in 80usr/220sys/307real ms.
Pass 3: translated to C into "/tmp/stapIAZSXk/stap_093f662386cfef37de7929734d9fa9c1_38571_src.c" using 116524virt/53048res/8336shr/44844data kb, in 40usr/200sys/236real ms.
Pass 4: compiled C into "stap_093f662386cfef37de7929734d9fa9c1_38571.ko" in 6080usr/1530sys/7204real ms.
Pass 5: starting run.
function:isPrime, latency microsec mean:6, variance:167 std-dev:sqrt(167) count:11979134 total:71874804 
function:f1, latency microsec mean:21525725, variance:6435019932039 std-dev:sqrt(6435019932039) count:11 total:236782975  WATCH THIS
function:f2, latency microsec mean:21525779, variance:6435172397322 std-dev:sqrt(6435172397322) count:11 total:236783569  WATCH THIS
function:f3, latency microsec mean:21525818, variance:6435239316113 std-dev:sqrt(6435239316113) count:11 total:236783998  WATCH THIS
function:f4, latency microsec mean:28479143, variance:15604731554753 std-dev:sqrt(15604731554753) count:10 total:284791430  WATCH THIS
function:io_thread_function, latency microsec mean:109169027, variance:1916802280 std-dev:sqrt(1916802280) count:3 total:327507081  WATCH THIS
function:main, latency microsec mean:109219953, variance:0 std-dev:sqrt(0) count:1 total:109219953  WATCH THIS


GOOD Show Time Spent on Each Line of a Function
---------------------------------------------
Ref: https://sourceware.org/systemtap/examples/index.html#profiling/linetimes.stp
Modified code a bit and it is under scripts/linetimes.stp

Eg., here is a sample function with line numbers. A few line times are annotated 

 90void f4(int d) {
 91  f3(d);                     
 92  pthread_mutex_lock(&mutex1);
 93  sleep(1);
 94  pthread_mutex_unlock(&mutex1);
 95
 96  pthread_mutex_lock(&mutex2);
 97  sleep(2);
 98  pthread_mutex_unlock(&mutex2);
 99
100  pthread_mutex_lock(&mutex3); <-- Avg latency is 2387387 us, max latency 2686463 us
101  sleep(3);                    <-- Avg latency is 3000163 us, max latency is 3000198 us
102  pthread_mutex_unlock(&mutex3); <-- avg(us):74 max: 99
103}

$sudo stap linetimes.stp "/tmp/simple" "f4" -c '/tmp/simple'
io_threads are running ...
cpu_threads are running ...

/tmp/simple f4 call count: 37

region                                                                                      avg(us)    max(us)
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:100")    2387387    2686463
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:101")    3000163    3000198
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:102")         74         99
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:103")         10         18
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:90")         17         50
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:91")     484091     538079
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:92")      71023    1792180
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:93")    1000154    1000179
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:94")         36         79
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:96")      81096    2000029
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:97")    2000150    2000166
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:98")         33         78


control flow graph information
from
        to
=======================
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:100")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:101") 35
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:101")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:102") 34
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:102")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:103") 34
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:103")
        process("/tmp/simple").function("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:90").return 34
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:90")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:91") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:91")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:92") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:92")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:93") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:93")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:94") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:94")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:96") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:96")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:97") 37
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:97")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:98") 36
process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:98")
        process("/tmp/simple").statement("f4@/home/krishna/linux_perf_cheatsheet/simple.cc:100") 36
krishna@krishna:~/linux_perf_cheatsheet/scripts$ 

What probes are available:
-----------------------------
Ref: https://sourceware.org/systemtap/man/stapprobes.3stap.html (see sections USER-SPACE, Java)
process("PATH").function("NAME")
  - Places a probe near the beginning of the named function, so that parameters are available as context variables.
process("PATH").statement("*@FILE.c:123")
  -  Places a probe at the exact spot, exposing those local variables that are visible there.
process("PATH").library("PATH").function("NAME")
process("PATH").library("PATH").statement("*@FILE.c:123")
  -  Places a probe at the exact spot, exposing those local variables that are visible there.
process("PATH").library("PATH").statement("*@FILE.c:123").nearest
process("PATH").function("*").return
  - Places a probe at the moment after the return from the named function, so the return value is available as the "$return" context variable.
process("PATH").function("myfun").label("foo")
process("PATH").function("foo").callee("bar")
  - Places a probe on the callee function given in the .callee modifier, where the callee must be a function called by the target function given in .function. calls through function pointers are not available.
process("PATH").function("foo").callee("bar").return
process("PATH").function("foo").callee("bar").call
process("PATH").function("foo").callees(DEPTH)
  - Recursively places probes on callees. 
process(PID).function("NAME")
process(PID).function("myfun").label("foo")
process(PID).plt("NAME")
 - ?? A .plt probe will probe functions in the program linkage table corresponding to the rest of the probe point
process(PID).plt("NAME").return
process(PID).statement("*@FILE.c:123")
process(PID).statement("*@FILE.c:123").nearest <-- Places a probe at the nearest available line number for each line number given in the statement.
process(PID).statement(ADDRESS).absolute
  - use raw (unverified) virtual addresses
process("PATH").mark("LABEL")
  - This is for instrumented code(code should have STAP_PROBE1). A .mark probe gets called via a static probe which is defined in the application by STAP_PROBE1(PROVIDER,LABEL,arg1), which are macros defined in sys/sdt.h.


process(PID).begin
process("FULLPATH").begin
process.begin
 - A process.begin probe gets called when new process described by PID or FULLPATH gets created. In addition, it is called once from the context of each preexisting process, at systemtap script startup. This is useful to track live processes

process(PID).thread.begin
process("FULLPATH").thread.begin
process.thread.begin
  -  A process.thread.begin probe gets called when a new thread described by PID or FULLPATH gets created.
process(PID).end
process("FULLPATH").end
process.end
process(PID).thread.end
process("FULLPATH").thread.end
process.thread.end

process(PID).syscall
process("FULLPATH").syscall
process.syscall
 - The system call number is available in the $syscall context variable, and the first 6 arguments of the system call are available in the $argN (ex. $arg1, $arg2, ...) context variable.
 
process(PID).syscall.return
process("FULLPATH").syscall.return
process.syscall.return
  - the return value of the system call is available in the $return context variabl
  
process(PID).insn
process("FULLPATH").insn
process(PID).insn.block
process("FULLPATH").insn.block
 - A process.insn probe gets called for every single-stepped instruction of the process described by PID or FULLPATH. A process.insn.block probe gets called for every block-stepped instruction of the process described by PID or FULLPATH


What to print:
-------------------
Ref: https://sourceware.org/systemtap/tutorial.pdf
tid() The id of the current thread.
pid() The process (task group) id of the current thread.
uid() The id of the current user.
execname() The name of the current process.
cpu() The current cpu number.
gettimeofday_s() Number of seconds since epoch.
get_cycles() Snapshot of hardware cycle counter.
pp() A string describing the probe point being currently handled.
ppfunc() If known, the the function name in which this probe was placed.
$$vars If available, a pretty-printed listing of all local variables in scope.
print_backtrace() If possible, print a kernel backtrace.
print_ubacktrace() If possible, print a user-space backtrace.


Multiple probes can be specified using a ","
---------------------------------------------------

sudo stap -e 'probe process("/tmp/foo.so").function("f1"),process("/tmp/foo.so").function("f2") { printf("hello");}'


==========================================================
* strace


-c Count time, calls, and  errors for each system call and report a summary on program exit.
   This attempts to show system time (CPU time spent running in the kernel) independent of  wall clock time.

-e trace=set eg., -e trace=open,close,read,write

summary of system calls and times
---------------------------------------
$  strace -c -f /tmp/simple
strace: Process 32966 attached
strace: Process 32967 attached
strace: Process 32968 attached
strace: Process 32969 attached
strace: Process 32970 attached
strace: Process 32971 attached
io_threads are running ...
cpu_threads are running ...
% time     seconds  usecs/call     calls    errors syscall
------ ----------- ----------- --------- --------- ----------------
 72.99    0.908515        2232       407           nanosleep
 22.04    0.274316        3345        82           futex
  4.68    0.058269         194       300           pwrite64 <-- 4% of the system time(CPU time in kernel) is pwrite64
                                                                300 call. total CPU time in kernel 0.058269 sec.
                                                                Each call avg 194 micro seconds.
  0.07    0.000868          41        21           mprotect
  0.06    0.000686         114         6           munmap
  0.05    0.000617         103         6           clone
  0.04    0.000489          19        26           mmap
  0.02    0.000298         149         2           write
  0.02    0.000285          17        17         8 openat
  0.02    0.000270          39         7           set_robust_list
  0.01    0.000122          41         3           madvise
  0.00    0.000055           8         7           fstat
  0.00    0.000000           0         5           read
  0.00    0.000000           0         6           close
  0.00    0.000000           0         8         7 stat
  0.00    0.000000           0         3           brk
  0.00    0.000000           0         3           rt_sigaction
  0.00    0.000000           0         1           rt_sigprocmask
  0.00    0.000000           0         7         7 access
  0.00    0.000000           0         1           execve
  0.00    0.000000           0         1           arch_prctl
  0.00    0.000000           0         1           set_tid_address
  0.00    0.000000           0         1           prlimit64
------ ----------- ----------- --------- --------- ----------------
100.00    1.244790                   921        22 total


-p pid
-xx         Print all strings in hexadecimal string format.
-f   trace child/threads
-s strsize  Specify the maximum string size to print (the default is 32).
strace -f -p $(pidof mysqld) -e pwrite -s1 -xx 2>&1 | grep 'pwrite([FD1FD2],' |head -n 100000 | awk '{writes[$5]++}END {for(w in writes){print w, " ", writes[w]}}'
[5:56 PM] Anand Subramanian
    this should give the InnoDB log file writes being done
[5:56 PM] Anand Subramanian
    number/count of and what sized IOs

strace -f -e pwrite64 /tmp/simple -s1 -xx 2>&1 | grep pwrite64 | grep -v resumed | awk '{ print $5, " ", $0;}'


=============================
* time

time /tmp/simple
io_threads are running ...
cpu_threads are running ...

real    1m47.819s <- Elapsed real (wall clock) time used by the process, in seconds.
user    0m17.813s <-- Total number of CPU-seconds that the process used directly (in user mode), in seconds.
sys     0m0.077s  <-- Total number of CPU-seconds used by the system on behalf of the process (in kernel mode), in seconds.
==========================
* migration

Ref: https://stackoverflow.com/questions/45368742/linux-difference-between-migrations-and-switches

A thread can migrate to another CPU in the following cases:
 - During exec()
 - During fork()
 - During thread wake-up.
 - If thread affinity mask has changed.
 - When the current CPU is getting offline.

Process migration in computing comes in two flavors:[1]
- Non-preemptive process migration: Process migration that takes place before execution of
  the process starts (i.e. migration whereby a process need not be preempted).
  This type of process migration is relatively cheap, since relatively little administrative
  overhead is involved.
- Preemptive process migration: Process migration whereby a process is preempted, migrated
  and continues processing in a different execution environment.
  This type of process migration is relatively expensive, since it involves recording,
  migration and recreation of the process state as well as the reconstructing of any
  inter-process communication channels to which the migrating process is connected.


$ cat /proc/33514/sched
simple (33514, #threads: 7)
-------------------------------------------------------------------
se.exec_start                                :     231412663.439654
se.vruntime                                  :      13531310.384397
se.sum_exec_runtime                          :             3.964652
se.nr_migrations                             :                    0 <-- number of context switches.
nr_switches                                  :                    3
nr_voluntary_switches                        :                    3 <--  number of voluntary switches, i.e. the thread blocked and hence another thread is picked up.
nr_involuntary_switches                      :                    0 <-- the scheduler kicked the thread out as there is another hungry thread is ready to run.
se.load.weight                               :              1048576
se.runnable_weight                           :              1048576
se.avg.load_sum                              :                47280
se.avg.runnable_load_sum                     :                47280
se.avg.util_sum                              :             26015811
se.avg.load_avg                              :                 1023
se.avg.runnable_load_avg                     :                 1023
se.avg.util_avg                              :                  547
se.avg.last_update_time                      :      231412663439360
policy                                       :                    0
prio                                         :                  120
clock-delta                                  :                  191
mm->numa_scan_seq                            :                    1
numa_pages_migrated                          :                  184
numa_preferred_nid                           :                   -1
total_numa_faults                            :                14371
current_node=0, numa_group_id=0
numa_faults node=0 task_private=0 task_shared=0 group_private=0 group_shared=0
numa_faults node=1 task_private=0 task_shared=0 group_private=0 group_shared=0
========================================================================================
* optimizations * cpu optimization


** Branch prediction macros in GCC
Ref: https://www.geeksforgeeks.org/branch-prediction-macros-in-gcc/

#define likely(x)      __builtin_expect(!!(x), 1)
#define unlikely(x)    __builtin_expect(!!(x), 0)

const char *home_dir ;

home_dir = getenv("HOME");
if (likely(home_dir))
   printf("home directory: %s\n", home_dir);
else
   perror("getenv");

For above example, we have marked if condition as likely() true, so compiler will put true code immediately after branch, and false code within the branch instruction. In this way compiler can achieve optimization.
Accessing memory is the slowest CPU operation as compared to other CPU operations. To avoid this limitation, CPU uses CPU caches e.g L1-cache, L2-cache etc. The idea behind cache is, copy some part of memory into CPU itself. We can access cache memory much faster than any other memory. But the problem is, limited size of cache memory, we cant copy entire memory into cache. So, the CPU has to guess which memory is going to be used in the near future and load that memory into the CPU cache and above macros are hint to load memory into the CPU cache.


** Loop Optimization in Compiler Design
Ref: https://www.geeksforgeeks.org/loop-optimization-in-compiler-design/?ref=rp

*** Frequency Reduction (Code Motion):
In frequency reduction, the amount of code in loop is decreased. A statement or expression, which can be moved outside the loop body without affecting the semantics of the program, is moved outside the loop.

Initial code:

while(i<100)
{
   a = Sin(x)/Cos(x) + i;
   i++;
}

Optimized code:

t = Sin(x)/Cos(x);
while(i<100)
{
 a = t + i;
 i++;
}

*** Loop Unrolling: Loop unrolling is a loop transformation technique that helps to optimize the execution time of a program. We basically remove or reduce iterations. Loop unrolling increases the programs speed by eliminating loop control instruction and loop test instructions.
Example:

Initial code:-

for (int i=0; i<5; i++)
  printf("Pankaj\n");

Optimized code:-

printf("Pankaj\n");
printf("Pankaj\n");
printf("Pankaj\n");
printf("Pankaj\n");
printf("Pankaj\n");

*** Loop Jamming: Loop jamming is the combining the two or more loops in a single loop. It reduces the time taken to compile the many number of loops.
Example:

Initial Code:

for(int i=0; i<5; i++)
    a = i + 5;
for(int i=0; i<5; i++)
    b = i + 10;

Optimized code:
for(int i=0; i<5; i++)
{
  a = i + 5;
  b = i + 10;
}

*** Peephole Optimization in Compiler Design
Ref: https://www.geeksforgeeks.org/peephole-optimization-in-compiler-design/

Peephole optimization is a type of Code Optimization performed on a small part of the code. It is performed on the very small set of instructions in a segment of code.

Redundant load and store elimination: In this technique the redundancy is eliminated.

Initial code:
  y = x + 5;
  i = y;
  z = i;
  w = z * 3;

Optimized code: ( here variable "z" is redundant/removed)
  y = x + 5;
  i = y;
  w = y * 3;
Constant folding: The code that can be simplified by user itself, is simplified.

Initial code:
  x = 2 * 3;

Optimized code:
  x = 6;
  
Strength Reduction:The operators that consume higher execution time are replaced by the operators consuming less execution time.

Initial code:
  y = x * 2;
Optimized code:
  y = x + x;    or     y = x << 1;

Initial code:
  y = x / 2;
Optimized code:
  y = x >> 1;
  
Null sequences: Useless operations are deleted.

Combine operations: Several operations are replaced by a single equivalent operation.

** Basic optimizations

Ref: https://www.geeksforgeeks.org/basic-code-optimizations-in-c/

Avoid pointer Dereference in loop: Pointer dereferencing creates lots of trouble in memory. So better assign it to some temporary variable and then use that temporary variable in the loop.

Unoptimized:-
#include <stdio.h>
int main(void) {
  int a = 0;
  int *iptr = &a;

  // Dereferencing pointer inside loop
  // is costly
  for (int i = 1; i < 11; ++i) {
    *iptr = *iptr + i;
  }
  printf("Value of a : %d", a);
  return 0;
}

Optimized:-
#include <stdio.h>
int main(void) {
  int a = 0;
  int *iptr = &a;

  // Dereferencing pointer outside loop
  // and saving its value in a temp variable
  int temp = *iptr;

  for (int i = 1; i < 11; ++i) {

    // performing calculations on temp variable
    temp = temp + i;
  }

  // Updating pointer using final value of temp
  *iptr = temp;

  printf("Value of a : %d", a);
  return 0;
}

============================================================
* pgo profile guide optimization

Ref:
  What Every Programmer Should Know About Memory https://akkadia.org/drepper/cpumemory.pdf
  https://ddmler.github.io/compiler/2018/06/29/profile-guided-optimization.html
The first step  is to create an instrumented version of our binary that will gather the runtime data

$ g++ -fprofile-generate simple.cc -o /tmp/simple -lpthread -rdynamic;

Normally you would run it multiple times with different input and so on to create a somewhat representative sample of your actual usage patterns. This will create a new .gcda file in this case its called simple.gcda. We will use this in our next step as the profile:

$g++ -fprofile-use=simple.gcda -O3 simple.cc -o /tmp/simple -lpthread -rdynamic;

==============================================================
* compiler optimizations 
gcc: how did gcc optimize my code
-------------------------------
Ref: https://gcc.gnu.org/onlinedocs/gcc-6.3.0/gcc/Developer-Options.html
  - fdump-tree-switch-options=filename Control the dumping at various stages of processing the intermediate language tree to a file.
   optimized Enable showing optimization information (only available in certain passes)

Ref: https://stackoverflow.com/questions/2391442/how-to-see-the-optimized-code-in-c

You can get an idea of optimization using the option -fdump-tree-optimized with gcc . and you'll get an optimised file. you cannot run the code but using that you can get an idea of optimization . dont forget to include -O2 or -O3 or some other level.

Eg.,
$ g++  -O3 -fdump-tree-optimized=optimized.txt  simple.cc -o /tmp/simple -lpthread -rdynamic;
optimized.txt file will contains the file that shows how g++ optimized the code with "-O3" option
$ time /tmp/simple
real    0m9.659s <-- 10 sec

$g++ -fdump-tree-optimized=unoptimized.txt  simple.cc -o /tmp/simple -lpthread -rdynamic;
unoptimized.txt file will contain the file that shows the unoptimized code
$ time /tmp/simple
Unoptimized takes very long time ...  may be 10 mins?

Original cpu_thread_function:-

void *cpu_thread_function(void *vargp) {
  uint32_t my_num = (*(uint32_t *)vargp);

  for (int loop_count = 0; loop_count < LOOP_COUNT; loop_count++) {
    f4(loop_count);
  }
}

From optimized.txt cpu_thread_function:-
  - Notice these things:
    -- conntents of f4() are put inside cpu_thread_function (inlined)
    -- f4() calls f3(). Here f3() as removed (as it is a redundant function: its return value not used, no printf in it, no global variables set)
void* cpu_thread_function(void*) (void * vargp)
{
  int i;
  double _10;
  unsigned int ivtmp_12;
  unsigned int ivtmp_31;

  <bb 2> [0.01%]:

  <bb 3> [0.15%]:
  # ivtmp_12 = PHI <ivtmp_31(8), 10(2)>
  goto <bb 7>; [100.00%]

  <bb 4> [14.29%]:
  _10 = (double) i_9;
  if (_10 u>= 0.0)
    goto <bb 6>; [98.99%]
  else
    goto <bb 5>; [1.01%]

  <bb 5> [0.14%]:
  __builtin_sqrt (_10);

  <bb 6> [14.29%]:

  <bb 7> [14.44%]:
  # i_6 = PHI <i_9(6), 0(3)>
  i_9 = i_6 + 1;
  if (i_9 == 1000000000)
    goto <bb 8>; [1.01%]
  else
    goto <bb 4>; [98.99%]

  <bb 8> [0.15%]:
  __builtin_putchar (46);
  __builtin_putchar (46);
  pthread_mutex_lock (&mutex1);
  pthread_mutex_unlock (&mutex1);
  pthread_mutex_lock (&mutex2);
  pthread_mutex_unlock (&mutex2);
  pthread_mutex_lock (&mutex3);
  pthread_mutex_unlock (&mutex3);
  __builtin_putchar (46);
  ivtmp_31 = ivtmp_12 + 4294967295;
  if (ivtmp_31 == 0)
    goto <bb 9>; [9.70%]
  else
    goto <bb 3>; [90.30%]

  <bb 9> [0.01%]:
  return;

}


From unoptimized.txt cpu_thread_function:-
  - Notice this:
    - no code optimization
    - while loop is replaced with "loop_count_1", "if" and "goto"
    
;; Function void* cpu_thread_function(void*) (_Z19cpu_thread_functionPv, funcdef_no=1729, decl_uid=42507, cgraph_uid=601, symbol_order=608)

void* cpu_thread_function(void*) (void * vargp)
{
  int loop_count;
  uint32_t my_num;

  <bb 2> [0.00%]:
  my_num_5 = MEM[(uint32_t *)vargp_4(D)];
  loop_count_6 = 0;

  <bb 3> [0.00%]:
  # loop_count_1 = PHI <loop_count_6(2), loop_count_8(4)>
  if (loop_count_1 > 9)
    goto <bb 5>; [0.00%]
  else
    goto <bb 4>; [0.00%]

  <bb 4> [0.00%]:
  f4 (loop_count_1);
  loop_count_8 = loop_count_1 + 1;
  goto <bb 3>; [0.00%]

  <bb 5> [0.00%]:
  return;

}


gcc: which optimizations are applied/missed
---------------------------------------------
Print information when an optimization is successfully applied.
$ g++ -O3 -fopt-info-optimized=optimized.all  simple.cc -o /tmp/simple -lpthread -rdynamic;

File optimized.all:-
....
simple.cc:189:26: note: loop turned into non-loop; it never loops.
simple.cc:189:26: note: loop with 3 iterations completely unrolled
...
File simple.cc:-
189  for (uint32_t i = 0; i < IO_THREAD_COUNT; i++) {
190    int *return_value;
191    pthread_join(cpu_threads[i], (void **)&return_value);
192  }

you can see the loop was unrolled (use $g++  -O3 -fdump-tree-optimized=optimized.txt  simple.cc -o /tmp/simple -lpthread -rdynamic;): 
  io_threads_nums[0] = 0;
  pthread_create (&cpu_threads, 0B, cpu_thread_function, &io_threads_nums);
  io_threads_nums[1] = 1;
  pthread_create (&MEM[(void *)&cpu_threads + 8B], 0B, cpu_thread_function, &MEM[(void *)&io_threads_nums + 4B]);
  io_threads_nums[2] = 2;
  pthread_create (&MEM[(void *)&cpu_threads + 16B], 0B, cpu_thread_function, &MEM[(void *)&io_threads_nums + 8B]);
  __builtin_puts (&"io_threads are running ..."[0]);
  __builtin_puts (&"cpu_threads are running ..."[0]);
  _32 = cpu_threads[0];
  pthread_join (_32, &return_value);
  return_value ={v} {CLOBBER};
  _38 = cpu_threads[1];
  pthread_join (_38, &return_value);
  return_value ={v} {CLOBBER};
  _3 = cpu_threads[2];
  pthread_join (_3, &return_value);
  return_value ={v} {CLOBBER};
  io_threads_nums ={v} {CLOBBER};
  cpu_threads ={v} {CLOBBER};


Which optimizations are missed ?
$ g++ -O3 -fopt-info-missed=missed.all  simple.cc -o /tmp/simple -lpthread -rdynamic;

missed.all file:
...
simple.cc:191:17: note: not vectorized: not enough data-refs in basic block.
simple.cc:191:17: note: not vectorized: not enough data-refs in basic block.
simple.cc:191:17: note: not vectorized: not enough data-refs in basic block.
..

gcc: which optimizations are enabled/disbaled at -O3
-------------------------------------------------------
Ref: https://stackoverflow.com/questions/14737371/how-to-find-out-which-optimizations-are-actually-applied-when-using-gcc

use -Q --help=optimizers 
$ g++  -O3 -Q --help=optimizers  simple.cc -o /tmp/simple -lpthread -rdynamic;
The following options control optimizations:
  -O<number>                            
  -Ofast                                
  -Og                                   
  -Os                                   
  -faggressive-loop-optimizations       [enabled]
  -falign-functions                     [disabled]
  -falign-jumps                         [disabled]
  -falign-labels                        [enabled]
  -falign-loops                         [disabled]
  -fassociative-math                    [disabled]
  -fasynchronous-unwind-tables          [enabled]
  -fauto-inc-dec                        [enabled]
  -fbranch-count-reg                    [enabled]
  -fcaller-saves                        [enabled]
  -fcode-hoisting                       [enabled]
  -fcombine-stack-adjustments           [enabled]
  -fcompare-elim                        [enabled]
  -fcprop-registers                     [enabled]
  -fcrossjumping                        [enabled]
  -fcse-follow-jumps                    [enabled]
  ..
  -finline                              [enabled]
  -finline-atomics                      [enabled]
  -finline-functions                    [enabled]
  -finline-functions-called-once        [enabled]
  -finline-small-functions              [enabled]
  -fipa-bit-cp                          [enabled]
  -fipa-cp                              [enabled]
  -fipa-cp-clone                        [enabled]
  -fipa-icf                             [enabled]
  -fipa-icf-functions                   [enabled]
  -fipa-icf-variables                   [enabled]
  -fipa-profile                         [enabled]
  ..xs
=======================================================================
